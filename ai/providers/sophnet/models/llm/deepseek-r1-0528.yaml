model: DeepSeek-R1-0528
label:
  zh_Hans: DeepSeek-R1-0528
  en_US: DeepSeek-R1-0528
model_type: llm
features:
  - agent-thought
model_properties:
  mode: chat
  context_size: 128000
parameter_rules:
  - name: max_tokens
    use_template: max_tokens
    type: int
    default: 8192
    min: 1
    max: 128000
    required: false
    help:
      zh_Hans: 模型回复最大长度（单位 token）。如果生成结果截断，可以调大该参数。
      en_US: The maximum length of the model's response (in tokens). If the generated results are truncated, you can increase this parameter.
  - name: response_format
    use_template: response_format
    label:
      zh_Hans: 回复格式
      en_US: Response Format
    type: string
    help:
      zh_Hans: 指定模型必须输出的格式的对象。 可启用 JSON 模式，这保证模型生成的消息是有效的 JSON。重要：使用 JSON 模式时，您还必须通过系统或用户消息提示模型自行生成JSON。
      en_US: Specifies the format that the model must output. JSON mode can be enabled, which ensures that the message generated by the model is valid JSON. Important! When using JSON mode, you must also prompt the model to generate JSON through system or user messages.
    required: false
    options:
      - text
      - json_object
pricing:
  input: '4'
  output: '16'
  unit: '0.000001'
  currency: RMB