background: '#EFFDFD'
configurate_methods:
- customizable-model
extra:
  python:
    model_sources:
      - models/llm/llm.py
    provider_source: provider/triton_inference_server.py
help:
  title:
    en_US: How to deploy Triton Inference Server
    zh_Hans: 如何部署 Triton Inference Server
  url:
    en_US: https://github.com/triton-inference-server/server
icon_large:
  en_US: icon_l_en.png
icon_small:
  en_US: icon_s_en.svg
label:
  en_US: Triton Inference Server
model_credential_schema:
  credential_form_schemas:
    - label:
        en_US: Server url
        zh_Hans: 服务器URL
      placeholder:
        en_US: Enter the url of your Triton Inference Server, e.g. http://192.168.1.100:8000
        zh_Hans: 在此输入 Triton Inference Server 的服务器地址，如 http://192.168.1.100:8000
      required: true
      type: text-input
      variable: server_url
    - default: '2048'
      label:
        en_US: Context size
        zh_Hans: 上下文大小
      placeholder:
        en_US: Enter the context size
        zh_Hans: 在此输入您的上下文大小
      required: true
      type: text-input
      variable: context_size
    - default: chat
      label:
        en_US: Model type
        zh_Hans: 补全类型
      options:
        - label:
            en_US: Completion model
            zh_Hans: 补全模型
          value: completion
        - label:
            en_US: Chat model
            zh_Hans: 对话模型
          value: chat
      placeholder:
        en_US: Enter the completion type
        zh_Hans: 在此输入您的补全类型
      required: true
      type: select
      variable: completion_type
    - default: 'true'
      label:
        en_US: Stream output
        zh_Hans: 流式输出
      options:
        - label:
            en_US: 'Yes'
            zh_Hans: 是
          value: 'true'
        - label:
            en_US: 'No'
            zh_Hans: 否
          value: 'false'
      placeholder:
        en_US: Whether to support stream output
        zh_Hans: 是否支持流式输出
      required: true
      type: select
      variable: stream
  model:
    label:
      en_US: Model Name
      zh_Hans: 模型名称
    placeholder:
      en_US: Enter your model name
      zh_Hans: 输入模型名称
models:
  llm:
    position: models/llm/_position.yaml
    predefined:
      - models/llm/*.yaml
provider: triton_inference_server
supported_model_types:
  - llm
