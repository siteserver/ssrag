{
  "manifests": [
      {
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "ssrag",
          "author": "ssrag",
          "label": {
              "en_US": "SSRAG",
              "zh_Hans": "SSRAG"
          },
          "description": {
              "en_US": "SSRAG is a default option built into the product, users can enjoy the service without filling in the API Key.",
              "zh_Hans": "内置默认选项，将硅基流动模型服务内置在产品中，无需申请与填写 API Key 即可轻松使用。"
          },
          "icon": "ssrag_square.png",
          "plugins": {
              "models": [
                  "provider/ssrag.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": false
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.23",
          "created_at": "2024-09-20T00:13:50.292989-04:00",
          "model": {
              "background": "#ffecff",
              "configurate_methods": [
                  "predefined-model",
                  "customizable-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/rerank/rerank.py",
                          "models/text_embedding/text_embedding.py",
                          "models/tts/tts.py",
                          "models/speech2text/speech2text.py"
                      ],
                      "provider_source": "provider/siliconflow.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "How to use SSRAG default model settings",
                      "zh_Hans": "如何使用 SSRAG 默认模型设置"
                  },
                  "url": {
                      "en_US": "https://ssrag.com/docs/default-model-settings"
                  }
              },
              "icon_large": {
                  "en_US": "ssrag.png"
              },
              "icon_small": {
                  "en_US": "ssrag_square.png"
              },
              "label": {
                  "en_US": "SSRAG",
                  "zh_Hans": "SSRAG"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Model context size",
                              "zh_Hans": "模型上下文长度"
                          },
                          "placeholder": {
                              "en_US": "Enter your Model context size",
                              "zh_Hans": "在此输入您的模型上下文长度"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "context_size"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Upper bound for max tokens",
                              "zh_Hans": "最大 token 上限"
                          },
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "text-input",
                          "variable": "max_tokens"
                      },
                      {
                          "default": "no_call",
                          "label": {
                              "en_US": "Function calling"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  },
                                  "value": "no_call"
                              },
                              {
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  },
                                  "value": "function_call"
                              }
                          ],
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "select",
                          "variable": "function_calling_type"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  }
              },
              "models": [
                  {
                      "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
                      "label": {
                          "zh_Hans": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
                          "en_US": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 16384,
                              "default": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.70",
                          "output": "0.70",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
                      "label": {
                          "zh_Hans": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
                          "en_US": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 16384,
                              "default": 8192
                          }
                      ],
                      "pricing": {
                          "input": "1.26",
                          "output": "1.26",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
                      "label": {
                          "zh_Hans": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
                          "en_US": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 16384,
                              "default": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Pro/deepseek-ai/DeepSeek-R1",
                      "label": {
                          "zh_Hans": "Pro/deepseek-ai/DeepSeek-R1",
                          "en_US": "Pro/deepseek-ai/DeepSeek-R1"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 16384,
                              "default": 16384
                          }
                      ],
                      "pricing": {
                          "input": "4",
                          "output": "16",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "deepseek-ai/DeepSeek-R1",
                      "label": {
                          "zh_Hans": "deepseek-ai/DeepSeek-R1",
                          "en_US": "deepseek-ai/DeepSeek-R1"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 16384,
                              "default": 16384
                          }
                      ],
                      "pricing": {
                          "input": "4",
                          "output": "16",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "deepseek-ai/DeepSeek-V2.5",
                      "label": {
                          "en_US": "deepseek-ai/DeepSeek-V2.5"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 4096,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "1.33",
                          "output": "1.33",
                          "unit": "0.000001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Pro/deepseek-ai/DeepSeek-V3",
                      "label": {
                          "en_US": "Pro/deepseek-ai/DeepSeek-V3"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 4096,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "8",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "deepseek-ai/DeepSeek-V3",
                      "label": {
                          "en_US": "deepseek-ai/DeepSeek-V3"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 4096,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "8",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "THUDM/GLM-4.1V-9B-Thinking",
                      "label": {
                          "en_US": "THUDM/glm-41v-9b-thinking"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16384
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 16384,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "default": 2,
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "default": 1.1
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "THUDM/glm-4-9b-chat",
                      "label": {
                          "en_US": "THUDM/glm-4-9b-chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 4096,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "zai-org/GLM-4.5-Air",
                      "label": {
                          "zh_Hans": "zai-org/GLM-4.5-Air",
                          "en_US": "zai-org/GLM-4.5-Air"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "1",
                          "output": "6",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "zai-org/GLM-4.5",
                      "label": {
                          "zh_Hans": "zai-org/GLM-4.5",
                          "en_US": "zai-org/GLM-4.5"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "3.5",
                          "output": "14",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "internlm/internlm2_5-7b-chat",
                      "label": {
                          "en_US": "internlm/internlm2_5-7b-chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 4096,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Pro/moonshotai/Kimi-K2-Instruct",
                      "label": {
                          "zh_Hans": "Pro/moonshotai/Kimi-K2-Instruct",
                          "en_US": "Pro/moonshotai/Kimi-K2-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 16384,
                              "default": 16384
                          }
                      ],
                      "pricing": {
                          "input": "4",
                          "output": "16",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "moonshotai/Kimi-K2-Instruct",
                      "label": {
                          "zh_Hans": "moonshotai/Kimi-K2-Instruct",
                          "en_US": "moonshotai/Kimi-K2-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 16384,
                              "default": 16384
                          }
                      ],
                      "pricing": {
                          "input": "4",
                          "output": "16",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/QVQ-72B-Preview",
                      "label": {
                          "en_US": "Qwen/QVQ-72B-Preview"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 16384,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "9.90",
                          "output": "9.90",
                          "unit": "0.000001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Qwen/QwQ-32B",
                      "label": {
                          "en_US": "Qwen/QwQ-32B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 32768,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "1",
                          "output": "4",
                          "unit": "0.000001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Qwen/Qwen2-7B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2-7B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 4096,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Qwen/Qwen2-VL-72B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2-VL-72B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "4.13",
                          "output": "4.13",
                          "unit": "0.000001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Qwen/Qwen2.5-14B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-14B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.7",
                          "output": "0.7",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-32B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-32B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "1.26",
                          "output": "1.26",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-72B-Instruct-128K",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-72B-Instruct-128K"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 4096,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "4.13",
                          "output": "4.13",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-72B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-72B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 4096,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "4.13",
                          "output": "4.13",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-7B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-7B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-Coder-32B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-Coder-32B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "1.26",
                          "output": "1.26",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-Coder-7B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-Coder-7B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-VL-32B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-VL-32B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "1.89",
                          "output": "1.89",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-VL-72B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-VL-72B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "4.13",
                          "output": "4.13",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Pro/Qwen/Qwen2.5-VL-7B-Instruct",
                      "label": {
                          "en_US": "Pro/Qwen/Qwen2.5-VL-7B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.35",
                          "output": "0.35",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-14B",
                      "label": {
                          "zh_Hans": "Qwen/Qwen3-14B",
                          "en_US": "Qwen/Qwen3-14B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.5",
                          "output": "2",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-235B-A22B-Instruct-2507",
                      "label": {
                          "zh_Hans": "Qwen/Qwen3-235B-A22B-Instruct-2507",
                          "en_US": "Qwen/Qwen3-235B-A22B-Instruct-2507"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 256000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          }
                      ],
                      "pricing": {
                          "input": "2.5",
                          "output": "10",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-235B-A22B-Thinking-2507",
                      "label": {
                          "zh_Hans": "Qwen/Qwen3-235B-A22B-Thinking-2507",
                          "en_US": "Qwen/Qwen3-235B-A22B-Thinking-2507"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 256000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          }
                      ],
                      "pricing": {
                          "input": "2.5",
                          "output": "10",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-235B-A22B",
                      "label": {
                          "zh_Hans": "Qwen/Qwen3-235B-A22B",
                          "en_US": "Qwen/Qwen3-235B-A22B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "2.5",
                          "output": "10",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-30B-A3B-Instruct-2507",
                      "label": {
                          "zh_Hans": "Qwen/Qwen3-30B-A3B-Instruct-2507",
                          "en_US": "Qwen/Qwen3-30B-A3B-Instruct-2507"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 256000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.7",
                          "output": "2.8",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-30B-A3B",
                      "label": {
                          "zh_Hans": "Qwen/Qwen3-30B-A3B",
                          "en_US": "Qwen/Qwen3-30B-A3B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.7",
                          "output": "2.8",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-32B",
                      "label": {
                          "zh_Hans": "Qwen/Qwen3-32B",
                          "en_US": "Qwen/Qwen3-32B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "1",
                          "output": "4",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-8B",
                      "label": {
                          "zh_Hans": "Qwen/Qwen3-8B",
                          "en_US": "Qwen/Qwen3-8B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "netease-youdao/bce-reranker-base_v1",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 512
                      }
                  },
                  {
                      "model": "BAAI/bge-reranker-v2-m3",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 8192
                      }
                  },
                  {
                      "model": "FunAudioLLM/SenseVoiceSmall",
                      "model_type": "speech2text",
                      "model_properties": {
                          "file_upload_limit": 1,
                          "supported_file_extensions": "mp3,wav"
                      }
                  },
                  {
                      "model": "iic/SenseVoiceSmall",
                      "model_type": "speech2text",
                      "model_properties": {
                          "file_upload_limit": 1,
                          "supported_file_extensions": "mp3,wav"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "netease-youdao/bce-embedding-base_v1",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 512,
                          "max_chunks": 1
                      }
                  },
                  {
                      "model": "BAAI/bge-large-en-v1.5",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 512,
                          "max_chunks": 1
                      }
                  },
                  {
                      "model": "BAAI/bge-large-zh-v1.5",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 512,
                          "max_chunks": 1
                      }
                  },
                  {
                      "model": "BAAI/bge-m3",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 1
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-Embedding-0.6B",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 32768,
                          "vector_dimension": 1024
                      },
                      "order": 3
                  },
                  {
                      "model": "Qwen/Qwen3-Embedding-4B",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 32768,
                          "vector_dimension": 2560
                      },
                      "order": 2
                  },
                  {
                      "model": "Qwen/Qwen3-Embedding-8B",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 32768,
                          "vector_dimension": 4096
                      },
                      "order": 1
                  },
                  {
                      "model": "FunAudioLLM/CosyVoice2-0.5B",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "FunAudioLLM/CosyVoice2-0.5B:alex",
                          "voices": [
                              {
                                  "mode": "FunAudioLLM/CosyVoice2-0.5B:alex",
                                  "name": "Alex（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "FunAudioLLM/CosyVoice2-0.5B:benjamin",
                                  "name": "Benjamin（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "FunAudioLLM/CosyVoice2-0.5B:charles",
                                  "name": "Charles（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "FunAudioLLM/CosyVoice2-0.5B:david",
                                  "name": "David（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "FunAudioLLM/CosyVoice2-0.5B:anna",
                                  "name": "Anna（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "FunAudioLLM/CosyVoice2-0.5B:bella",
                                  "name": "Bella（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "FunAudioLLM/CosyVoice2-0.5B:claire",
                                  "name": "Claire（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "FunAudioLLM/CosyVoice2-0.5B:diana",
                                  "name": "Diana（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              }
                          ],
                          "audio_type": "mp3",
                          "max_workers": 5
                      },
                      "pricing": {
                          "input": "50",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "fishaudio/fish-speech-1.4",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "fishaudio/fish-speech-1.4:alex",
                          "voices": [
                              {
                                  "mode": "fishaudio/fish-speech-1.4:alex",
                                  "name": "Alex（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.4:benjamin",
                                  "name": "Benjamin（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.4:charles",
                                  "name": "Charles（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.4:david",
                                  "name": "David（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.4:anna",
                                  "name": "Anna（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.4:bella",
                                  "name": "Bella（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.4:claire",
                                  "name": "Claire（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.4:diana",
                                  "name": "Diana（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              }
                          ],
                          "audio_type": "mp3",
                          "max_workers": 5
                      },
                      "pricing": {
                          "input": "105",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "fishaudio/fish-speech-1.5",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "fishaudio/fish-speech-1.5:alex",
                          "voices": [
                              {
                                  "mode": "fishaudio/fish-speech-1.5:alex",
                                  "name": "Alex（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.5:benjamin",
                                  "name": "Benjamin（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.5:charles",
                                  "name": "Charles（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.5:david",
                                  "name": "David（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.5:anna",
                                  "name": "Anna（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.5:bella",
                                  "name": "Bella（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.5:claire",
                                  "name": "Claire（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.5:diana",
                                  "name": "Diana（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              }
                          ],
                          "audio_type": "mp3",
                          "max_workers": 5
                      },
                      "pricing": {
                          "input": "105",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "RVC-Boss/GPT-SoVITS",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "RVC-Boss/GPT-SoVITS:alex",
                          "voices": [
                              {
                                  "mode": "RVC-Boss/GPT-SoVITS:alex",
                                  "name": "Alex（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "RVC-Boss/GPT-SoVITS:benjamin",
                                  "name": "Benjamin（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "RVC-Boss/GPT-SoVITS:charles",
                                  "name": "Charles（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "RVC-Boss/GPT-SoVITS:david",
                                  "name": "David（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "RVC-Boss/GPT-SoVITS:anna",
                                  "name": "Anna（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "RVC-Boss/GPT-SoVITS:bella",
                                  "name": "Bella（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "RVC-Boss/GPT-SoVITS:claire",
                                  "name": "Claire（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "RVC-Boss/GPT-SoVITS:diana",
                                  "name": "Diana（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              }
                          ],
                          "audio_type": "mp3",
                          "max_workers": 5
                      },
                      "pricing": {
                          "input": "50",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  }
              ],
              "provider": "ssrag",
              "supported_model_types": [
                  "llm",
                  "text-embedding",
                  "rerank",
                  "speech2text",
                  "tts"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "Ollama"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "Ollama"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "ollama",
          "plugins": {
              "models": [
                  "provider/ollama.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.6",
          "model": {
              "background": "#F9FAFB",
              "configurate_methods": [
                  "customizable-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/text_embedding/text_embedding.py"
                      ],
                      "provider_source": "provider/ollama.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "How to integrate with Ollama",
                      "zh_Hans": "如何集成 Ollama"
                  },
                  "url": {
                      "en_US": "https://docs.ssrag.ai/tutorials/model-configuration/ollama"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "Ollama"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "Base URL",
                              "zh_Hans": "基础 URL"
                          },
                          "placeholder": {
                              "en_US": "Base url of Ollama server, e.g. http://192.168.1.100:11434",
                              "zh_Hans": "Ollama server 的基础 URL，例如 http://192.168.1.100:11434"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "base_url"
                      },
                      {
                          "default": "chat",
                          "label": {
                              "en_US": "Completion mode",
                              "zh_Hans": "模型类型"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Completion",
                                      "zh_Hans": "补全"
                                  },
                                  "value": "completion"
                              },
                              {
                                  "label": {
                                      "en_US": "Chat",
                                      "zh_Hans": "对话"
                                  },
                                  "value": "chat"
                              }
                          ],
                          "placeholder": {
                              "en_US": "Select completion mode",
                              "zh_Hans": "选择对话类型"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "select",
                          "variable": "mode"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Model context size",
                              "zh_Hans": "模型上下文长度"
                          },
                          "placeholder": {
                              "en_US": "Enter your Model context size",
                              "zh_Hans": "在此输入您的模型上下文长度"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "context_size"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Upper bound for max tokens",
                              "zh_Hans": "最大 token 上限"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "text-input",
                          "variable": "max_tokens"
                      },
                      {
                          "default": "false",
                          "label": {
                              "en_US": "Vision support",
                              "zh_Hans": "是否支持 Vision"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Yes",
                                      "zh_Hans": "是"
                                  },
                                  "value": "true"
                              },
                              {
                                  "label": {
                                      "en_US": "No",
                                      "zh_Hans": "否"
                                  },
                                  "value": "false"
                              }
                          ],
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "radio",
                          "variable": "vision_support"
                      },
                      {
                          "default": "false",
                          "label": {
                              "en_US": "Function call support",
                              "zh_Hans": "是否支持函数调用"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Yes",
                                      "zh_Hans": "是"
                                  },
                                  "value": "true"
                              },
                              {
                                  "label": {
                                      "en_US": "No",
                                      "zh_Hans": "否"
                                  },
                                  "value": "false"
                              }
                          ],
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "radio",
                          "variable": "function_call_support"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  }
              },
              "provider": "ollama",
              "supported_model_types": [
                  "llm",
                  "text-embedding"
              ],
              "models": []
          }
      },
      {
          "version": "0.0.29",
          "type": "plugin",
          "author": "langgenius",
          "name": "openai",
          "description": {
              "en_US": "Models provided by OpenAI, such as GPT-3.5-Turbo and GPT-4.",
              "zh_Hans": "OpenAI 提供的模型，例如 GPT-3.5-Turbo 和 GPT-4。"
          },
          "label": {
              "en_US": "OpenAI"
          },
          "created_at": "2024-07-12T08:03:44.658609186Z",
          "icon": "icon_s_en.svg",
          "resource": {
              "memory": 1048576,
              "permission": {
                  "tool": {
                      "enabled": true
                  },
                  "model": {
                      "enabled": true,
                      "llm": true
                  }
              }
          },
          "plugins": {
              "models": [
                  "provider/openai.yaml"
              ]
          },
          "meta": {
              "version": "0.0.1",
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "language": "python",
                  "version": "3.12",
                  "entrypoint": "main"
              }
          },
          "model": {
              "provider": "openai",
              "label": {
                  "en_US": "OpenAI"
              },
              "description": {
                  "en_US": "Models provided by OpenAI, such as GPT-3.5-Turbo and GPT-4.",
                  "zh_Hans": "OpenAI 提供的模型，例如 GPT-3.5-Turbo 和 GPT-4。"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "background": "#E5E7EB",
              "help": {
                  "title": {
                      "en_US": "Get your API Key from OpenAI",
                      "zh_Hans": "从 OpenAI 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://platform.openai.com/account/api-keys"
                  }
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding",
                  "speech2text",
                  "moderation",
                  "tts"
              ],
              "configurate_methods": [
                  "predefined-model",
                  "customizable-model"
              ],
              "model_credential_schema": {
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  },
                  "credential_form_schemas": [
                      {
                          "variable": "openai_api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "type": "secret-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Key",
                              "en_US": "Enter your API Key"
                          }
                      },
                      {
                          "variable": "openai_organization",
                          "label": {
                              "zh_Hans": "组织 ID",
                              "en_US": "Organization"
                          },
                          "type": "text-input",
                          "required": false,
                          "placeholder": {
                              "zh_Hans": "在此输入您的组织 ID",
                              "en_US": "Enter your Organization ID"
                          }
                      },
                      {
                          "variable": "openai_api_base",
                          "label": {
                              "zh_Hans": "API Base",
                              "en_US": "API Base"
                          },
                          "type": "text-input",
                          "required": false,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Base",
                              "en_US": "Enter your API Base"
                          }
                      }
                  ]
              },
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "variable": "openai_api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "type": "secret-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Key",
                              "en_US": "Enter your API Key"
                          }
                      },
                      {
                          "variable": "openai_organization",
                          "label": {
                              "zh_Hans": "组织 ID",
                              "en_US": "Organization"
                          },
                          "type": "text-input",
                          "required": false,
                          "placeholder": {
                              "zh_Hans": "在此输入您的组织 ID",
                              "en_US": "Enter your Organization ID"
                          }
                      },
                      {
                          "variable": "openai_api_base",
                          "label": {
                              "zh_Hans": "API Base",
                              "en_US": "API Base"
                          },
                          "type": "text-input",
                          "required": false,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Base, 如：https://api.openai.com",
                              "en_US": "Enter your API Base, e.g. https://api.openai.com"
                          }
                      }
                  ]
              },
              "models": [
                  {
                      "model": "chatgpt-4o-latest",
                      "label": {
                          "zh_Hans": "chatgpt-4o-latest",
                          "en_US": "chatgpt-4o-latest"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 16384
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "2.50",
                          "output": "10.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-3.5-turbo-0125",
                      "label": {
                          "zh_Hans": "gpt-3.5-turbo-0125",
                          "en_US": "gpt-3.5-turbo-0125"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16385
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.0005",
                          "output": "0.0015",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-3.5-turbo-0613",
                      "label": {
                          "zh_Hans": "gpt-3.5-turbo-0613",
                          "en_US": "gpt-3.5-turbo-0613"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0015",
                          "output": "0.002",
                          "unit": "0.001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "gpt-3.5-turbo-1106",
                      "label": {
                          "zh_Hans": "gpt-3.5-turbo-1106",
                          "en_US": "gpt-3.5-turbo-1106"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16385
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.001",
                          "output": "0.002",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-3.5-turbo-16k-0613",
                      "label": {
                          "zh_Hans": "gpt-3.5-turbo-16k-0613",
                          "en_US": "gpt-3.5-turbo-16k-0613"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16385
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 16385
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.003",
                          "output": "0.004",
                          "unit": "0.001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "gpt-3.5-turbo-16k",
                      "label": {
                          "zh_Hans": "gpt-3.5-turbo-16k",
                          "en_US": "gpt-3.5-turbo-16k"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16385
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 16385
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.003",
                          "output": "0.004",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-3.5-turbo-instruct",
                      "label": {
                          "zh_Hans": "gpt-3.5-turbo-instruct",
                          "en_US": "gpt-3.5-turbo-instruct"
                      },
                      "model_type": "llm",
                      "features": [],
                      "model_properties": {
                          "mode": "completion",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0015",
                          "output": "0.002",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-3.5-turbo",
                      "label": {
                          "zh_Hans": "gpt-3.5-turbo",
                          "en_US": "gpt-3.5-turbo"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16385
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.0005",
                          "output": "0.0015",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4-0125-preview",
                      "label": {
                          "zh_Hans": "gpt-4-0125-preview",
                          "en_US": "gpt-4-0125-preview"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "seed",
                              "label": {
                                  "zh_Hans": "种子",
                                  "en_US": "Seed"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "如果指定，模型将尽最大努力进行确定性采样，使得重复的具有相同种子和参数的请求应该返回相同的结果。不能保证确定性，您应该参考 system_fingerprint 响应参数来监视变化。",
                                  "en_US": "If specified, model will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes in the backend."
                              },
                              "required": false
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.01",
                          "output": "0.03",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4-1106-preview",
                      "label": {
                          "zh_Hans": "gpt-4-1106-preview",
                          "en_US": "gpt-4-1106-preview"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "seed",
                              "label": {
                                  "zh_Hans": "种子",
                                  "en_US": "Seed"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "如果指定，模型将尽最大努力进行确定性采样，使得重复的具有相同种子和参数的请求应该返回相同的结果。不能保证确定性，您应该参考 system_fingerprint 响应参数来监视变化。",
                                  "en_US": "If specified, model will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes in the backend."
                              },
                              "required": false
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.01",
                          "output": "0.03",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4-32k",
                      "label": {
                          "zh_Hans": "gpt-4-32k",
                          "en_US": "gpt-4-32k"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 32768
                          },
                          {
                              "name": "seed",
                              "label": {
                                  "zh_Hans": "种子",
                                  "en_US": "Seed"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "如果指定，模型将尽最大努力进行确定性采样，使得重复的具有相同种子和参数的请求应该返回相同的结果。不能保证确定性，您应该参考 system_fingerprint 响应参数来监视变化。",
                                  "en_US": "If specified, model will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes in the backend."
                              },
                              "required": false
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.06",
                          "output": "0.12",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4-turbo-2024-04-09",
                      "label": {
                          "zh_Hans": "gpt-4-turbo-2024-04-09",
                          "en_US": "gpt-4-turbo-2024-04-09"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "seed",
                              "label": {
                                  "zh_Hans": "种子",
                                  "en_US": "Seed"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "如果指定，模型将尽最大努力进行确定性采样，使得重复的具有相同种子和参数的请求应该返回相同的结果。不能保证确定性，您应该参考 system_fingerprint 响应参数来监视变化。",
                                  "en_US": "If specified, model will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes in the backend."
                              },
                              "required": false
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.01",
                          "output": "0.03",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4-turbo-preview",
                      "label": {
                          "zh_Hans": "gpt-4-turbo-preview",
                          "en_US": "gpt-4-turbo-preview"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "seed",
                              "label": {
                                  "zh_Hans": "种子",
                                  "en_US": "Seed"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "如果指定，模型将尽最大努力进行确定性采样，使得重复的具有相同种子和参数的请求应该返回相同的结果。不能保证确定性，您应该参考 system_fingerprint 响应参数来监视变化。",
                                  "en_US": "If specified, model will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes in the backend."
                              },
                              "required": false
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.01",
                          "output": "0.03",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4-turbo",
                      "label": {
                          "zh_Hans": "gpt-4-turbo",
                          "en_US": "gpt-4-turbo"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "seed",
                              "label": {
                                  "zh_Hans": "种子",
                                  "en_US": "Seed"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "如果指定，模型将尽最大努力进行确定性采样，使得重复的具有相同种子和参数的请求应该返回相同的结果。不能保证确定性，您应该参考 system_fingerprint 响应参数来监视变化。",
                                  "en_US": "If specified, model will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes in the backend."
                              },
                              "required": false
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.01",
                          "output": "0.03",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4-vision-preview",
                      "label": {
                          "zh_Hans": "gpt-4-vision-preview",
                          "en_US": "gpt-4-vision-preview"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "seed",
                              "label": {
                                  "zh_Hans": "种子",
                                  "en_US": "Seed"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "如果指定，模型将尽最大努力进行确定性采样，使得重复的具有相同种子和参数的请求应该返回相同的结果。不能保证确定性，您应该参考 system_fingerprint 响应参数来监视变化。",
                                  "en_US": "If specified, model will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes in the backend."
                              },
                              "required": false
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.01",
                          "output": "0.03",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4.1-2025-04-14",
                      "label": {
                          "zh_Hans": "gpt-4.1-2025-04-14",
                          "en_US": "gpt-4.1-2025-04-14"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1047576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 32768
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "2.00",
                          "output": "8.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4.1-mini-2025-04-14",
                      "label": {
                          "zh_Hans": "gpt-4.1-mini-2025-04-14",
                          "en_US": "gpt-4.1-mini-2025-04-14"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1047576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 32768
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.40",
                          "output": "1.60",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4.1-mini",
                      "label": {
                          "zh_Hans": "gpt-4.1-mini",
                          "en_US": "gpt-4.1-mini"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1047576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 32768
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.40",
                          "output": "1.60",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4.1-nano-2025-04-14",
                      "label": {
                          "zh_Hans": "gpt-4.1-nano-2025-04-14",
                          "en_US": "gpt-4.1-nano-2025-04-14"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1047576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 32768
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.10",
                          "output": "0.40",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4.1-nano",
                      "label": {
                          "zh_Hans": "gpt-4.1-nano",
                          "en_US": "gpt-4.1-nano"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1047576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 32768
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.10",
                          "output": "0.40",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4.1",
                      "label": {
                          "zh_Hans": "gpt-4.1",
                          "en_US": "gpt-4.1"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1047576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 32768
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "2.00",
                          "output": "8.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4",
                      "label": {
                          "zh_Hans": "gpt-4",
                          "en_US": "gpt-4"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "seed",
                              "label": {
                                  "zh_Hans": "种子",
                                  "en_US": "Seed"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "如果指定，模型将尽最大努力进行确定性采样，使得重复的具有相同种子和参数的请求应该返回相同的结果。不能保证确定性，您应该参考 system_fingerprint 响应参数来监视变化。",
                                  "en_US": "If specified, model will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes in the backend."
                              },
                              "required": false
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.03",
                          "output": "0.06",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4o-2024-05-13",
                      "label": {
                          "zh_Hans": "gpt-4o-2024-05-13",
                          "en_US": "gpt-4o-2024-05-13"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 2048,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "5.00",
                          "output": "15.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4o-2024-08-06",
                      "label": {
                          "zh_Hans": "gpt-4o-2024-08-06",
                          "en_US": "gpt-4o-2024-08-06"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 16384
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "2.50",
                          "output": "10.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4o-2024-11-20",
                      "label": {
                          "zh_Hans": "gpt-4o-2024-11-20",
                          "en_US": "gpt-4o-2024-11-20"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 16384
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "2.50",
                          "output": "10.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4o-audio-preview-2025-06-03",
                      "label": {
                          "zh_Hans": "gpt-4o-audio-preview-2025-06-03",
                          "en_US": "gpt-4o-audio-preview-2025-06-03"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 16384
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "5.00",
                          "output": "15.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4o-audio-preview",
                      "label": {
                          "zh_Hans": "gpt-4o-audio-preview",
                          "en_US": "gpt-4o-audio-preview"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 16384
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "5.00",
                          "output": "15.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4o-mini-2024-07-18",
                      "label": {
                          "zh_Hans": "gpt-4o-mini-2024-07-18",
                          "en_US": "gpt-4o-mini-2024-07-18"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 16384
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.15",
                          "output": "0.60",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4o-mini",
                      "label": {
                          "zh_Hans": "gpt-4o-mini",
                          "en_US": "gpt-4o-mini"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 16384
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.15",
                          "output": "0.60",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4o",
                      "label": {
                          "zh_Hans": "gpt-4o",
                          "en_US": "gpt-4o"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 16384
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "5.00",
                          "output": "15.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "o1-mini-2024-09-12",
                      "label": {
                          "zh_Hans": "o1-mini-2024-09-12",
                          "en_US": "o1-mini-2024-09-12"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 65536,
                              "min": 1,
                              "max": 65536
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "3.00",
                          "output": "12.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "o1-mini",
                      "label": {
                          "zh_Hans": "o1-mini",
                          "en_US": "o1-mini"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 65536,
                              "min": 1,
                              "max": 65536
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "3.00",
                          "output": "12.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "o1-preview-2024-09-12",
                      "label": {
                          "zh_Hans": "o1-preview-2024-09-12",
                          "en_US": "o1-preview-2024-09-12"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 32768,
                              "min": 1,
                              "max": 32768
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "15.00",
                          "output": "60.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "o1-preview",
                      "label": {
                          "zh_Hans": "o1-preview",
                          "en_US": "o1-preview"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 32768,
                              "min": 1,
                              "max": 32768
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "15.00",
                          "output": "60.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "o1",
                      "label": {
                          "zh_Hans": "o1",
                          "en_US": "o1"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 50000,
                              "min": 1,
                              "max": 50000
                          },
                          {
                              "name": "reasoning_effort",
                              "label": {
                                  "zh_Hans": "推理工作",
                                  "en_US": "reasoning_effort"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "限制推理模型的推理工作",
                                  "en_US": "constrains effort on reasoning for reasoning models"
                              },
                              "required": false,
                              "options": [
                                  "low",
                                  "medium",
                                  "high"
                              ]
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "15.00",
                          "output": "60.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "o3-2025-04-16",
                      "label": {
                          "zh_Hans": "o3-2025-04-16",
                          "en_US": "o3-2025-04-16"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 100000,
                              "min": 1,
                              "max": 100000
                          },
                          {
                              "name": "reasoning_effort",
                              "label": {
                                  "zh_Hans": "推理工作",
                                  "en_US": "reasoning_effort"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "限制推理模型的推理工作",
                                  "en_US": "constrains effort on reasoning for reasoning models"
                              },
                              "required": false,
                              "options": [
                                  "low",
                                  "medium",
                                  "high"
                              ]
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "2.0",
                          "output": "8.0",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "o3-mini-2025-01-31",
                      "label": {
                          "zh_Hans": "o3-mini-2025-01-31",
                          "en_US": "o3-mini-2025-01-31"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 100000,
                              "min": 1,
                              "max": 100000
                          },
                          {
                              "name": "reasoning_effort",
                              "label": {
                                  "zh_Hans": "推理工作",
                                  "en_US": "reasoning_effort"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "限制推理模型的推理工作",
                                  "en_US": "constrains effort on reasoning for reasoning models"
                              },
                              "required": false,
                              "options": [
                                  "low",
                                  "medium",
                                  "high"
                              ]
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "1.10",
                          "output": "4.40",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "o3-mini",
                      "label": {
                          "zh_Hans": "o3-mini",
                          "en_US": "o3-mini"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 100000,
                              "min": 1,
                              "max": 100000
                          },
                          {
                              "name": "reasoning_effort",
                              "label": {
                                  "zh_Hans": "推理工作",
                                  "en_US": "reasoning_effort"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "限制推理模型的推理工作",
                                  "en_US": "constrains effort on reasoning for reasoning models"
                              },
                              "required": false,
                              "options": [
                                  "low",
                                  "medium",
                                  "high"
                              ]
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "1.10",
                          "output": "4.40",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "o3-pro-2025-06-10",
                      "label": {
                          "zh_Hans": "o3-pro-2025-06-10",
                          "en_US": "o3-pro-2025-06-10"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 100000,
                              "min": 1,
                              "max": 100000
                          },
                          {
                              "name": "reasoning_effort",
                              "label": {
                                  "zh_Hans": "推理工作",
                                  "en_US": "reasoning_effort"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "限制推理模型的推理工作",
                                  "en_US": "constrains effort on reasoning for reasoning models"
                              },
                              "required": false,
                              "options": [
                                  "low",
                                  "medium",
                                  "high"
                              ]
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "20.0",
                          "output": "80.0",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "o3-pro",
                      "label": {
                          "zh_Hans": "o3-pro",
                          "en_US": "o3-pro"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 100000,
                              "min": 1,
                              "max": 100000
                          },
                          {
                              "name": "reasoning_effort",
                              "label": {
                                  "zh_Hans": "推理工作",
                                  "en_US": "reasoning_effort"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "限制推理模型的推理工作",
                                  "en_US": "constrains effort on reasoning for reasoning models"
                              },
                              "required": false,
                              "options": [
                                  "low",
                                  "medium",
                                  "high"
                              ]
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "20.0",
                          "output": "80.0",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "o3",
                      "label": {
                          "zh_Hans": "o3",
                          "en_US": "o3"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 100000,
                              "min": 1,
                              "max": 100000
                          },
                          {
                              "name": "reasoning_effort",
                              "label": {
                                  "zh_Hans": "推理工作",
                                  "en_US": "reasoning_effort"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "限制推理模型的推理工作",
                                  "en_US": "constrains effort on reasoning for reasoning models"
                              },
                              "required": false,
                              "options": [
                                  "low",
                                  "medium",
                                  "high"
                              ]
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "2.0",
                          "output": "8.0",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "o4-mini-2025-04-16",
                      "label": {
                          "zh_Hans": "o4-mini-2025-04-16",
                          "en_US": "o4-mini-2025-04-16"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 100000,
                              "min": 1,
                              "max": 100000
                          },
                          {
                              "name": "reasoning_effort",
                              "label": {
                                  "zh_Hans": "推理工作",
                                  "en_US": "reasoning_effort"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "限制推理模型的推理工作",
                                  "en_US": "constrains effort on reasoning for reasoning models"
                              },
                              "required": false,
                              "options": [
                                  "low",
                                  "medium",
                                  "high"
                              ]
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "1.10",
                          "output": "4.40",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "o4-mini",
                      "label": {
                          "zh_Hans": "o4-mini",
                          "en_US": "o4-mini"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 100000,
                              "min": 1,
                              "max": 100000
                          },
                          {
                              "name": "reasoning_effort",
                              "label": {
                                  "zh_Hans": "推理工作",
                                  "en_US": "reasoning_effort"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "限制推理模型的推理工作",
                                  "en_US": "constrains effort on reasoning for reasoning models"
                              },
                              "required": false,
                              "options": [
                                  "low",
                                  "medium",
                                  "high"
                              ]
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "1.10",
                          "output": "4.40",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "text-davinci-003",
                      "label": {
                          "zh_Hans": "text-davinci-003",
                          "en_US": "text-davinci-003"
                      },
                      "model_type": "llm",
                      "features": [],
                      "model_properties": {
                          "mode": "completion",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.001",
                          "output": "0.002",
                          "unit": "0.001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "text-embedding-3-large",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8191,
                          "max_chunks": 32
                      },
                      "pricing": {
                          "input": "0.00013",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "text-embedding-3-small",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8191,
                          "max_chunks": 32
                      },
                      "pricing": {
                          "input": "0.00002",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "text-embedding-ada-002",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8097,
                          "max_chunks": 32
                      },
                      "pricing": {
                          "input": "0.0001",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4o-mini-tts",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "alloy",
                          "voices": [
                              {
                                  "mode": "alloy",
                                  "name": "Alloy",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "ash",
                                  "name": "Ash",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "ballad",
                                  "name": "Ballad",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "coral",
                                  "name": "Coral",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "echo",
                                  "name": "Echo",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "fable",
                                  "name": "Fable",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "onyx",
                                  "name": "Onyx",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "nova",
                                  "name": "Nova",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "sage",
                                  "name": "Sage",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "shimmer",
                                  "name": "Shimmer",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "verse",
                                  "name": "Verse",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              }
                          ],
                          "word_limit": 3500,
                          "audio_type": "mp3",
                          "max_workers": 5
                      },
                      "pricing": {
                          "input": "0.012",
                          "output": "0",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "tts-1-hd",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "alloy",
                          "voices": [
                              {
                                  "mode": "alloy",
                                  "name": "Alloy",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "ash",
                                  "name": "Ash",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "ballad",
                                  "name": "Ballad",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "coral",
                                  "name": "Coral",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "echo",
                                  "name": "Echo",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "fable",
                                  "name": "Fable",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "onyx",
                                  "name": "Onyx",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "nova",
                                  "name": "Nova",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "sage",
                                  "name": "Sage",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "shimmer",
                                  "name": "Shimmer",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "verse",
                                  "name": "Verse",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              }
                          ],
                          "word_limit": 3500,
                          "audio_type": "mp3",
                          "max_workers": 5
                      },
                      "pricing": {
                          "input": "0.03",
                          "output": "0",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "tts-1",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "alloy",
                          "voices": [
                              {
                                  "mode": "alloy",
                                  "name": "Alloy",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "ash",
                                  "name": "Ash",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "ballad",
                                  "name": "Ballad",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "coral",
                                  "name": "Coral",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "echo",
                                  "name": "Echo",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "fable",
                                  "name": "Fable",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "onyx",
                                  "name": "Onyx",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "nova",
                                  "name": "Nova",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "sage",
                                  "name": "Sage",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "shimmer",
                                  "name": "Shimmer",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "verse",
                                  "name": "Verse",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              }
                          ],
                          "word_limit": 3500,
                          "audio_type": "mp3",
                          "max_workers": 5
                      },
                      "pricing": {
                          "input": "0.015",
                          "output": "0",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "whisper-1",
                      "model_type": "speech2text",
                      "model_properties": {
                          "file_upload_limit": 25,
                          "supported_file_extensions": "flac,mp3,mp4,mpeg,mpga,m4a,ogg,wav,webm"
                      }
                  },
                  {
                      "model": "text-moderation-stable",
                      "model_type": "moderation",
                      "model_properties": {
                          "max_chunks": 32,
                          "max_characters_per_chunk": 2000
                      }
                  }
              ],
              "extra": {
                  "python": {
                      "provider_source": "provider/openai.py",
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/text_embedding/text_embedding.py",
                          "models/speech2text/speech2text.py",
                          "models/moderation/moderation.py",
                          "models/tts/tts.py"
                      ]
                  }
              }
          }
      },
      {
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "tongyi",
          "author": "ssrag",
          "label": {
              "en_US": "TONGYI",
              "zh_Hans": "通义千问"
          },
          "description": {
              "en_US": "TONGYI",
              "zh_Hans": "通义千问"
          },
          "icon": "icon_s_en.png",
          "plugins": {
              "models": [
                  "provider/tongyi.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": false
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.28",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "model": {
              "background": "#EFF1FE",
              "configurate_methods": [
                  "predefined-model",
                  "customizable-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/rerank/rerank.py",
                          "models/text_embedding/text_embedding.py",
                          "models/tts/tts.py",
                          "models/speech2text/speech2text.py"
                      ],
                      "provider_source": "provider/tongyi.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API key from AliCloud",
                      "zh_Hans": "从阿里云百炼获取 API Key"
                  },
                  "url": {
                      "en_US": "https://bailian.console.aliyun.com/?apiKey=1#/api-key"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.png",
                  "zh_Hans": "icon_l_zh.png"
              },
              "icon_small": {
                  "en_US": "icon_s_en.png"
              },
              "label": {
                  "en_US": "TONGYI",
                  "zh_Hans": "通义千问"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "dashscope_api_key"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Model context size",
                              "zh_Hans": "模型上下文长度"
                          },
                          "placeholder": {
                              "en_US": "Enter your Model context size",
                              "zh_Hans": "在此输入您的模型上下文长度"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "context_size"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Upper bound for max tokens",
                              "zh_Hans": "最大 token 上限"
                          },
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "text-input",
                          "variable": "max_tokens"
                      },
                      {
                          "default": "no_call",
                          "label": {
                              "en_US": "Function calling"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  },
                                  "value": "no_call"
                              },
                              {
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  },
                                  "value": "function_call"
                              }
                          ],
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "select",
                          "variable": "function_calling_type"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  }
              },
              "models": [
                  {
                      "model": "deepseek-r1-distill-qwen-14b",
                      "label": {
                          "zh_Hans": "DeepSeek-R1-Distill-Qwen-14B",
                          "en_US": "DeepSeek-R1-Distill-Qwen-14B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.001",
                          "output": "0.003",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "deepseek-r1-distill-qwen-32b",
                      "label": {
                          "zh_Hans": "DeepSeek-R1-Distill-Qwen-32B",
                          "en_US": "DeepSeek-R1-Distill-Qwen-32B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.002",
                          "output": "0.006",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "deepseek-r1",
                      "label": {
                          "zh_Hans": "DeepSeek-R1",
                          "en_US": "DeepSeek-R1"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.016",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "deepseek-v3",
                      "label": {
                          "zh_Hans": "DeepSeek-V3",
                          "en_US": "DeepSeek-V3"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 4096,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.002",
                          "output": "0.008",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "farui-plus",
                      "label": {
                          "en_US": "farui-plus"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 12288
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.02",
                          "output": "0.02",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qvq-max-latest",
                      "label": {
                          "en_US": "qvq-max-latest"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.0016",
                          "output": "0.004",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qvq-max",
                      "label": {
                          "en_US": "qvq-max"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.0016",
                          "output": "0.004",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-coder-turbo-0919",
                      "label": {
                          "en_US": "qwen-coder-turbo-0919"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.002",
                          "output": "0.006",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-coder-turbo-latest",
                      "label": {
                          "en_US": "qwen-coder-turbo-latest"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.002",
                          "output": "0.006",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-coder-turbo",
                      "label": {
                          "en_US": "qwen-coder-turbo"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.002",
                          "output": "0.006",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-long",
                      "label": {
                          "en_US": "qwen-long"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "document"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 10000000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 6000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0005",
                          "output": "0.002",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-math-plus-0816",
                      "label": {
                          "en_US": "qwen-math-plus-0816"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 3072,
                              "min": 1,
                              "max": 3072,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.012",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-math-plus-0919",
                      "label": {
                          "en_US": "qwen-math-plus-0919"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 3072,
                              "min": 1,
                              "max": 3072,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.012",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-math-plus-latest",
                      "label": {
                          "en_US": "qwen-math-plus-latest"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 3072,
                              "min": 1,
                              "max": 3072,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.012",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-math-plus",
                      "label": {
                          "en_US": "qwen-math-plus"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 3072,
                              "min": 1,
                              "max": 3072,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.012",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-math-turbo-0919",
                      "label": {
                          "en_US": "qwen-math-turbo-0919"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 3072,
                              "min": 1,
                              "max": 3072,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.002",
                          "output": "0.006",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-math-turbo-latest",
                      "label": {
                          "en_US": "qwen-math-turbo-latest"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 3072,
                              "min": 1,
                              "max": 3072,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.002",
                          "output": "0.006",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-math-turbo",
                      "label": {
                          "en_US": "qwen-math-turbo"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 3072,
                              "min": 1,
                              "max": 3072,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.002",
                          "output": "0.006",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-max-0107",
                      "label": {
                          "en_US": "qwen-max-0107"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.04",
                          "output": "0.12",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-max-0125",
                      "label": {
                          "en_US": "qwen-max-0125"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0024",
                          "output": "0.0096",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-max-0403",
                      "label": {
                          "en_US": "qwen-max-0403"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.04",
                          "output": "0.12",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-max-0428",
                      "label": {
                          "en_US": "qwen-max-0428"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.04",
                          "output": "0.12",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-max-0919",
                      "label": {
                          "en_US": "qwen-max-0919"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.02",
                          "output": "0.06",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-max-1201",
                      "label": {
                          "en_US": "qwen-max-1201"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.04",
                          "output": "0.12",
                          "unit": "0.001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "qwen-max-latest",
                      "label": {
                          "en_US": "qwen-max-latest"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0024",
                          "output": "0.0096",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-max-longcontext",
                      "label": {
                          "en_US": "qwen-max-longcontext"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8000,
                              "min": 1,
                              "max": 8000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.04",
                          "output": "0.12",
                          "unit": "0.001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "qwen-max",
                      "label": {
                          "en_US": "qwen-max"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0024",
                          "output": "0.0096",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-plus-0112",
                      "label": {
                          "en_US": "qwen-plus-0112"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0008",
                          "output": "0.002",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-plus-0125",
                      "label": {
                          "en_US": "qwen-plus-0125"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0008",
                          "output": "0.002",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-plus-0206",
                      "label": {
                          "en_US": "qwen-plus-0206"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8000,
                              "min": 1,
                              "max": 8000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.012",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-plus-0624",
                      "label": {
                          "en_US": "qwen-plus-0624"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8000,
                              "min": 1,
                              "max": 8000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.012",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-plus-0723",
                      "label": {
                          "en_US": "qwen-plus-0723"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8000,
                              "min": 1,
                              "max": 8000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.012",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-plus-0806",
                      "label": {
                          "en_US": "qwen-plus-0806"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.012",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-plus-0919",
                      "label": {
                          "en_US": "qwen-plus-0919"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0008",
                          "output": "0.002",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-plus-1125",
                      "label": {
                          "en_US": "qwen-plus-1125"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0008",
                          "output": "0.002",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-plus-1127",
                      "label": {
                          "en_US": "qwen-plus-1127"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0008",
                          "output": "0.002",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-plus-1220",
                      "label": {
                          "en_US": "qwen-plus-1220"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0008",
                          "output": "0.002",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-plus-2025-04-28",
                      "label": {
                          "en_US": "qwen-plus-2025-04-28(Qwen3)"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0008",
                          "output": "0.002",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-plus-chat",
                      "label": {
                          "en_US": "qwen-plus-chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.012",
                          "unit": "0.001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "qwen-plus-latest",
                      "label": {
                          "en_US": "qwen-plus-latest(Qwen3)"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 2048,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0008",
                          "output": "0.002",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-plus",
                      "label": {
                          "en_US": "qwen-plus"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0008",
                          "output": "0.002",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-turbo-0206",
                      "label": {
                          "en_US": "qwen-turbo-0206"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.002",
                          "output": "0.006",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-turbo-0624",
                      "label": {
                          "en_US": "qwen-turbo-0624"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.002",
                          "output": "0.006",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-turbo-0919",
                      "label": {
                          "en_US": "qwen-turbo-0919"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0003",
                          "output": "0.0006",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-turbo-2025-04-28",
                      "label": {
                          "en_US": "qwen-turbo-2025-04-28(Qwen3)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0003",
                          "output": "0.0006",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-turbo-chat",
                      "label": {
                          "en_US": "qwen-turbo-chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 1500,
                              "min": 1,
                              "max": 1500,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.002",
                          "output": "0.006",
                          "unit": "0.001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "qwen-turbo-latest",
                      "label": {
                          "en_US": "qwen-turbo-latest(Qwen3)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1000000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0003",
                          "output": "0.0006",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-turbo",
                      "label": {
                          "en_US": "qwen-turbo"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0006",
                          "output": "0.0003",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-vl-max-0201",
                      "label": {
                          "en_US": "qwen-vl-max-0201"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision",
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.02",
                          "output": "0.02",
                          "unit": "0.001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "qwen-vl-max-0809",
                      "label": {
                          "en_US": "qwen-vl-max-0809"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision",
                          "agent-thought",
                          "video"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "required": false,
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.02",
                          "output": "0.02",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-vl-max-2025-01-25",
                      "label": {
                          "en_US": "qwen-vl-max-2025-01-25"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision",
                          "agent-thought",
                          "video"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "required": false,
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 4096,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.003",
                          "output": "0.009",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-vl-max-latest",
                      "label": {
                          "en_US": "qwen-vl-max-latest"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision",
                          "agent-thought",
                          "video"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "required": false,
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 4096,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.003",
                          "output": "0.009",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-vl-max",
                      "label": {
                          "en_US": "qwen-vl-max"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision",
                          "agent-thought",
                          "video"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "required": false,
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.02",
                          "output": "0.02",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-vl-plus-0809",
                      "label": {
                          "en_US": "qwen-vl-plus-0809"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision",
                          "agent-thought",
                          "video"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "required": false,
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.008",
                          "output": "0.008",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-vl-plus-2025-01-02",
                      "label": {
                          "en_US": "qwen-vl-plus-2025-01-02"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision",
                          "agent-thought",
                          "video"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "required": false,
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 1024,
                              "min": 1,
                              "max": 2048,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0015",
                          "output": "0.0045",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-vl-plus-2025-01-25",
                      "label": {
                          "en_US": "qwen-vl-plus-2025-01-25"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision",
                          "agent-thought",
                          "video"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "required": false,
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 4096,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.003",
                          "output": "0.009",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-vl-plus-latest",
                      "label": {
                          "en_US": "qwen-vl-plus-latest"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision",
                          "agent-thought",
                          "video"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "required": false,
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 4096,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.003",
                          "output": "0.009",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen-vl-plus",
                      "label": {
                          "en_US": "qwen-vl-plus"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision",
                          "agent-thought",
                          "video"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "required": false,
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.008",
                          "output": "0.008",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2-math-1.5b-instruct",
                      "label": {
                          "en_US": "qwen2-math-1.5b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.012",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2-math-72b-instruct",
                      "label": {
                          "en_US": "qwen2-math-72b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.012",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2-math-7b-instruct",
                      "label": {
                          "en_US": "qwen2-math-7b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.012",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2.5-0.5b-instruct",
                      "label": {
                          "en_US": "qwen2.5-0.5b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2.5-1.5b-instruct",
                      "label": {
                          "en_US": "qwen2.5-1.5b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2.5-14b-instruct-1m",
                      "label": {
                          "en_US": "qwen2.5-14b-instruct-1m"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1000000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.001",
                          "output": "0.003",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2.5-14b-instruct",
                      "label": {
                          "en_US": "qwen2.5-14b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.001",
                          "output": "0.003",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2.5-32b-instruct",
                      "label": {
                          "en_US": "qwen2.5-32b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.002",
                          "output": "0.006",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2.5-3b-instruct",
                      "label": {
                          "en_US": "qwen2.5-3b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0003",
                          "output": "0.0009",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2.5-72b-instruct",
                      "label": {
                          "en_US": "qwen2.5-72b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.012",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2.5-7b-instruct-1m",
                      "label": {
                          "en_US": "qwen2.5-7b-instruct-1m"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1000000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0005",
                          "output": "0.001",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2.5-7b-instruct",
                      "label": {
                          "en_US": "qwen2.5-7b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0005",
                          "output": "0.001",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2.5-coder-7b-instruct",
                      "label": {
                          "en_US": "qwen2.5-coder-7b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.001",
                          "output": "0.002",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2.5-vl-3b-instruct",
                      "label": {
                          "en_US": "qwen2.5-vl-3b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision",
                          "agent-thought",
                          "video"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0012",
                          "output": "0.0036",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2.5-vl-72b-instruct",
                      "label": {
                          "en_US": "qwen2.5-vl-72b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision",
                          "agent-thought",
                          "video"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.016",
                          "output": "0.048",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2.5-vl-7b-instruct",
                      "label": {
                          "en_US": "qwen2.5-vl-7b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision",
                          "agent-thought",
                          "video"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.002",
                          "output": "0.005",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen3-0.6b",
                      "label": {
                          "en_US": "qwen3-0.6b"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected, the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0003",
                          "output": "0.0012",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen3-1.7b",
                      "label": {
                          "en_US": "qwen3-1.7b"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected, the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0003",
                          "output": "0.0012",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen3-14b",
                      "label": {
                          "en_US": "qwen3-14b"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected, the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.001",
                          "output": "0.004",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen3-235b-a22b",
                      "label": {
                          "en_US": "qwen3-235b-a22b"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected, the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.012",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen3-30b-a3b",
                      "label": {
                          "en_US": "qwen3-30b-a3b"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected, the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0015",
                          "output": "0.006",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen3-32b",
                      "label": {
                          "en_US": "qwen3-32b"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected, the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.002",
                          "output": "0.008",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen3-4b",
                      "label": {
                          "en_US": "qwen3-4b"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected, the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0003",
                          "output": "0.0012",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen3-8b",
                      "label": {
                          "en_US": "qwen3-8b"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected, the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0005",
                          "output": "0.002",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwq-32b",
                      "label": {
                          "en_US": "qwq-32b"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.012",
                          "output": "0.036",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwq-plus-0305",
                      "label": {
                          "en_US": "qwq-plus-0305"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.0016",
                          "output": "0.004",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwq-plus",
                      "label": {
                          "en_US": "qwq-plus"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.0016",
                          "output": "0.004",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "gte-rerank-v2",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 4000
                      }
                  },
                  {
                      "model": "gte-rerank",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 4000
                      }
                  },
                  {
                      "model": "paraformer-realtime-v1",
                      "model_type": "speech2text",
                      "model_properties": {
                          "file_upload_limit": 100,
                          "supported_file_extensions": "aac,amr,avi,flac,flv,m4a,mkv,mov,mp3,mp4,mpeg,ogg,opus,wav,webm,wma,wmv"
                      },
                      "pricing": {
                          "input": "0.00024",
                          "unit": "0.00001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "paraformer-realtime-v2",
                      "model_type": "speech2text",
                      "model_properties": {
                          "file_upload_limit": 100,
                          "supported_file_extensions": "aac,amr,avi,flac,flv,m4a,mkv,mov,mp3,mp4,mpeg,ogg,opus,wav,webm,wma,wmv"
                      },
                      "pricing": {
                          "input": "0.00024",
                          "unit": "0.00001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "text-embedding-v1",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 2048,
                          "max_chunks": 25
                      },
                      "pricing": {
                          "input": "0.0007",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "text-embedding-v2",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 2048,
                          "max_chunks": 25
                      },
                      "pricing": {
                          "input": "0.0007",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "text-embedding-v3",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 10
                      },
                      "pricing": {
                          "input": "0.0007",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "text-embedding-v4",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 10
                      },
                      "pricing": {
                          "input": "0.0005",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "tts-1",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "sambert-zhiru-v1",
                          "voices": [
                              {
                                  "mode": "sambert-zhinan-v1",
                                  "name": "知楠（广告男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhiqi-v1",
                                  "name": "知琪（温柔女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhichu-v1",
                                  "name": "知厨（新闻播报）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhide-v1",
                                  "name": "知德（新闻男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhijia-v1",
                                  "name": "知佳（标准女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhiru-v1",
                                  "name": "知茹（新闻女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhiqian-v1",
                                  "name": "知倩（配音解说、新闻播报）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhixiang-v1",
                                  "name": "知祥（配音解说）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhiwei-v1",
                                  "name": "知薇（萝莉女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhihao-v1",
                                  "name": "知浩（咨询男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhijing-v1",
                                  "name": "知婧（严厉女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhiming-v1",
                                  "name": "知茗（诙谐男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhimo-v1",
                                  "name": "知墨（情感男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhina-v1",
                                  "name": "知娜（浙普女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhishu-v1",
                                  "name": "知树（资讯男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhistella-v1",
                                  "name": "知莎（知性女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhiting-v1",
                                  "name": "知婷（电台女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhixiao-v1",
                                  "name": "知笑（资讯女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhiya-v1",
                                  "name": "知雅（严厉女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhiye-v1",
                                  "name": "知晔（青年男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhiying-v1",
                                  "name": "知颖（软萌童声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhiyuan-v1",
                                  "name": "知媛（知心姐姐）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhigui-v1",
                                  "name": "知柜（直播女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhishuo-v1",
                                  "name": "知硕（自然男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhimiao-emo-v1",
                                  "name": "知妙（多种情感女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhimao-v1",
                                  "name": "知猫（直播女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhilun-v1",
                                  "name": "知伦（悬疑解说）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhifei-v1",
                                  "name": "知飞（激昂解说）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-zhida-v1",
                                  "name": "知达（标准男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-camila-v1",
                                  "name": "Camila（西班牙语女声）",
                                  "language": [
                                      "es-ES"
                                  ]
                              },
                              {
                                  "mode": "sambert-perla-v1",
                                  "name": "Perla（意大利语女声）",
                                  "language": [
                                      "it-IT"
                                  ]
                              },
                              {
                                  "mode": "sambert-indah-v1",
                                  "name": "Indah（印尼语女声）",
                                  "language": [
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "sambert-clara-v1",
                                  "name": "Clara（法语女声）",
                                  "language": [
                                      "fr-FR"
                                  ]
                              },
                              {
                                  "mode": "sambert-hanna-v1",
                                  "name": "Hanna（德语女声）",
                                  "language": [
                                      "de-DE"
                                  ]
                              },
                              {
                                  "mode": "sambert-beth-v1",
                                  "name": "Beth（咨询女声）",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-betty-v1",
                                  "name": "Betty（客服女声）",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-cally-v1",
                                  "name": "Cally（自然女声）",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-cindy-v1",
                                  "name": "Cindy（对话女声）",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-eva-v1",
                                  "name": "Eva（陪伴女声）",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-donna-v1",
                                  "name": "Donna（教育女声）",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-brian-v1",
                                  "name": "Brian（客服男声）",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "sambert-waan-v1",
                                  "name": "Waan（泰语女声）",
                                  "language": [
                                      "th-TH"
                                  ]
                              }
                          ],
                          "word_limit": 7000,
                          "audio_type": "mp3",
                          "max_workers": 5
                      },
                      "pricing": {
                          "input": "1",
                          "output": "0",
                          "unit": "0.0001",
                          "currency": "RMB"
                      }
                  }
              ],
              "provider": "tongyi",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "dashscope_api_key"
                      },
                      {
                          "label": {
                              "en_US": "Use International Endpoint",
                              "zh_Hans": "使用国际端点"
                          },
                          "type": "radio",
                          "required": true,
                          "default": "false",
                          "variable": "use_international_endpoint",
                          "options": [
                              {
                                  "label": {
                                      "en_US": "True",
                                      "zh_Hans": "是"
                                  },
                                  "value": "true"
                              },
                              {
                                  "label": {
                                      "en_US": "False",
                                      "zh_Hans": "否"
                                  },
                                  "value": "false"
                              }
                          ]
                      }
                  ]
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding",
                  "rerank",
                  "speech2text",
                  "tts"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "Models provided by deepseek, such as deepseek-chat、deepseek-coder.",
              "zh_Hans": "深度求索提供的模型，例如 deepseek-chat、deepseek-coder 。"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "DeepSeek",
              "zh_Hans": "深度求索"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "deepseek",
          "plugins": {
              "models": [
                  "provider/deepseek.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.6",
          "model": {
              "background": "#c0cdff",
              "configurate_methods": [
                  "predefined-model"
              ],
              "description": {
                  "en_US": "Models provided by deepseek, such as deepseek-reasoner、deepseek-chat、deepseek-coder.",
                  "zh_Hans": "深度求索提供的模型，例如 deepseek-reasoner、deepseek-chat、deepseek-coder 。"
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py"
                      ],
                      "provider_source": "provider/deepseek.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API Key from deepseek",
                      "zh_Hans": "从深度求索获取 API Key"
                  },
                  "url": {
                      "en_US": "https://platform.deepseek.com/api_keys"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "deepseek",
                  "zh_Hans": "深度求索"
              },
              "models": [
                  {
                      "model": "deepseek-chat",
                      "label": {
                          "zh_Hans": "deepseek-chat",
                          "en_US": "deepseek-chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 1,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的多样性和随机性。数值越小，越严谨；数值越大，越发散。",
                                  "en_US": "Control the diversity and randomness of generated results. The smaller the value, the more rigorous it is; the larger the value, the more divergent it is."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 4096,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 1,
                              "min": 0.01,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的随机性。数值越小，随机性越弱；数值越大，随机性越强。一般而言，top_p 和 temperature 两个参数选择一个进行调整即可。",
                                  "en_US": "Control the randomness of generated results. The smaller the value, the weaker the randomness; the larger the value, the stronger the randomness. Generally speaking, you can adjust one of the two parameters top_p and temperature."
                              }
                          },
                          {
                              "name": "logprobs",
                              "label": {
                                  "en_US": "Logprobs"
                              },
                              "help": {
                                  "zh_Hans": "是否返回所输出 token 的对数概率。如果为 true，则在 message 的 content 中返回每个输出 token 的对数概率。",
                                  "en_US": "Whether to return the log probability of the output token. If true, returns the log probability of each output token in the content of message ."
                              },
                              "type": "boolean"
                          },
                          {
                              "name": "top_logprobs",
                              "label": {
                                  "en_US": "Top Logprobs"
                              },
                              "type": "int",
                              "default": 0,
                              "min": 0,
                              "max": 20,
                              "help": {
                                  "zh_Hans": "一个介于 0 到 20 之间的整数 N，指定每个输出位置返回输出概率 top N 的 token，且返回这些 token 的对数概率。指定此参数时，logprobs 必须为 true。",
                                  "en_US": "An integer N between 0 and 20, specifying that each output position returns the top N tokens with output probability, and returns the logarithmic probability of these tokens. When specifying this parameter, logprobs must be true."
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "default": 0,
                              "min": -2.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "介于 -2.0 和 2.0 之间的数字。如果该值为正，那么新 token 会根据其在已有文本中的出现频率受到相应的惩罚，降低模型重复相同内容的可能性。",
                                  "en_US": "A number between -2.0 and 2.0. If the value is positive, new tokens are penalized based on their frequency of occurrence in existing text, reducing the likelihood that the model will repeat the same content."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "8",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "deepseek-coder",
                      "label": {
                          "zh_Hans": "deepseek-coder",
                          "en_US": "deepseek-coder"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 1,
                              "default": 0.5
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 4096,
                              "default": 1024
                          }
                      ]
                  },
                  {
                      "model": "deepseek-reasoner",
                      "label": {
                          "zh_Hans": "deepseek-reasoner",
                          "en_US": "deepseek-reasoner"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 4096
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "4",
                          "output": "16",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  }
              ],
              "provider": "deepseek",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "label": {
                              "en_US": "Custom API endpoint URL",
                              "zh_Hans": "自定义 API endpoint 地址"
                          },
                          "placeholder": {
                              "en_US": "Base URL, e.g. https://api.deepseek.com/v1 or https://api.deepseek.com",
                              "zh_Hans": "Base URL, e.g. https://api.deepseek.com/v1 or https://api.deepseek.com"
                          },
                          "required": false,
                          "type": "text-input",
                          "variable": "endpoint_url"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm"
              ]
          }
      },
      {
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "siliconflow",
          "author": "ssrag",
          "label": {
              "en_US": "SiliconFlow",
              "zh_Hans": "硅基流动"
          },
          "description": {
              "en_US": "SiliconFlow provides access to various models (LLMs, text embedding, reranking, STT, TTS), configurable via model name, API key, and other parameters.",
              "zh_Hans": "硅基流动提供对各种模型（LLM、文本嵌入、重排序、STT、TTS）的访问，可通过模型名称、API密钥和其他参数进行配置。"
          },
          "icon": "siliconflow_square.svg",
          "plugins": {
              "models": [
                  "provider/siliconflow.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": false
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.23",
          "created_at": "2024-09-20T00:13:50.292989-04:00",
          "model": {
              "background": "#ffecff",
              "configurate_methods": [
                  "predefined-model",
                  "customizable-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/rerank/rerank.py",
                          "models/text_embedding/text_embedding.py",
                          "models/tts/tts.py",
                          "models/speech2text/speech2text.py"
                      ],
                      "provider_source": "provider/siliconflow.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API Key from SiliconFlow",
                      "zh_Hans": "从 SiliconFlow 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://cloud.siliconflow.cn/account/ak"
                  }
              },
              "icon_large": {
                  "en_US": "siliconflow.svg"
              },
              "icon_small": {
                  "en_US": "siliconflow_square.svg"
              },
              "label": {
                  "en_US": "SiliconFlow",
                  "zh_Hans": "硅基流动"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Model context size",
                              "zh_Hans": "模型上下文长度"
                          },
                          "placeholder": {
                              "en_US": "Enter your Model context size",
                              "zh_Hans": "在此输入您的模型上下文长度"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "context_size"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Upper bound for max tokens",
                              "zh_Hans": "最大 token 上限"
                          },
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "text-input",
                          "variable": "max_tokens"
                      },
                      {
                          "default": "no_call",
                          "label": {
                              "en_US": "Function calling"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  },
                                  "value": "no_call"
                              },
                              {
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  },
                                  "value": "function_call"
                              }
                          ],
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "select",
                          "variable": "function_calling_type"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  }
              },
              "models": [
                  {
                      "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
                      "label": {
                          "zh_Hans": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
                          "en_US": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 16384,
                              "default": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.70",
                          "output": "0.70",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
                      "label": {
                          "zh_Hans": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
                          "en_US": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 16384,
                              "default": 8192
                          }
                      ],
                      "pricing": {
                          "input": "1.26",
                          "output": "1.26",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
                      "label": {
                          "zh_Hans": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
                          "en_US": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 16384,
                              "default": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Pro/deepseek-ai/DeepSeek-R1",
                      "label": {
                          "zh_Hans": "Pro/deepseek-ai/DeepSeek-R1",
                          "en_US": "Pro/deepseek-ai/DeepSeek-R1"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 16384,
                              "default": 16384
                          }
                      ],
                      "pricing": {
                          "input": "4",
                          "output": "16",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "deepseek-ai/DeepSeek-R1",
                      "label": {
                          "zh_Hans": "deepseek-ai/DeepSeek-R1",
                          "en_US": "deepseek-ai/DeepSeek-R1"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 16384,
                              "default": 16384
                          }
                      ],
                      "pricing": {
                          "input": "4",
                          "output": "16",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "deepseek-ai/DeepSeek-V2.5",
                      "label": {
                          "en_US": "deepseek-ai/DeepSeek-V2.5"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 4096,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "1.33",
                          "output": "1.33",
                          "unit": "0.000001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Pro/deepseek-ai/DeepSeek-V3",
                      "label": {
                          "en_US": "Pro/deepseek-ai/DeepSeek-V3"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 4096,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "8",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "deepseek-ai/DeepSeek-V3",
                      "label": {
                          "en_US": "deepseek-ai/DeepSeek-V3"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 4096,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "8",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "THUDM/GLM-4.1V-9B-Thinking",
                      "label": {
                          "en_US": "THUDM/glm-41v-9b-thinking"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16384
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 16384,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "default": 2,
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "default": 1.1
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "THUDM/glm-4-9b-chat",
                      "label": {
                          "en_US": "THUDM/glm-4-9b-chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 4096,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "zai-org/GLM-4.5-Air",
                      "label": {
                          "zh_Hans": "zai-org/GLM-4.5-Air",
                          "en_US": "zai-org/GLM-4.5-Air"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "1",
                          "output": "6",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "zai-org/GLM-4.5",
                      "label": {
                          "zh_Hans": "zai-org/GLM-4.5",
                          "en_US": "zai-org/GLM-4.5"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "3.5",
                          "output": "14",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "internlm/internlm2_5-7b-chat",
                      "label": {
                          "en_US": "internlm/internlm2_5-7b-chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 4096,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Pro/moonshotai/Kimi-K2-Instruct",
                      "label": {
                          "zh_Hans": "Pro/moonshotai/Kimi-K2-Instruct",
                          "en_US": "Pro/moonshotai/Kimi-K2-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 16384,
                              "default": 16384
                          }
                      ],
                      "pricing": {
                          "input": "4",
                          "output": "16",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "moonshotai/Kimi-K2-Instruct",
                      "label": {
                          "zh_Hans": "moonshotai/Kimi-K2-Instruct",
                          "en_US": "moonshotai/Kimi-K2-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 16384,
                              "default": 16384
                          }
                      ],
                      "pricing": {
                          "input": "4",
                          "output": "16",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/QVQ-72B-Preview",
                      "label": {
                          "en_US": "Qwen/QVQ-72B-Preview"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 16384,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "9.90",
                          "output": "9.90",
                          "unit": "0.000001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Qwen/QwQ-32B",
                      "label": {
                          "en_US": "Qwen/QwQ-32B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 32768,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "1",
                          "output": "4",
                          "unit": "0.000001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Qwen/Qwen2-7B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2-7B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 4096,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Qwen/Qwen2-VL-72B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2-VL-72B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "4.13",
                          "output": "4.13",
                          "unit": "0.000001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Qwen/Qwen2.5-14B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-14B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.7",
                          "output": "0.7",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-32B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-32B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "1.26",
                          "output": "1.26",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-72B-Instruct-128K",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-72B-Instruct-128K"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 4096,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "4.13",
                          "output": "4.13",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-72B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-72B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 4096,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "4.13",
                          "output": "4.13",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-7B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-7B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-Coder-32B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-Coder-32B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "1.26",
                          "output": "1.26",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-Coder-7B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-Coder-7B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-VL-32B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-VL-32B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "1.89",
                          "output": "1.89",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-VL-72B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-VL-72B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "4.13",
                          "output": "4.13",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Pro/Qwen/Qwen2.5-VL-7B-Instruct",
                      "label": {
                          "en_US": "Pro/Qwen/Qwen2.5-VL-7B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.35",
                          "output": "0.35",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-14B",
                      "label": {
                          "zh_Hans": "Qwen/Qwen3-14B",
                          "en_US": "Qwen/Qwen3-14B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.5",
                          "output": "2",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-235B-A22B-Instruct-2507",
                      "label": {
                          "zh_Hans": "Qwen/Qwen3-235B-A22B-Instruct-2507",
                          "en_US": "Qwen/Qwen3-235B-A22B-Instruct-2507"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 256000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          }
                      ],
                      "pricing": {
                          "input": "2.5",
                          "output": "10",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-235B-A22B-Thinking-2507",
                      "label": {
                          "zh_Hans": "Qwen/Qwen3-235B-A22B-Thinking-2507",
                          "en_US": "Qwen/Qwen3-235B-A22B-Thinking-2507"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 256000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          }
                      ],
                      "pricing": {
                          "input": "2.5",
                          "output": "10",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-235B-A22B",
                      "label": {
                          "zh_Hans": "Qwen/Qwen3-235B-A22B",
                          "en_US": "Qwen/Qwen3-235B-A22B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "2.5",
                          "output": "10",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-30B-A3B-Instruct-2507",
                      "label": {
                          "zh_Hans": "Qwen/Qwen3-30B-A3B-Instruct-2507",
                          "en_US": "Qwen/Qwen3-30B-A3B-Instruct-2507"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 256000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.7",
                          "output": "2.8",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-30B-A3B",
                      "label": {
                          "zh_Hans": "Qwen/Qwen3-30B-A3B",
                          "en_US": "Qwen/Qwen3-30B-A3B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.7",
                          "output": "2.8",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-32B",
                      "label": {
                          "zh_Hans": "Qwen/Qwen3-32B",
                          "en_US": "Qwen/Qwen3-32B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "1",
                          "output": "4",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-8B",
                      "label": {
                          "zh_Hans": "Qwen/Qwen3-8B",
                          "en_US": "Qwen/Qwen3-8B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "netease-youdao/bce-reranker-base_v1",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 512
                      }
                  },
                  {
                      "model": "BAAI/bge-reranker-v2-m3",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 8192
                      }
                  },
                  {
                      "model": "FunAudioLLM/SenseVoiceSmall",
                      "model_type": "speech2text",
                      "model_properties": {
                          "file_upload_limit": 1,
                          "supported_file_extensions": "mp3,wav"
                      }
                  },
                  {
                      "model": "iic/SenseVoiceSmall",
                      "model_type": "speech2text",
                      "model_properties": {
                          "file_upload_limit": 1,
                          "supported_file_extensions": "mp3,wav"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "netease-youdao/bce-embedding-base_v1",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 512,
                          "max_chunks": 1
                      }
                  },
                  {
                      "model": "BAAI/bge-large-en-v1.5",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 512,
                          "max_chunks": 1
                      }
                  },
                  {
                      "model": "BAAI/bge-large-zh-v1.5",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 512,
                          "max_chunks": 1
                      }
                  },
                  {
                      "model": "BAAI/bge-m3",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 1
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-Embedding-0.6B",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 32768,
                          "vector_dimension": 1024
                      },
                      "order": 3
                  },
                  {
                      "model": "Qwen/Qwen3-Embedding-4B",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 32768,
                          "vector_dimension": 2560
                      },
                      "order": 2
                  },
                  {
                      "model": "Qwen/Qwen3-Embedding-8B",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 32768,
                          "vector_dimension": 4096
                      },
                      "order": 1
                  },
                  {
                      "model": "FunAudioLLM/CosyVoice2-0.5B",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "FunAudioLLM/CosyVoice2-0.5B:alex",
                          "voices": [
                              {
                                  "mode": "FunAudioLLM/CosyVoice2-0.5B:alex",
                                  "name": "Alex（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "FunAudioLLM/CosyVoice2-0.5B:benjamin",
                                  "name": "Benjamin（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "FunAudioLLM/CosyVoice2-0.5B:charles",
                                  "name": "Charles（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "FunAudioLLM/CosyVoice2-0.5B:david",
                                  "name": "David（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "FunAudioLLM/CosyVoice2-0.5B:anna",
                                  "name": "Anna（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "FunAudioLLM/CosyVoice2-0.5B:bella",
                                  "name": "Bella（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "FunAudioLLM/CosyVoice2-0.5B:claire",
                                  "name": "Claire（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "FunAudioLLM/CosyVoice2-0.5B:diana",
                                  "name": "Diana（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              }
                          ],
                          "audio_type": "mp3",
                          "max_workers": 5
                      },
                      "pricing": {
                          "input": "50",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "fishaudio/fish-speech-1.4",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "fishaudio/fish-speech-1.4:alex",
                          "voices": [
                              {
                                  "mode": "fishaudio/fish-speech-1.4:alex",
                                  "name": "Alex（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.4:benjamin",
                                  "name": "Benjamin（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.4:charles",
                                  "name": "Charles（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.4:david",
                                  "name": "David（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.4:anna",
                                  "name": "Anna（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.4:bella",
                                  "name": "Bella（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.4:claire",
                                  "name": "Claire（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.4:diana",
                                  "name": "Diana（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              }
                          ],
                          "audio_type": "mp3",
                          "max_workers": 5
                      },
                      "pricing": {
                          "input": "105",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "fishaudio/fish-speech-1.5",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "fishaudio/fish-speech-1.5:alex",
                          "voices": [
                              {
                                  "mode": "fishaudio/fish-speech-1.5:alex",
                                  "name": "Alex（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.5:benjamin",
                                  "name": "Benjamin（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.5:charles",
                                  "name": "Charles（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.5:david",
                                  "name": "David（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.5:anna",
                                  "name": "Anna（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.5:bella",
                                  "name": "Bella（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.5:claire",
                                  "name": "Claire（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "fishaudio/fish-speech-1.5:diana",
                                  "name": "Diana（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              }
                          ],
                          "audio_type": "mp3",
                          "max_workers": 5
                      },
                      "pricing": {
                          "input": "105",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "RVC-Boss/GPT-SoVITS",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "RVC-Boss/GPT-SoVITS:alex",
                          "voices": [
                              {
                                  "mode": "RVC-Boss/GPT-SoVITS:alex",
                                  "name": "Alex（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "RVC-Boss/GPT-SoVITS:benjamin",
                                  "name": "Benjamin（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "RVC-Boss/GPT-SoVITS:charles",
                                  "name": "Charles（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "RVC-Boss/GPT-SoVITS:david",
                                  "name": "David（男声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "RVC-Boss/GPT-SoVITS:anna",
                                  "name": "Anna（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "RVC-Boss/GPT-SoVITS:bella",
                                  "name": "Bella（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "RVC-Boss/GPT-SoVITS:claire",
                                  "name": "Claire（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              },
                              {
                                  "mode": "RVC-Boss/GPT-SoVITS:diana",
                                  "name": "Diana（女声）",
                                  "language": [
                                      "zh-Hans",
                                      "en-US"
                                  ]
                              }
                          ],
                          "audio_type": "mp3",
                          "max_workers": 5
                      },
                      "pricing": {
                          "input": "50",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  }
              ],
              "provider": "siliconflow",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding",
                  "rerank",
                  "speech2text",
                  "tts"
              ]
          }
      },
      {
          "version": "0.0.16",
          "type": "plugin",
          "author": "langgenius",
          "name": "openai_api_compatible",
          "description": {
              "en_US": "Model providers compatible with OpenAI's API standard, such as LM Studio.",
              "zh_Hans": "兼容 OpenAI API 的模型供应商，例如 LM Studio 。"
          },
          "label": {
              "en_US": "OpenAI-API-compatible"
          },
          "created_at": "2024-07-12T08:03:44.658609186Z",
          "icon": "icon.svg",
          "resource": {
              "memory": 1048576,
              "permission": {
                  "tool": {
                      "enabled": true
                  },
                  "model": {
                      "enabled": true,
                      "llm": true
                  }
              }
          },
          "plugins": {
              "models": [
                  "provider/openai_api_compatible.yaml"
              ]
          },
          "meta": {
              "version": "0.0.1",
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "language": "python",
                  "version": "3.12",
                  "entrypoint": "main"
              }
          },
          "model": {
              "provider": "openai_api_compatible",
              "label": {
                  "en_US": "OpenAI-API-compatible"
              },
              "description": {
                  "en_US": "Model providers compatible with OpenAI's API standard, such as LM Studio.",
                  "zh_Hans": "兼容 OpenAI API 的模型供应商，例如 LM Studio 。"
              },
              "icon_small": {
                  "en_US": "icon.svg"
              },
              "supported_model_types": [
                  "llm",
                  "rerank",
                  "text-embedding",
                  "speech2text",
                  "tts"
              ],
              "configurate_methods": [
                  "customizable-model"
              ],
              "model_credential_schema": {
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter full model name",
                          "zh_Hans": "输入模型全称"
                      }
                  },
                  "credential_form_schemas": [
                      {
                          "variable": "display_name",
                          "label": {
                              "en_US": "Model display name",
                              "zh_Hans": "模型显示名称"
                          },
                          "type": "text-input",
                          "required": false,
                          "placeholder": {
                              "zh_Hans": "模型在界面的显示名称",
                              "en_US": "The display name of the model in the interface."
                          }
                      },
                      {
                          "variable": "api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "type": "secret-input",
                          "required": false,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Key",
                              "en_US": "Enter your API Key"
                          }
                      },
                      {
                          "variable": "endpoint_url",
                          "label": {
                              "zh_Hans": "API endpoint URL",
                              "en_US": "API endpoint URL"
                          },
                          "type": "text-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "Base URL, e.g. https://api.openai.com/v1",
                              "en_US": "Base URL, e.g. https://api.openai.com/v1"
                          }
                      },
                      {
                          "variable": "endpoint_model_name",
                          "label": {
                              "zh_Hans": "API endpoint中的模型名称",
                              "en_US": "model name for API endpoint"
                          },
                          "type": "text-input",
                          "required": false,
                          "placeholder": {
                              "zh_Hans": "endpoint model name, e.g. chatgpt4.0",
                              "en_US": "endpoint model name, e.g. chatgpt4.0"
                          }
                      },
                      {
                          "variable": "mode",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "en_US": "Completion mode"
                          },
                          "type": "select",
                          "required": false,
                          "default": "chat",
                          "placeholder": {
                              "zh_Hans": "选择对话类型",
                              "en_US": "Select completion mode"
                          },
                          "options": [
                              {
                                  "value": "completion",
                                  "label": {
                                      "en_US": "Completion",
                                      "zh_Hans": "补全"
                                  }
                              },
                              {
                                  "value": "chat",
                                  "label": {
                                      "en_US": "Chat",
                                      "zh_Hans": "对话"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "context_size",
                          "label": {
                              "zh_Hans": "模型上下文长度",
                              "en_US": "Model context size"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "type": "text-input",
                          "default": "4096",
                          "placeholder": {
                              "zh_Hans": "在此输入您的模型上下文长度",
                              "en_US": "Enter your Model context size"
                          }
                      },
                      {
                          "variable": "context_size",
                          "label": {
                              "zh_Hans": "模型上下文长度",
                              "en_US": "Model context size"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "text-embedding"
                              }
                          ],
                          "type": "text-input",
                          "default": "4096",
                          "placeholder": {
                              "zh_Hans": "在此输入您的模型上下文长度",
                              "en_US": "Enter your Model context size"
                          }
                      },
                      {
                          "variable": "context_size",
                          "label": {
                              "zh_Hans": "模型上下文长度",
                              "en_US": "Model context size"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "rerank"
                              }
                          ],
                          "type": "text-input",
                          "default": "4096",
                          "placeholder": {
                              "zh_Hans": "在此输入您的模型上下文长度",
                              "en_US": "Enter your Model context size"
                          }
                      },
                      {
                          "variable": "max_tokens_to_sample",
                          "label": {
                              "zh_Hans": "最大 token 上限",
                              "en_US": "Upper bound for max tokens"
                          },
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "default": "4096",
                          "type": "text-input"
                      },
                      {
                          "variable": "agent_though_support",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "en_US": "Agent Thought"
                          },
                          "type": "select",
                          "required": false,
                          "default": "not_supported",
                          "options": [
                              {
                                  "value": "supported",
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  }
                              },
                              {
                                  "value": "not_supported",
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "function_calling_type",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "en_US": "Function calling"
                          },
                          "type": "select",
                          "required": false,
                          "default": "no_call",
                          "options": [
                              {
                                  "value": "function_call",
                                  "label": {
                                      "en_US": "Function Call",
                                      "zh_Hans": "Function Call"
                                  }
                              },
                              {
                                  "value": "tool_call",
                                  "label": {
                                      "en_US": "Tool Call",
                                      "zh_Hans": "Tool Call"
                                  }
                              },
                              {
                                  "value": "no_call",
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "stream_function_calling",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "en_US": "Stream function calling"
                          },
                          "type": "select",
                          "required": false,
                          "default": "not_supported",
                          "options": [
                              {
                                  "value": "supported",
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  }
                              },
                              {
                                  "value": "not_supported",
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "vision_support",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "zh_Hans": "Vision 支持",
                              "en_US": "Vision Support"
                          },
                          "type": "select",
                          "required": false,
                          "default": "no_support",
                          "options": [
                              {
                                  "value": "support",
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  }
                              },
                              {
                                  "value": "no_support",
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "structured_output_support",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "en_US": "Structured Output"
                          },
                          "type": "select",
                          "required": false,
                          "default": "not_supported",
                          "options": [
                              {
                                  "value": "supported",
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  }
                              },
                              {
                                  "value": "not_supported",
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "stream_mode_delimiter",
                          "label": {
                              "zh_Hans": "流模式返回结果的分隔符",
                              "en_US": "Delimiter for streaming results"
                          },
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "default": "\\n\\n",
                          "type": "text-input"
                      },
                      {
                          "variable": "voices",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "tts"
                              }
                          ],
                          "label": {
                              "en_US": "Available Voices (comma-separated)",
                              "zh_Hans": "可用声音（用英文逗号分隔）"
                          },
                          "type": "text-input",
                          "required": false,
                          "default": "alloy",
                          "placeholder": {
                              "en_US": "alloy,echo,fable,onyx,nova,shimmer",
                              "zh_Hans": "alloy,echo,fable,onyx,nova,shimmer"
                          },
                          "help": {
                              "en_US": "List voice names separated by commas. First voice will be used as default.",
                              "zh_Hans": "用英文逗号分隔的声音列表。第一个声音将作为默认值。"
                          }
                      }
                  ]
              },
              "extra": {
                  "python": {
                      "provider_source": "provider/openai_api_compatible.py",
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/text_embedding/text_embedding.py",
                          "models/rerank/rerank.py",
                          "models/speech2text/speech2text.py",
                          "models/tts/tts.py"
                      ]
                  }
              },
              "models": []
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "Google's Gemini model.",
              "zh_Hans": "谷歌提供的 Gemini 模型."
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "Gemini"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.2"
          },
          "name": "gemini",
          "plugins": {
              "models": [
                  "provider/google.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.2.5",
          "model": {
              "background": "#FCFDFF",
              "configurate_methods": [
                  "predefined-model"
              ],
              "description": {
                  "en_US": "Google's Gemini model.",
                  "zh_Hans": "谷歌提供的 Gemini 模型."
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py"
                      ],
                      "provider_source": "provider/google.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API Key from Google",
                      "zh_Hans": "从 Google 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://ai.google.dev/"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "Gemini"
              },
              "models": [
                  {
                      "model": "gemini-1.5-flash-001",
                      "label": {
                          "en_US": "Gemini 1.5 Flash 001"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-1.5-flash-002",
                      "label": {
                          "en_US": "Gemini 1.5 Flash 002"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-1.5-flash-8b-exp-0827",
                      "label": {
                          "en_US": "Gemini 1.5 Flash 8B 0827"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-1.5-flash-8b-exp-0924",
                      "label": {
                          "en_US": "Gemini 1.5 Flash 8B 0924"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-1.5-flash-exp-0827",
                      "label": {
                          "en_US": "Gemini 1.5 Flash 0827"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-1.5-flash-latest",
                      "label": {
                          "en_US": "Gemini 1.5 Flash Latest"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-1.5-flash",
                      "label": {
                          "en_US": "Gemini 1.5 Flash"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-1.5-pro-001",
                      "label": {
                          "en_US": "Gemini 1.5 Pro 001"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2097152
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-1.5-pro-002",
                      "label": {
                          "en_US": "Gemini 1.5 Pro 002"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2097152
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-1.5-pro-exp-0801",
                      "label": {
                          "en_US": "Gemini 1.5 Pro 0801"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2097152
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-1.5-pro-exp-0827",
                      "label": {
                          "en_US": "Gemini 1.5 Pro 0827"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2097152
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-1.5-pro-latest",
                      "label": {
                          "en_US": "Gemini 1.5 Pro Latest"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2097152
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-1.5-pro",
                      "label": {
                          "en_US": "Gemini 1.5 Pro"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2097152
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.0-flash-001",
                      "label": {
                          "en_US": "Gemini 2.0 Flash 001"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.0-flash-exp",
                      "label": {
                          "en_US": "Gemini 2.0 Flash Exp"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.0-flash-lite-001",
                      "label": {
                          "en_US": "Gemini 2.0 Flash-Lite 001"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.0-flash-lite-preview-02-05",
                      "label": {
                          "en_US": "Gemini 2.0 Flash-Lite Preview 02-05"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.0-flash-lite-preview",
                      "label": {
                          "en_US": "Gemini 2.0 Flash-Lite Preview"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.0-flash-lite",
                      "label": {
                          "en_US": "Gemini 2.0 Flash-Lite"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.0-flash-preview-image-generation",
                      "label": {
                          "en_US": "Gemini 2.0 Flash Preview Image Generation"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.0-flash-thinking-exp-01-21",
                      "label": {
                          "en_US": "Gemini 2.0 Flash Thinking Experimental 01-21"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 65536,
                              "min": 1,
                              "max": 65536
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.0-flash-thinking-exp-1219",
                      "label": {
                          "en_US": "Gemini 2.0 Flash Thinking Experimental"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 65536,
                              "min": 1,
                              "max": 65536
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.0-flash",
                      "label": {
                          "en_US": "Gemini 2.0 Flash"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          },
                          {
                              "name": "grounding",
                              "label": {
                                  "en_US": "Grounding",
                                  "ja_JP": "Grounding"
                              },
                              "type": "boolean",
                              "help": {
                                  "en_US": "ensures responses are based on Google Search.",
                                  "ja_JP": "Google検索に基づいた応答をします。"
                              },
                              "required": true,
                              "default": false
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.0-pro-exp-02-05",
                      "label": {
                          "en_US": "Gemini 2.0 Pro Experimental 02-05"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2097152
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.0-pro-exp",
                      "label": {
                          "en_US": "Gemini 2.0 Pro Experimental"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2097152
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.5-flash-preview-04-17",
                      "label": {
                          "en_US": "Gemini 2.5 Flash Preview 04-17"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 65536
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.15",
                          "output": "0.60",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.5-flash-preview-05-20",
                      "label": {
                          "en_US": "Gemini 2.5 Flash Preview 05-20"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 65536
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          },
                          {
                              "name": "grounding",
                              "label": {
                                  "en_US": "Grounding",
                                  "ja_JP": "Grounding"
                              },
                              "type": "boolean",
                              "help": {
                                  "en_US": "ensures responses are based on Google Search.",
                                  "ja_JP": "Google検索に基づいた応答をします。"
                              },
                              "required": true,
                              "default": false
                          }
                      ],
                      "pricing": {
                          "input": "0.15",
                          "output": "0.60",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.5-pro-exp-03-25",
                      "label": {
                          "en_US": "Gemini 2.5 Pro Experimental 03-25"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 64000
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.5-pro-preview-03-25",
                      "label": {
                          "en_US": "Gemini 2.5 Pro Preview 03-25"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 65536
                          },
                          {
                              "name": "grounding",
                              "label": {
                                  "en_US": "Grounding",
                                  "zh_Hans": "事实核查",
                                  "ja_JP": "事実チェック"
                              },
                              "type": "boolean",
                              "help": {
                                  "en_US": "Grounding with Google Search",
                                  "zh_Hans": "Google 事实核查",
                                  "ja_JP": "Google検索に基づいた応答をします。"
                              },
                              "required": true,
                              "default": false
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "1.25",
                          "output": "10.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.5-pro-preview-05-06",
                      "label": {
                          "en_US": "Gemini 2.5 Pro Preview 05-06"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 65535,
                              "min": 1,
                              "max": 65536
                          },
                          {
                              "name": "grounding",
                              "label": {
                                  "en_US": "Grounding",
                                  "zh_Hans": "事实核查",
                                  "ja_JP": "事実チェック"
                              },
                              "type": "boolean",
                              "help": {
                                  "en_US": "Grounding with Google Search",
                                  "zh_Hans": "Google 事实核查",
                                  "ja_JP": "Google検索に基づいた応答をします。"
                              },
                              "required": true,
                              "default": false
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "1.25",
                          "output": "10.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.5-pro-preview-06-05",
                      "label": {
                          "en_US": "Gemini 2.5 Pro Preview 06-05"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 65535,
                              "min": 1,
                              "max": 65536
                          },
                          {
                              "name": "grounding",
                              "label": {
                                  "en_US": "Grounding",
                                  "zh_Hans": "事实核查",
                                  "ja_JP": "事実チェック"
                              },
                              "type": "boolean",
                              "help": {
                                  "en_US": "Grounding with Google Search",
                                  "zh_Hans": "Google 事实核查",
                                  "ja_JP": "Google検索に基づいた応答をします。"
                              },
                              "required": true,
                              "default": false
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "1.25",
                          "output": "10.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-exp-1114",
                      "label": {
                          "en_US": "Gemini exp 1114"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32767
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-exp-1121",
                      "label": {
                          "en_US": "Gemini exp 1121"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32767
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-exp-1206",
                      "label": {
                          "en_US": "Gemini Experimental 1206"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2097152
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-pro-vision",
                      "label": {
                          "en_US": "Gemini Pro Vision"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 12288
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens_to_sample",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 4096,
                              "min": 1,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "gemini-pro",
                      "label": {
                          "en_US": "Gemini Pro"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 30720
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens_to_sample",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 2048,
                              "min": 1,
                              "max": 2048
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "learnlm-1.5-pro-experimental",
                      "label": {
                          "en_US": "LearnLM 1.5 Pro Experimental"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32767
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  }
              ],
              "provider": "google",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "google_api_key"
                      },
                      {
                          "label": {
                              "en_US": "Files URL"
                          },
                          "placeholder": {
                              "en_US": "Enter the Local FILES URL prefix to get better upload performance",
                              "zh_Hans": "在此输入本地文件地址的URL前缀"
                          },
                          "required": false,
                          "type": "text-input",
                          "variable": "file_url"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "Volcengine Ark models.",
              "zh_Hans": "火山方舟提供的模型，例如 Doubao-pro-4k、Doubao-pro-32k 和 Doubao-pro-128k。"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "Volcengine",
              "zh_Hans": "火山方舟"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "volcengine_maas",
          "plugins": {
              "models": [
                  "provider/volcengine_maas.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.20",
          "model": {
              "background": "#F9FAFB",
              "configurate_methods": [
                  "customizable-model"
              ],
              "description": {
                  "en_US": "Volcengine Ark models.",
                  "zh_Hans": "火山方舟提供的模型，例如 Doubao-pro-4k、Doubao-pro-32k 和 Doubao-pro-128k。"
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/text_embedding/text_embedding.py"
                      ],
                      "provider_source": "provider/volcengine_maas.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your Access Key and Secret Access Key from Volcengine Console",
                      "zh_Hans": "从火山引擎控制台获取您的 Access Key 和 Secret Access Key"
                  },
                  "url": {
                      "en_US": "https://console.volcengine.com/iam/keymanage/"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg",
                  "zh_Hans": "icon_l_zh.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "Volcengine"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "default": "aksk",
                          "label": {
                              "en_US": "Authentication Method",
                              "zh_Hans": "鉴权方式"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "API Key"
                                  },
                                  "value": "api_key"
                              },
                              {
                                  "label": {
                                      "en_US": "Access Key / Secret Access Key"
                                  },
                                  "value": "aksk"
                              }
                          ],
                          "placeholder": {
                              "en_US": "Enter your Authentication Method",
                              "zh_Hans": "选择鉴权方式"
                          },
                          "required": true,
                          "type": "select",
                          "variable": "auth_method"
                      },
                      {
                          "label": {
                              "en_US": "Access Key",
                              "zh_Hans": "Access Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your Access Key",
                              "zh_Hans": "输入您的 Access Key"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "value": "aksk",
                                  "variable": "auth_method"
                              }
                          ],
                          "type": "secret-input",
                          "variable": "volc_access_key_id"
                      },
                      {
                          "label": {
                              "en_US": "Secret Access Key",
                              "zh_Hans": "Secret Access Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your Secret Access Key",
                              "zh_Hans": "输入您的 Secret Access Key"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "value": "aksk",
                                  "variable": "auth_method"
                              }
                          ],
                          "type": "secret-input",
                          "variable": "volc_secret_access_key"
                      },
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "输入您的 API Key"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "value": "api_key",
                                  "variable": "auth_method"
                              }
                          ],
                          "type": "secret-input",
                          "variable": "volc_api_key"
                      },
                      {
                          "default": "cn-beijing",
                          "label": {
                              "en_US": "Volcengine Region",
                              "zh_Hans": "火山引擎地域"
                          },
                          "placeholder": {
                              "en_US": "Enter Volcengine Region",
                              "zh_Hans": "输入火山引擎地域"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "volc_region"
                      },
                      {
                          "default": "https://ark.cn-beijing.volces.com/api/v3",
                          "label": {
                              "en_US": "API Endpoint Host",
                              "zh_Hans": "API Endpoint Host"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Endpoint Host",
                              "zh_Hans": "输入 API Endpoint Host"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "api_endpoint_host"
                      },
                      {
                          "label": {
                              "en_US": "Endpoint ID",
                              "zh_Hans": "Endpoint ID"
                          },
                          "placeholder": {
                              "en_US": "Enter your Endpoint ID",
                              "zh_Hans": "输入您的 Endpoint ID"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "endpoint_id"
                      },
                      {
                          "label": {
                              "en_US": "Base Model",
                              "zh_Hans": "基础模型"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Doubao-Seed-1.6"
                                  },
                                  "value": "Doubao-Seed-1.6",
                                  "show_on": [
                                      {
                                          "variable": "__model_type",
                                          "value": "llm"
                                      }
                                  ]
                              },
                              {
                                  "label": {
                                      "en_US": "Doubao-Seed-1.6-flash"
                                  },
                                  "value": "Doubao-Seed-1.6-flash",
                                  "show_on": [
                                      {
                                          "variable": "__model_type",
                                          "value": "llm"
                                      }
                                  ]
                              },
                              {
                                  "label": {
                                      "en_US": "Doubao-Seed-1.6-thinking"
                                  },
                                  "value": "Doubao-Seed-1.6-thinking",
                                  "show_on": [
                                      {
                                          "variable": "__model_type",
                                          "value": "llm"
                                      }
                                  ]
                              },
                              {
                                  "label": {
                                      "en_US": "Doubao-1.5-thinking-vision-pro"
                                  },
                                  "value": "Doubao-1.5-thinking-vision-pro",
                                  "show_on": [
                                      {
                                          "variable": "__model_type",
                                          "value": "llm"
                                      }
                                  ]
                              },
                              {
                                  "label": {
                                      "en_US": "Doubao-1.5-UI-TARS"
                                  },
                                  "value": "Doubao-1.5-UI-TARS",
                                  "show_on": [
                                      {
                                          "variable": "__model_type",
                                          "value": "llm"
                                      }
                                  ]
                              },
                              {
                                  "label": {
                                      "en_US": "Doubao-1.5-vision-lite"
                                  },
                                  "value": "Doubao-1.5-vision-lite",
                                  "show_on": [
                                      {
                                          "variable": "__model_type",
                                          "value": "llm"
                                      }
                                  ]
                              },
                              {
                                  "label": {
                                      "en_US": "Doubao-1.5-vision-pro"
                                  },
                                  "value": "Doubao-1.5-vision-pro",
                                  "show_on": [
                                      {
                                          "variable": "__model_type",
                                          "value": "llm"
                                      }
                                  ]
                              },
                              {
                                  "label": {
                                      "en_US": "Doubao-1.5-thinking-pro"
                                  },
                                  "value": "Doubao-1.5-thinking-pro",
                                  "show_on": [
                                      {
                                          "variable": "__model_type",
                                          "value": "llm"
                                      }
                                  ]
                              },
                              {
                                  "label": {
                                      "en_US": "DeepSeek-R1-Distill-Qwen-32B"
                                  },
                                  "value": "DeepSeek-R1-Distill-Qwen-32B",
                                  "show_on": [
                                      {
                                          "variable": "__model_type",
                                          "value": "llm"
                                      }
                                  ]
                              },
                              {
                                  "label": {
                                      "en_US": "DeepSeek-R1-Distill-Qwen-7B"
                                  },
                                  "value": "DeepSeek-R1-Distill-Qwen-7B",
                                  "show_on": [
                                      {
                                          "variable": "__model_type",
                                          "value": "llm"
                                      }
                                  ]
                              },
                              {
                                  "label": {
                                      "en_US": "DeepSeek-R1"
                                  },
                                  "value": "DeepSeek-R1",
                                  "show_on": [
                                      {
                                          "variable": "__model_type",
                                          "value": "llm"
                                      }
                                  ]
                              },
                              {
                                  "label": {
                                      "en_US": "DeepSeek-V3"
                                  },
                                  "value": "DeepSeek-V3",
                                  "show_on": [
                                      {
                                          "variable": "__model_type",
                                          "value": "llm"
                                      }
                                  ]
                              },
                              {
                                  "label": {
                                      "en_US": "Doubao-1.5-vision-pro-32k"
                                  },
                                  "value": "Doubao-1.5-vision-pro-32k",
                                  "show_on": [
                                      {
                                          "variable": "__model_type",
                                          "value": "llm"
                                      }
                                  ]
                              },
                              {
                                  "label": {
                                      "en_US": "Doubao-1.5-pro-32k"
                                  },
                                  "value": "Doubao-1.5-pro-32k",
                                  "show_on": [
                                      {
                                          "variable": "__model_type",
                                          "value": "llm"
                                      }
                                  ]
                              },
                              {
                                  "label": {
                                      "en_US": "Doubao-1.5-lite-32k"
                                  },
                                  "value": "Doubao-1.5-lite-32k",
                                  "show_on": [
                                      {
                                          "variable": "__model_type",
                                          "value": "llm"
                                      }
                                  ]
                              },
                              {
                                  "label": {
                                      "en_US": "Doubao-1.5-pro-256k"
                                  },
                                  "value": "Doubao-1.5-pro-256k",
                                  "show_on": [
                                      {
                                          "variable": "__model_type",
                                          "value": "llm"
                                      }
                                  ]
                              },
                              {
                                  "label": {
                                      "en_US": "Doubao-vision-pro-32k"
                                  },
                                  "value": "Doubao-vision-pro-32k",
                                  "show_on": [
                                      {
                                          "variable": "__model_type",
                                          "value": "llm"
                                      }
                                  ]
                              },
                              {
                                  "label": {
                                      "en_US": "Doubao-vision-lite-32k"
                                  },
                                  "value": "Doubao-vision-lite-32k",
                                  "show_on": [
                                      {
                                          "variable": "__model_type",
                                          "value": "llm"
                                      }
                                  ]
                              },
                              {
                                  "label": {
                                      "en_US": "Doubao-pro-4k"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "Doubao-pro-4k"
                              },
                              {
                                  "label": {
                                      "en_US": "Doubao-lite-4k"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "Doubao-lite-4k"
                              },
                              {
                                  "label": {
                                      "en_US": "Doubao-pro-32k"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "Doubao-pro-32k"
                              },
                              {
                                  "label": {
                                      "en_US": "Doubao-lite-32k"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "Doubao-lite-32k"
                              },
                              {
                                  "label": {
                                      "en_US": "Doubao-pro-128k"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "Doubao-pro-128k"
                              },
                              {
                                  "label": {
                                      "en_US": "Doubao-lite-128k"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "Doubao-lite-128k"
                              },
                              {
                                  "label": {
                                      "en_US": "Doubao-pro-256k"
                                  },
                                  "value": "Doubao-pro-256k",
                                  "show_on": [
                                      {
                                          "variable": "__model_type",
                                          "value": "llm"
                                      }
                                  ]
                              },
                              {
                                  "label": {
                                      "en_US": "Llama3-8B"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "Llama3-8B"
                              },
                              {
                                  "label": {
                                      "en_US": "Llama3-70B"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "Llama3-70B"
                              },
                              {
                                  "label": {
                                      "en_US": "Moonshot-v1-8k"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "Moonshot-v1-8k"
                              },
                              {
                                  "label": {
                                      "en_US": "Moonshot-v1-32k"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "Moonshot-v1-32k"
                              },
                              {
                                  "label": {
                                      "en_US": "Moonshot-v1-128k"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "Moonshot-v1-128k"
                              },
                              {
                                  "label": {
                                      "en_US": "GLM3-130B"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "GLM3-130B"
                              },
                              {
                                  "label": {
                                      "en_US": "GLM3-130B-Fin"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "GLM3-130B-Fin"
                              },
                              {
                                  "label": {
                                      "en_US": "Mistral-7B"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "Mistral-7B"
                              },
                              {
                                  "label": {
                                      "en_US": "Doubao-embedding"
                                  },
                                  "show_on": [
                                      {
                                          "value": "text-embedding",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "Doubao-embedding"
                              },
                              {
                                  "label": {
                                      "en_US": "Doubao-embedding-large"
                                  },
                                  "value": "Doubao-embedding-large",
                                  "show_on": [
                                      {
                                          "variable": "__model_type",
                                          "value": "text-embedding"
                                      }
                                  ]
                              },
                              {
                                  "label": {
                                      "en_US": "Custom",
                                      "zh_Hans": "自定义"
                                  },
                                  "value": "Custom"
                              }
                          ],
                          "required": true,
                          "type": "select",
                          "variable": "base_model_name"
                      },
                      {
                          "default": "chat",
                          "label": {
                              "en_US": "Completion Mode",
                              "zh_Hans": "模型类型"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Completion",
                                      "zh_Hans": "补全"
                                  },
                                  "value": "completion"
                              },
                              {
                                  "label": {
                                      "en_US": "Chat",
                                      "zh_Hans": "对话"
                                  },
                                  "value": "chat"
                              }
                          ],
                          "placeholder": {
                              "en_US": "Select Completion Mode",
                              "zh_Hans": "选择对话类型"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              },
                              {
                                  "value": "Custom",
                                  "variable": "base_model_name"
                              }
                          ],
                          "type": "select",
                          "variable": "mode"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Model Context Size",
                              "zh_Hans": "模型上下文长度"
                          },
                          "placeholder": {
                              "en_US": "Enter your Model Context Size",
                              "zh_Hans": "输入您的模型上下文长度"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "value": "Custom",
                                  "variable": "base_model_name"
                              }
                          ],
                          "type": "text-input",
                          "variable": "context_size"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Upper Bound for Max Tokens",
                              "zh_Hans": "最大 token 上限"
                          },
                          "placeholder": {
                              "en_US": "Enter your model Upper Bound for Max Tokens",
                              "zh_Hans": "输入您的模型最大 token 上限"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              },
                              {
                                  "value": "Custom",
                                  "variable": "base_model_name"
                              }
                          ],
                          "type": "text-input",
                          "variable": "max_tokens"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your Model Name",
                          "zh_Hans": "输入模型名称"
                      }
                  }
              },
              "models": [],
              "provider": "volcengine_maas",
              "supported_model_types": [
                  "llm",
                  "text-embedding"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "Xorbits Inference"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "Xorbits Inference"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "xinference",
          "plugins": {
              "models": [
                  "provider/xinference.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.3",
          "model": {
              "background": "#FAF5FF",
              "configurate_methods": [
                  "customizable-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/rerank/rerank.py",
                          "models/text_embedding/text_embedding.py",
                          "models/tts/tts.py",
                          "models/speech2text/speech2text.py"
                      ],
                      "provider_source": "provider/xinference.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "How to deploy Xinference",
                      "zh_Hans": "如何部署 Xinference"
                  },
                  "url": {
                      "en_US": "https://github.com/xorbitsai/inference"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "Xorbits Inference"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "Server url",
                              "zh_Hans": "服务器URL"
                          },
                          "placeholder": {
                              "en_US": "Enter the url of your Xinference, e.g. http://192.168.1.100:9997",
                              "zh_Hans": "在此输入Xinference的服务器地址，如 http://192.168.1.100:9997"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "server_url"
                      },
                      {
                          "label": {
                              "en_US": "Model uid",
                              "zh_Hans": "模型UID"
                          },
                          "placeholder": {
                              "en_US": "Enter the model uid",
                              "zh_Hans": "在此输入您的Model UID"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "model_uid"
                      },
                      {
                          "label": {
                              "en_US": "API key",
                              "zh_Hans": "API密钥"
                          },
                          "placeholder": {
                              "en_US": "Enter the api key",
                              "zh_Hans": "在此输入您的API密钥"
                          },
                          "required": false,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "default": "60",
                          "label": {
                              "en_US": "invoke timeout (unit:second)",
                              "zh_Hans": "调用超时时间 (单位:秒)"
                          },
                          "placeholder": {
                              "en_US": "Enter invoke timeout value",
                              "zh_Hans": "在此输入调用超时时间"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "invoke_timeout"
                      },
                      {
                          "default": "3",
                          "label": {
                              "en_US": "max retries",
                              "zh_Hans": "调用重试次数"
                          },
                          "placeholder": {
                              "en_US": "Enter max retries",
                              "zh_Hans": "在此输入调用重试次数"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "max_retries"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  }
              },
              "provider": "xinference",
              "supported_model_types": [
                  "llm",
                  "text-embedding",
                  "rerank",
                  "speech2text",
                  "tts"
              ],
              "models": []
          }
      },
      {
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "Anthropic's powerful models.",
              "zh_Hans": "Anthropic 的强大模型。"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "Anthropic"
          },
          "name": "anthropic",
          "plugins": {
              "models": [
                  "provider/anthropic.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": false
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.14",
          "model": {
              "background": "#F0F0EB",
              "configurate_methods": [
                  "predefined-model"
              ],
              "description": {
                  "en_US": "Anthropic’s powerful models, such as Claude 3.",
                  "zh_Hans": "Anthropic 的强大模型，例如 Claude 3。"
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py"
                      ],
                      "provider_source": "provider/anthropic.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API Key from Anthropic",
                      "zh_Hans": "从 Anthropic 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://console.anthropic.com/account/keys"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.png"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "Anthropic"
              },
              "models": [
                  {
                      "model": "claude-3-5-haiku-20241022",
                      "label": {
                          "en_US": "claude-3-5-haiku-20241022"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "1.00",
                          "output": "5.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "claude-3-5-sonnet-20240620",
                      "label": {
                          "en_US": "claude-3-5-sonnet-20240620"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "3.00",
                          "output": "15.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "claude-3-5-sonnet-20241022",
                      "label": {
                          "en_US": "claude-3-5-sonnet-20241022"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "3.00",
                          "output": "15.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "claude-3-7-sonnet-20250219",
                      "label": {
                          "en_US": "claude-3-7-sonnet-20250219"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "thinking",
                              "label": {
                                  "zh_Hans": "推理模式",
                                  "en_US": "Thinking Mode"
                              },
                              "type": "boolean",
                              "default": false,
                              "required": false,
                              "help": {
                                  "zh_Hans": "控制模型的推理能力。启用时，temperature、top_p和top_k将被禁用。",
                                  "en_US": "Controls the model's thinking capability. When enabled, temperature, top_p and top_k will be disabled."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "label": {
                                  "zh_Hans": "推理预算",
                                  "en_US": "Thinking Budget"
                              },
                              "type": "int",
                              "default": 1024,
                              "min": 0,
                              "max": 128000,
                              "required": false,
                              "help": {
                                  "zh_Hans": "推理的预算限制（最小1024），必须小于max_tokens。仅在推理模式启用时可用。",
                                  "en_US": "Budget limit for thinking (minimum 1024), must be less than max_tokens. Only available when thinking mode is enabled."
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 64000,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "extended_output",
                              "label": {
                                  "zh_Hans": "扩展输出",
                                  "en_US": "Extended Output"
                              },
                              "type": "boolean",
                              "default": false,
                              "help": {
                                  "zh_Hans": "启用长达128K标记的输出能力。",
                                  "en_US": "Enable capability for up to 128K output tokens."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "3.00",
                          "output": "15.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "claude-3-haiku-20240307",
                      "label": {
                          "en_US": "claude-3-haiku-20240307"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 4096,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.25",
                          "output": "1.25",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "claude-3-opus-20240229",
                      "label": {
                          "en_US": "claude-3-opus-20240229"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 4096,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "15.00",
                          "output": "75.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "claude-3-sonnet-20240229",
                      "label": {
                          "en_US": "claude-3-sonnet-20240229"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 4096,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "3.00",
                          "output": "15.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "claude-opus-4-20250514",
                      "label": {
                          "en_US": "claude-opus-4-20250514"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "thinking",
                              "label": {
                                  "zh_Hans": "推理模式",
                                  "en_US": "Thinking Mode"
                              },
                              "type": "boolean",
                              "default": false,
                              "required": false,
                              "help": {
                                  "zh_Hans": "控制模型的推理能力。启用时，temperature、top_p和top_k将被禁用。",
                                  "en_US": "Controls the model's thinking capability. When enabled, temperature, top_p and top_k will be disabled."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "label": {
                                  "zh_Hans": "推理预算",
                                  "en_US": "Thinking Budget"
                              },
                              "type": "int",
                              "default": 1024,
                              "min": 0,
                              "max": 32000,
                              "required": false,
                              "help": {
                                  "zh_Hans": "推理的预算限制（最小1024），必须小于max_tokens。仅在推理模式启用时可用。",
                                  "en_US": "Budget limit for thinking (minimum 1024), must be less than max_tokens. Only available when thinking mode is enabled."
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 32000,
                              "min": 1,
                              "max": 32000
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "15.00",
                          "output": "75.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "claude-sonnet-4-20250514",
                      "label": {
                          "en_US": "claude-sonnet-4-20250514"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "thinking",
                              "label": {
                                  "zh_Hans": "推理模式",
                                  "en_US": "Thinking Mode"
                              },
                              "type": "boolean",
                              "default": false,
                              "required": false,
                              "help": {
                                  "zh_Hans": "控制模型的推理能力。启用时，temperature、top_p和top_k将被禁用。",
                                  "en_US": "Controls the model's thinking capability. When enabled, temperature, top_p and top_k will be disabled."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "label": {
                                  "zh_Hans": "推理预算",
                                  "en_US": "Thinking Budget"
                              },
                              "type": "int",
                              "default": 1024,
                              "min": 0,
                              "max": 64000,
                              "required": false,
                              "help": {
                                  "zh_Hans": "推理的预算限制（最小1024），必须小于max_tokens。仅在推理模式启用时可用。",
                                  "en_US": "Budget limit for thinking (minimum 1024), must be less than max_tokens. Only available when thinking mode is enabled."
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 64000,
                              "min": 1,
                              "max": 64000
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "3.00",
                          "output": "15.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  }
              ],
              "provider": "anthropic",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "anthropic_api_key"
                      },
                      {
                          "label": {
                              "en_US": "API URL"
                          },
                          "placeholder": {
                              "en_US": "Enter your API URL",
                              "zh_Hans": "在此输入您的 API URL"
                          },
                          "required": false,
                          "type": "text-input",
                          "variable": "anthropic_api_url"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm"
              ]
          }
      },
      {
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "azure_openai",
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "Azure OpenAI"
          },
          "description": {
              "en_US": "Azure OpenAI Service Model"
          },
          "plugins": {
              "models": [
                  "provider/azure_openai.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": false
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.17",
          "model": {
              "background": "#E3F0FF",
              "configurate_methods": [
                  "customizable-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/text_embedding/text_embedding.py",
                          "models/tts/tts.py",
                          "models/speech2text/speech2text.py"
                      ],
                      "provider_source": "provider/azure_openai.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API key from Azure",
                      "zh_Hans": "从 Azure 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://azure.microsoft.com/en-us/products/ai-services/openai-service"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.png"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "Azure OpenAI Service Model"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Endpoint URL",
                              "zh_Hans": "API 域名"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Endpoint, eg: https://example.com/xxx",
                              "zh_Hans": "在此输入您的 API 域名，如：https://example.com/xxx"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "openai_api_base"
                      },
                      {
                          "label": {
                              "en_US": "API Key",
                              "zh_Hans": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API key here",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "openai_api_key"
                      },
                      {
                          "label": {
                              "en_US": "API Version",
                              "zh_Hans": "API 版本"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "2025-03-01-preview"
                                  },
                                  "value": "2025-03-01-preview"
                              },
                              {
                                  "label": {
                                      "en_US": "2025-02-01-preview"
                                  },
                                  "value": "2025-02-01-preview"
                              },
                              {
                                  "label": {
                                      "en_US": "2025-01-01-preview"
                                  },
                                  "value": "2025-01-01-preview"
                              },
                              {
                                  "label": {
                                      "en_US": "2024-12-01-preview"
                                  },
                                  "value": "2024-12-01-preview"
                              },
                              {
                                  "label": {
                                      "en_US": "2024-10-01-preview"
                                  },
                                  "value": "2024-10-01-preview"
                              },
                              {
                                  "label": {
                                      "en_US": "2024-09-01-preview"
                                  },
                                  "value": "2024-09-01-preview"
                              },
                              {
                                  "label": {
                                      "en_US": "2024-08-01-preview"
                                  },
                                  "value": "2024-08-01-preview"
                              },
                              {
                                  "label": {
                                      "en_US": "2024-07-01-preview"
                                  },
                                  "value": "2024-07-01-preview"
                              },
                              {
                                  "label": {
                                      "en_US": "2024-05-01-preview"
                                  },
                                  "value": "2024-05-01-preview"
                              },
                              {
                                  "label": {
                                      "en_US": "2024-04-01-preview"
                                  },
                                  "value": "2024-04-01-preview"
                              },
                              {
                                  "label": {
                                      "en_US": "2024-03-01-preview"
                                  },
                                  "value": "2024-03-01-preview"
                              },
                              {
                                  "label": {
                                      "en_US": "2024-02-15-preview"
                                  },
                                  "value": "2024-02-15-preview"
                              },
                              {
                                  "label": {
                                      "en_US": "2023-12-01-preview"
                                  },
                                  "value": "2023-12-01-preview"
                              },
                              {
                                  "label": {
                                      "en_US": "2024-02-01"
                                  },
                                  "value": "2024-02-01"
                              },
                              {
                                  "label": {
                                      "en_US": "2024-06-01"
                                  },
                                  "value": "2024-06-01"
                              },
                              {
                                  "label": {
                                      "en_US": "2024-10-21"
                                  },
                                  "value": "2024-10-21"
                              }
                          ],
                          "placeholder": {
                              "en_US": "Select your API Version here",
                              "zh_Hans": "在此选择您的 API 版本"
                          },
                          "required": true,
                          "type": "select",
                          "variable": "openai_api_version"
                      },
                      {
                          "label": {
                              "en_US": "Base Model",
                              "zh_Hans": "基础模型"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "gpt-35-turbo"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "gpt-35-turbo"
                              },
                              {
                                  "label": {
                                      "en_US": "gpt-35-turbo-0125"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "gpt-35-turbo-0125"
                              },
                              {
                                  "label": {
                                      "en_US": "gpt-35-turbo-16k"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "gpt-35-turbo-16k"
                              },
                              {
                                  "label": {
                                      "en_US": "gpt-4"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "gpt-4"
                              },
                              {
                                  "label": {
                                      "en_US": "gpt-4-32k"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "gpt-4-32k"
                              },
                              {
                                  "label": {
                                      "en_US": "gpt-4.5-preview"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "gpt-4.5-preview"
                              },
                              {
                                  "label": {
                                      "en_US": "o3-mini"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "o3-mini"
                              },
                              {
                                  "label": {
                                      "en_US": "o3"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "o3"
                              },
                              {
                                  "label": {
                                      "en_US": "o4-mini"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "o4-mini"
                              },
                              {
                                  "label": {
                                      "en_US": "o1-mini"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "o1-mini"
                              },
                              {
                                  "label": {
                                      "en_US": "o1-preview"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "o1-preview"
                              },
                              {
                                  "label": {
                                      "en_US": "o1"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "o1"
                              },
                              {
                                  "label": {
                                      "en_US": "gpt-4o-mini"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "gpt-4o-mini"
                              },
                              {
                                  "label": {
                                      "en_US": "gpt-4o-mini-2024-07-18"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "gpt-4o-mini-2024-07-18"
                              },
                              {
                                  "label": {
                                      "en_US": "gpt-4o"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "gpt-4o"
                              },
                              {
                                  "label": {
                                      "en_US": "gpt-4o-2024-05-13"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "gpt-4o-2024-05-13"
                              },
                              {
                                  "label": {
                                      "en_US": "gpt-4o-2024-08-06"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "gpt-4o-2024-08-06"
                              },
                              {
                                  "label": {
                                      "en_US": "gpt-4.1"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "gpt-4.1"
                              },
                              {
                                  "label": {
                                      "en_US": "gpt-4.1-mini"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "gpt-4.1-mini"
                              },
                              {
                                  "label": {
                                      "en_US": "gpt-4.1-nano"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "gpt-4.1-nano"
                              },
                              {
                                  "label": {
                                      "en_US": "gpt-4-turbo"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "gpt-4-turbo"
                              },
                              {
                                  "label": {
                                      "en_US": "gpt-4-turbo-2024-04-09"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "gpt-4-turbo-2024-04-09"
                              },
                              {
                                  "label": {
                                      "en_US": "gpt-4o-2024-11-20"
                                  },
                                  "value": "gpt-4o-2024-11-20",
                                  "show_on": [
                                      {
                                          "variable": "__model_type",
                                          "value": "llm"
                                      }
                                  ]
                              },
                              {
                                  "label": {
                                      "en_US": "gpt-4-0125-preview"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "gpt-4-0125-preview"
                              },
                              {
                                  "label": {
                                      "en_US": "gpt-4-1106-preview"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "gpt-4-1106-preview"
                              },
                              {
                                  "label": {
                                      "en_US": "gpt-4-vision-preview"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "gpt-4-vision-preview"
                              },
                              {
                                  "label": {
                                      "en_US": "gpt-35-turbo-instruct"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "gpt-35-turbo-instruct"
                              },
                              {
                                  "label": {
                                      "en_US": "text-embedding-ada-002"
                                  },
                                  "show_on": [
                                      {
                                          "value": "text-embedding",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "text-embedding-ada-002"
                              },
                              {
                                  "label": {
                                      "en_US": "text-embedding-3-small"
                                  },
                                  "show_on": [
                                      {
                                          "value": "text-embedding",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "text-embedding-3-small"
                              },
                              {
                                  "label": {
                                      "en_US": "text-embedding-3-large"
                                  },
                                  "show_on": [
                                      {
                                          "value": "text-embedding",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "text-embedding-3-large"
                              },
                              {
                                  "label": {
                                      "en_US": "whisper-1"
                                  },
                                  "show_on": [
                                      {
                                          "value": "speech2text",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "whisper-1"
                              },
                              {
                                  "label": {
                                      "en_US": "tts-1"
                                  },
                                  "show_on": [
                                      {
                                          "value": "tts",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "tts-1"
                              },
                              {
                                  "label": {
                                      "en_US": "tts-1-hd"
                                  },
                                  "show_on": [
                                      {
                                          "value": "tts",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "tts-1-hd"
                              }
                          ],
                          "placeholder": {
                              "en_US": "Enter your model version",
                              "zh_Hans": "在此输入您的模型版本"
                          },
                          "required": true,
                          "type": "select",
                          "variable": "base_model_name"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Deployment Name",
                          "zh_Hans": "部署名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your Deployment Name here, matching the Azure deployment name.",
                          "zh_Hans": "在此输入您的部署名称，与 Azure 部署名称匹配。"
                      }
                  }
              },
              "models": [],
              "provider": "azure_openai",
              "supported_model_types": [
                  "llm",
                  "text-embedding",
                  "speech2text",
                  "tts"
              ]
          }
      },
      {
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "openrouter",
          "author": "ssrag",
          "icon": "openrouter_square.svg",
          "description": {
              "en_US": "OpenRouter is a powerful platform that provides access to a diverse set of language models, including both commercial and open-source options.",
              "zh_Hans": "OpenRouter 是一个强大的平台，提供对多种语言模型的访问，包括商业和开源选项。"
          },
          "label": {
              "en_US": "OpenRouter"
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": false
                  }
              }
          },
          "type": "plugin",
          "plugins": {
              "models": [
                  "provider/openrouter.yaml"
              ]
          },
          "version": "0.0.10",
          "created_at": "2024-09-20T00:13:50.292989-04:00",
          "model": {
              "background": "#F1EFED",
              "configurate_methods": [
                  "predefined-model",
                  "customizable-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py"
                      ],
                      "provider_source": "provider/openrouter.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API key from openrouter.ai",
                      "zh_Hans": "从 openrouter.ai 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://openrouter.ai/keys"
                  }
              },
              "icon_large": {
                  "en_US": "openrouter.svg"
              },
              "icon_small": {
                  "en_US": "openrouter_square.svg"
              },
              "label": {
                  "en_US": "OpenRouter"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "default": "chat",
                          "label": {
                              "en_US": "Completion mode"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Completion",
                                      "zh_Hans": "补全"
                                  },
                                  "value": "completion"
                              },
                              {
                                  "label": {
                                      "en_US": "Chat",
                                      "zh_Hans": "对话"
                                  },
                                  "value": "chat"
                              }
                          ],
                          "placeholder": {
                              "en_US": "Select completion mode",
                              "zh_Hans": "选择对话类型"
                          },
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "select",
                          "variable": "mode"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Model context size",
                              "zh_Hans": "模型上下文长度"
                          },
                          "placeholder": {
                              "en_US": "Enter your Model context size",
                              "zh_Hans": "在此输入您的模型上下文长度"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "context_size"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Upper bound for max tokens",
                              "zh_Hans": "最大 token 上限"
                          },
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "text-input",
                          "variable": "max_tokens_to_sample"
                      },
                      {
                          "default": "no_support",
                          "label": {
                              "en_US": "Vision Support",
                              "zh_Hans": "是否支持 Vision"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Yes",
                                      "zh_Hans": "是"
                                  },
                                  "value": "support"
                              },
                              {
                                  "label": {
                                      "en_US": "No",
                                      "zh_Hans": "否"
                                  },
                                  "value": "no_support"
                              }
                          ],
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "radio",
                          "variable": "vision_support"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter full model name",
                          "zh_Hans": "输入模型全称"
                      }
                  }
              },
              "models": [
                  {
                      "model": "anthropic/claude-3-5-haiku",
                      "label": {
                          "en_US": "claude-3-5-haiku"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "1",
                          "output": "5",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "anthropic/claude-3.5-sonnet",
                      "label": {
                          "en_US": "claude-3.5-sonnet"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "3.00",
                          "output": "15.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "anthropic/claude-3-haiku",
                      "label": {
                          "en_US": "claude-3-haiku"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 4096,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.25",
                          "output": "1.25",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "anthropic/claude-3-opus",
                      "label": {
                          "en_US": "claude-3-opus"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 4096,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "15.00",
                          "output": "75.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "anthropic/claude-3-sonnet",
                      "label": {
                          "en_US": "claude-3-sonnet"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 4096,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "3.00",
                          "output": "15.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "anthropic/claude-3.7-sonnet",
                      "label": {
                          "en_US": "claude-3.7-sonnet"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "thinking",
                              "label": {
                                  "zh_Hans": "推理模式",
                                  "en_US": "Thinking Mode"
                              },
                              "type": "boolean",
                              "default": false,
                              "required": false,
                              "help": {
                                  "zh_Hans": "控制模型的推理能力。启用时，temperature、top_p和top_k将被禁用。",
                                  "en_US": "Controls the model's thinking capability. When enabled, temperature, top_p and top_k will be disabled."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "label": {
                                  "zh_Hans": "推理预算",
                                  "en_US": "Thinking Budget"
                              },
                              "type": "int",
                              "default": 1024,
                              "min": 0,
                              "max": 128000,
                              "required": false,
                              "help": {
                                  "zh_Hans": "推理的预算限制（最小1024），必须小于max_tokens。仅在推理模式启用时可用。",
                                  "en_US": "Budget limit for thinking (minimum 1024), must be less than max_tokens. Only available when thinking mode is enabled."
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 64000,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "extended_output",
                              "label": {
                                  "zh_Hans": "扩展输出",
                                  "en_US": "Extended Output"
                              },
                              "type": "boolean",
                              "default": false,
                              "help": {
                                  "zh_Hans": "启用长达128K标记的输出能力。",
                                  "en_US": "Enable capability for up to 128K output tokens."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "3.00",
                          "output": "15.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "cohere/command-r-plus",
                      "label": {
                          "en_US": "command-r-plus"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "max": 5.0
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0.01,
                              "max": 0.99
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "3",
                          "output": "15",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "cohere/command-r",
                      "label": {
                          "en_US": "command-r"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "max": 5.0
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0.01,
                              "max": 0.99
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.5",
                          "output": "1.5",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "deepseek/deepseek-chat",
                      "label": {
                          "en_US": "deepseek-chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 1,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的多样性和随机性。数值越小，越严谨；数值越大，越发散。",
                                  "en_US": "Control the diversity and randomness of generated results. The smaller the value, the more rigorous it is; the larger the value, the more divergent it is."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 4096,
                              "min": 1,
                              "max": 4096,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 1,
                              "min": 0.01,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的随机性。数值越小，随机性越弱；数值越大，随机性越强。一般而言，top_p 和 temperature 两个参数选择一个进行调整即可。",
                                  "en_US": "Control the randomness of generated results. The smaller the value, the weaker the randomness; the larger the value, the stronger the randomness. Generally speaking, you can adjust one of the two parameters top_p and temperature."
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "default": 0,
                              "min": -2.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "介于 -2.0 和 2.0 之间的数字。如果该值为正，那么新 token 会根据其在已有文本中的出现频率受到相应的惩罚，降低模型重复相同内容的可能性。",
                                  "en_US": "A number between -2.0 and 2.0. If the value is positive, new tokens are penalized based on their frequency of occurrence in existing text, reducing the likelihood that the model will repeat the same content."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.14",
                          "output": "0.28",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "deepseek/deepseek-coder",
                      "label": {
                          "en_US": "deepseek-coder"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 1,
                              "default": 0.5
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 4096,
                              "default": 1024
                          }
                      ],
                      "pricing": {
                          "input": "0.14",
                          "output": "0.28",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "google/gemini-flash-1.5",
                      "label": {
                          "en_US": "gemini-flash-1.5"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.25",
                          "output": "0.75",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "google/gemini-pro-1.5",
                      "label": {
                          "en_US": "gemini-pro-1.5"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "2.5",
                          "output": "7.5",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "google/gemini-pro",
                      "label": {
                          "en_US": "gemini-pro"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 30720
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 2048,
                              "min": 1,
                              "max": 2048
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.125",
                          "output": "0.375",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "openai/gpt-3.5-turbo",
                      "label": {
                          "en_US": "gpt-3.5-turbo"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16385
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.5",
                          "output": "1.5",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "openai/gpt-4-32k",
                      "label": {
                          "en_US": "gpt-4-32k"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 32768
                          },
                          {
                              "name": "seed",
                              "label": {
                                  "zh_Hans": "种子",
                                  "en_US": "Seed"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "如果指定，模型将尽最大努力进行确定性采样，使得重复的具有相同种子和参数的请求应该返回相同的结果。不能保证确定性，您应该参考 system_fingerprint 响应参数来监视变化。",
                                  "en_US": "If specified, model will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes in the backend."
                              },
                              "required": false
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "60",
                          "output": "120",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "openai/gpt-4",
                      "label": {
                          "en_US": "gpt-4"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "seed",
                              "label": {
                                  "zh_Hans": "种子",
                                  "en_US": "Seed"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "如果指定，模型将尽最大努力进行确定性采样，使得重复的具有相同种子和参数的请求应该返回相同的结果。不能保证确定性，您应该参考 system_fingerprint 响应参数来监视变化。",
                                  "en_US": "If specified, model will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes in the backend."
                              },
                              "required": false
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "30",
                          "output": "60",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4o-2024-08-06",
                      "label": {
                          "zh_Hans": "gpt-4o-2024-08-06",
                          "en_US": "gpt-4o-2024-08-06"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 16384
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "2.50",
                          "output": "10.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "openai/gpt-4o-mini",
                      "label": {
                          "en_US": "gpt-4o-mini"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 16384
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.15",
                          "output": "0.60",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "openai/gpt-4o",
                      "label": {
                          "en_US": "gpt-4o"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "5.00",
                          "output": "15.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta-llama/llama-3-70b-instruct",
                      "label": {
                          "en_US": "llama-3-70b-instruct"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "completion",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 512,
                              "min": 1,
                              "max": 2048
                          }
                      ],
                      "pricing": {
                          "input": "0.59",
                          "output": "0.79",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta-llama/llama-3-8b-instruct",
                      "label": {
                          "en_US": "llama-3-8b-instruct"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "completion",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 512,
                              "min": 1,
                              "max": 2048
                          }
                      ],
                      "pricing": {
                          "input": "0.07",
                          "output": "0.07",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta-llama/llama-3.1-405b-instruct",
                      "label": {
                          "en_US": "llama-3.1-405b-instruct"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 512,
                              "min": 1,
                              "max": 131072
                          }
                      ],
                      "pricing": {
                          "input": "2.7",
                          "output": "2.7",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta-llama/llama-3.1-70b-instruct",
                      "label": {
                          "en_US": "llama-3.1-70b-instruct"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 512,
                              "min": 1,
                              "max": 131072
                          }
                      ],
                      "pricing": {
                          "input": "0.52",
                          "output": "0.75",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta-llama/llama-3.1-8b-instruct",
                      "label": {
                          "en_US": "llama-3.1-8b-instruct"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 512,
                              "min": 1,
                              "max": 131072
                          }
                      ],
                      "pricing": {
                          "input": "0.06",
                          "output": "0.06",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta-llama/llama-3.2-11b-vision-instruct",
                      "label": {
                          "zh_Hans": "llama-3.2-11b-vision-instruct",
                          "en_US": "llama-3.2-11b-vision-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.055",
                          "output": "0.055",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta-llama/llama-3.2-1b-instruct",
                      "label": {
                          "zh_Hans": "llama-3.2-1b-instruct",
                          "en_US": "llama-3.2-1b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.01",
                          "output": "0.02",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta-llama/llama-3.2-3b-instruct",
                      "label": {
                          "zh_Hans": "llama-3.2-3b-instruct",
                          "en_US": "llama-3.2-3b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.03",
                          "output": "0.05",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta-llama/llama-3.2-90b-vision-instruct",
                      "label": {
                          "zh_Hans": "llama-3.2-90b-vision-instruct",
                          "en_US": "llama-3.2-90b-vision-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.35",
                          "output": "0.4",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "mistralai/mistral-7b-instruct",
                      "label": {
                          "en_US": "mistral-7b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "completion",
                          "context_size": 8000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 2048
                          }
                      ],
                      "pricing": {
                          "input": "0.07",
                          "output": "0.07",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "mistralai/mixtral-8x22b-instruct",
                      "label": {
                          "en_US": "mixtral-8x22b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "completion",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 8000
                          }
                      ],
                      "pricing": {
                          "input": "0.65",
                          "output": "0.65",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "mistralai/mixtral-8x7b-instruct",
                      "label": {
                          "zh_Hans": "mixtral-8x7b-instruct",
                          "en_US": "mixtral-8x7b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "completion",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 8000
                          }
                      ],
                      "pricing": {
                          "input": "0.24",
                          "output": "0.24",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "openai/o1-mini",
                      "label": {
                          "en_US": "o1-mini"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 65536
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "3.00",
                          "output": "12.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "openai/o1-preview",
                      "label": {
                          "en_US": "o1-preview"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 32768
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "15.00",
                          "output": "60.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "openai/o3-mini-2025-01-31",
                      "label": {
                          "en_US": "o3-mini-2025-01-31"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 100000
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "1.10",
                          "output": "4.40",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "openai/o3-mini",
                      "label": {
                          "en_US": "o3-mini"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 100000
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "1.10",
                          "output": "4.40",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "qwen/qwen-2-72b-instruct",
                      "label": {
                          "en_US": "qwen-2-72b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "completion",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 4096,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          }
                      ],
                      "pricing": {
                          "input": "0.59",
                          "output": "0.79",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "qwen/qwen-2.5-72b-instruct",
                      "label": {
                          "en_US": "qwen-2.5-72b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          }
                      ],
                      "pricing": {
                          "input": "0.35",
                          "output": "0.4",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  }
              ],
              "provider": "openrouter",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm"
              ]
          }
      },
      {
          "version": "0.1.5",
          "type": "plugin",
          "author": "yangyaofei",
          "name": "vllm",
          "label": {
              "en_US": "vllm",
              "ja_JP": "vllm",
              "zh_Hans": "vllm",
              "pt_BR": "vllm"
          },
          "description": {
              "en_US": "vllm provider for guided support https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html#id5",
              "ja_JP": "vllm provider for guided support https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html#id5",
              "zh_Hans": "vllm provider for guided support https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html#id5",
              "pt_BR": "vllm provider for guided support https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html#id5"
          },
          "icon": "vLLM-Logo.svg",
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "text_embedding": false,
                      "rerank": false,
                      "tts": false,
                      "speech2text": false,
                      "moderation": false
                  }
              }
          },
          "plugins": {
              "models": [
                  "provider/vllm.yaml"
              ]
          },
          "meta": {
              "version": "0.1.5",
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "language": "python",
                  "version": "3.12",
                  "entrypoint": "main"
              }
          },
          "created_at": "2025-03-25",
          "verified": false,
          "model": {
              "provider": "vllm",
              "label": {
                  "en_US": "Vllm"
              },
              "description": {
                  "en_US": "Models provided by vllm with guided inference supported.",
                  "zh_Hans": "Vllm openai guided 支持"
              },
              "icon_small": {
                  "en_US": "vLLM-Logo.svg"
              },
              "icon_large": {
                  "en_US": "vLLM-Logo.svg"
              },
              "background": "#E5E7EB",
              "supported_model_types": [
                  "llm"
              ],
              "configurate_methods": [
                  "customizable-model"
              ],
              "model_credential_schema": {
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  },
                  "credential_form_schemas": [
                      {
                          "variable": "api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "type": "secret-input",
                          "required": false,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Key",
                              "en_US": "Enter your API Key"
                          }
                      },
                      {
                          "variable": "endpoint_url",
                          "label": {
                              "zh_Hans": "API endpoint URL",
                              "en_US": "API endpoint URL"
                          },
                          "type": "text-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "Base URL, e.g. https://api.openai.com/v1",
                              "en_US": "Base URL, e.g. https://api.openai.com/v1"
                          }
                      },
                      {
                          "variable": "endpoint_model_name",
                          "label": {
                              "zh_Hans": "API endpoint中的模型名称",
                              "en_US": "model name for API endpoint"
                          },
                          "type": "text-input",
                          "required": false,
                          "placeholder": {
                              "zh_Hans": "endpoint model name, e.g. chatgpt4.0",
                              "en_US": "endpoint model name, e.g. chatgpt4.0"
                          }
                      },
                      {
                          "variable": "mode",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "en_US": "Completion mode"
                          },
                          "type": "select",
                          "required": false,
                          "default": "chat",
                          "placeholder": {
                              "zh_Hans": "选择对话类型",
                              "en_US": "Select completion mode"
                          },
                          "options": [
                              {
                                  "value": "completion",
                                  "label": {
                                      "en_US": "Completion",
                                      "zh_Hans": "补全"
                                  }
                              },
                              {
                                  "value": "chat",
                                  "label": {
                                      "en_US": "Chat",
                                      "zh_Hans": "对话"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "context_size",
                          "label": {
                              "zh_Hans": "模型上下文长度",
                              "en_US": "Model context size"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "type": "text-input",
                          "default": "4096",
                          "placeholder": {
                              "zh_Hans": "在此输入您的模型上下文长度",
                              "en_US": "Enter your Model context size"
                          }
                      },
                      {
                          "variable": "max_tokens_to_sample",
                          "label": {
                              "zh_Hans": "最大 token 上限",
                              "en_US": "Upper bound for max tokens"
                          },
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "default": "4096",
                          "type": "text-input"
                      },
                      {
                          "variable": "agent_though_support",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "en_US": "Agent Thought"
                          },
                          "type": "select",
                          "required": false,
                          "default": "not_supported",
                          "options": [
                              {
                                  "value": "supported",
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  }
                              },
                              {
                                  "value": "not_supported",
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "function_calling_type",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "en_US": "Function calling"
                          },
                          "type": "select",
                          "required": false,
                          "default": "no_call",
                          "options": [
                              {
                                  "value": "function_call",
                                  "label": {
                                      "en_US": "Function Call",
                                      "zh_Hans": "Function Call"
                                  }
                              },
                              {
                                  "value": "tool_call",
                                  "label": {
                                      "en_US": "Tool Call",
                                      "zh_Hans": "Tool Call"
                                  }
                              },
                              {
                                  "value": "no_call",
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "stream_function_calling",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "en_US": "Stream function calling"
                          },
                          "type": "select",
                          "required": false,
                          "default": "not_supported",
                          "options": [
                              {
                                  "value": "supported",
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  }
                              },
                              {
                                  "value": "not_supported",
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "vision_support",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "zh_Hans": "Vision 支持",
                              "en_US": "Vision Support"
                          },
                          "type": "select",
                          "required": false,
                          "default": "no_support",
                          "options": [
                              {
                                  "value": "support",
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  }
                              },
                              {
                                  "value": "no_support",
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "stream_mode_delimiter",
                          "label": {
                              "zh_Hans": "流模式返回结果的分隔符",
                              "en_US": "Delimiter for streaming results"
                          },
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "default": "\\n\\n",
                          "type": "text-input"
                      }
                  ]
              },
              "extra": {
                  "python": {
                      "provider_source": "provider/vllm.py",
                      "model_sources": [
                          "models/llm/llm.py"
                      ]
                  }
              },
              "models": []
          }
      },
      {
          "type": "plugin",
          "version": "0.0.10",
          "author": "ssrag",
          "name": "zhipuai",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "ZHIPU AI",
              "zh_Hans": "智谱 AI"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "Zhipuai",
              "ja_JP": "Zhipuai",
              "zh_Hans": "Zhipuai",
              "pt_BR": "Zhipuai"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "plugins": {
              "models": [
                  "provider/zhipuai.yaml"
              ]
          },
          "resource": {
              "memory": 1048576,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "text_embedding": true
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "model": {
              "background": "#EFF1FE",
              "configurate_methods": [
                  "predefined-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/text_embedding/text_embedding.py"
                      ],
                      "provider_source": "provider/zhipuai.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API key from ZHIPU AI",
                      "zh_Hans": "从智谱 AI 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://open.bigmodel.cn/usercenter/apikeys"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg",
                  "zh_Hans": "icon_l_zh.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "ZHIPU AI",
                  "zh_Hans": "智谱 AI"
              },
              "models": [
                  {
                      "model": "chatglm_lite",
                      "label": {
                          "en_US": "chatglm_lite"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "chat"
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.9,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          }
                      ],
                      "deprecated": true
                  },
                  {
                      "model": "chatglm_lite_32k",
                      "label": {
                          "en_US": "chatglm_lite_32k"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "chat"
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.9,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          }
                      ],
                      "deprecated": true
                  },
                  {
                      "model": "chatglm_pro",
                      "label": {
                          "en_US": "chatglm_pro"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "chat"
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.9,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          }
                      ],
                      "deprecated": true
                  },
                  {
                      "model": "chatglm_std",
                      "label": {
                          "en_US": "chatglm_std"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "chat"
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.9,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          }
                      ],
                      "deprecated": true
                  },
                  {
                      "model": "chatglm_turbo",
                      "label": {
                          "en_US": "chatglm_turbo"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "chat"
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "do_sample",
                              "label": {
                                  "zh_Hans": "采样策略",
                                  "en_US": "Sampling strategy"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。",
                                  "en_US": "When `do_sample` is set to true, the sampling strategy is enabled. When `do_sample` is set to false, the sampling strategies such as `temperature` and `top_p` will not take effect. The default value is true."
                              },
                              "default": true
                          },
                          {
                              "name": "return_type",
                              "label": {
                                  "zh_Hans": "回复类型",
                                  "en_US": "Return Type"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "用于控制每次返回内容的类型，空或者没有此字段时默认按照 json_string 返回，json_string 返回标准的 JSON 字符串，text 返回原始的文本内容。",
                                  "en_US": "Used to control the type of content returned each time. When it is empty or does not have this field, it will be returned as json_string by default. json_string returns a standard JSON string, and text returns the original text content."
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_string"
                              ]
                          }
                      ],
                      "deprecated": true
                  },
                  {
                      "model": "glm-4-0520",
                      "label": {
                          "en_US": "glm-4-0520"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "do_sample",
                              "label": {
                                  "zh_Hans": "采样策略",
                                  "en_US": "Sampling strategy"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。",
                                  "en_US": "When `do_sample` is set to true, the sampling strategy is enabled. When `do_sample` is set to false, the sampling strategies such as `temperature` and `top_p` will not take effect. The default value is true."
                              },
                              "default": true
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 4095
                          },
                          {
                              "name": "web_search",
                              "type": "boolean",
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "default": false,
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.1",
                          "output": "0.1",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "glm-4-air-0111",
                      "label": {
                          "en_US": "glm-4-air-0111"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "do_sample",
                              "label": {
                                  "zh_Hans": "采样策略",
                                  "en_US": "Sampling strategy"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。",
                                  "en_US": "When `do_sample` is set to true, the sampling strategy is enabled. When `do_sample` is set to false, the sampling strategies such as `temperature` and `top_p` will not take effect. The default value is true."
                              },
                              "default": true
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 4095
                          },
                          {
                              "name": "web_search",
                              "type": "boolean",
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "default": false,
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.0005",
                          "output": "0.0005",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "glm-4-air-250414",
                      "label": {
                          "en_US": "glm-4-air-250414"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "do_sample",
                              "label": {
                                  "zh_Hans": "采样策略",
                                  "en_US": "Sampling strategy"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。",
                                  "en_US": "When `do_sample` is set to true, the sampling strategy is enabled. When `do_sample` is set to false, the sampling strategies such as `temperature` and `top_p` will not take effect. The default value is true."
                              },
                              "default": true
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 4095
                          },
                          {
                              "name": "web_search",
                              "type": "boolean",
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "default": false,
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.0005",
                          "output": "0.0005",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "glm-4-air",
                      "label": {
                          "en_US": "glm-4-air"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "do_sample",
                              "label": {
                                  "zh_Hans": "采样策略",
                                  "en_US": "Sampling strategy"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。",
                                  "en_US": "When `do_sample` is set to true, the sampling strategy is enabled. When `do_sample` is set to false, the sampling strategies such as `temperature` and `top_p` will not take effect. The default value is true."
                              },
                              "default": true
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 4095
                          },
                          {
                              "name": "web_search",
                              "type": "boolean",
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "default": false,
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.001",
                          "output": "0.001",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "glm-4-airx",
                      "label": {
                          "en_US": "glm-4-airx"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "do_sample",
                              "label": {
                                  "zh_Hans": "采样策略",
                                  "en_US": "Sampling strategy"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。",
                                  "en_US": "When `do_sample` is set to true, the sampling strategy is enabled. When `do_sample` is set to false, the sampling strategies such as `temperature` and `top_p` will not take effect. The default value is true."
                              },
                              "default": true
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 4095
                          },
                          {
                              "name": "web_search",
                              "type": "boolean",
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "default": false,
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.01",
                          "output": "0.01",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "glm-4-flash-250414",
                      "label": {
                          "en_US": "glm-4-flash-250414"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "do_sample",
                              "label": {
                                  "zh_Hans": "采样策略",
                                  "en_US": "Sampling strategy"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。",
                                  "en_US": "When `do_sample` is set to true, the sampling strategy is enabled. When `do_sample` is set to false, the sampling strategies such as `temperature` and `top_p` will not take effect. The default value is true."
                              },
                              "default": true
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 4095
                          },
                          {
                              "name": "web_search",
                              "type": "boolean",
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "default": false,
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "glm-4-flash",
                      "label": {
                          "en_US": "glm-4-flash"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "do_sample",
                              "label": {
                                  "zh_Hans": "采样策略",
                                  "en_US": "Sampling strategy"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。",
                                  "en_US": "When `do_sample` is set to true, the sampling strategy is enabled. When `do_sample` is set to false, the sampling strategies such as `temperature` and `top_p` will not take effect. The default value is true."
                              },
                              "default": true
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 4095
                          },
                          {
                              "name": "web_search",
                              "type": "boolean",
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "default": false,
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "glm-4-flashx-250414",
                      "label": {
                          "en_US": "glm-4-flashx-250414"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "do_sample",
                              "label": {
                                  "zh_Hans": "采样策略",
                                  "en_US": "Sampling strategy"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。",
                                  "en_US": "When `do_sample` is set to true, the sampling strategy is enabled. When `do_sample` is set to false, the sampling strategies such as `temperature` and `top_p` will not take effect. The default value is true."
                              },
                              "default": true
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 4095
                          },
                          {
                              "name": "web_search",
                              "type": "boolean",
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "default": false,
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "glm-4-flashx",
                      "label": {
                          "en_US": "glm-4-flashx"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "do_sample",
                              "label": {
                                  "zh_Hans": "采样策略",
                                  "en_US": "Sampling strategy"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。",
                                  "en_US": "When `do_sample` is set to true, the sampling strategy is enabled. When `do_sample` is set to false, the sampling strategies such as `temperature` and `top_p` will not take effect. The default value is true."
                              },
                              "default": true
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 4095
                          },
                          {
                              "name": "web_search",
                              "type": "boolean",
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "default": false,
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "glm-4v-flash",
                      "label": {
                          "en_US": "glm-4v-flash"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "features": [
                          "vision"
                      ],
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.6,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "do_sample",
                              "label": {
                                  "zh_Hans": "采样策略",
                                  "en_US": "Sampling strategy"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。",
                                  "en_US": "When `do_sample` is set to true, the sampling strategy is enabled. When `do_sample` is set to false, the sampling strategies such as `temperature` and `top_p` will not take effect. The default value is true."
                              },
                              "default": true
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 1024
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "glm-z1-air",
                      "label": {
                          "en_US": "glm-z1-air"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "do_sample",
                              "label": {
                                  "zh_Hans": "采样策略",
                                  "en_US": "Sampling strategy"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。",
                                  "en_US": "When `do_sample` is set to true, the sampling strategy is enabled. When `do_sample` is set to false, the sampling strategies such as `temperature` and `top_p` will not take effect. The default value is true."
                              },
                              "default": true
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 30720
                          }
                      ],
                      "pricing": {
                          "input": "0.0005",
                          "output": "0.0005",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "glm-z1-airx",
                      "label": {
                          "en_US": "glm-z1-airx"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "do_sample",
                              "label": {
                                  "zh_Hans": "采样策略",
                                  "en_US": "Sampling strategy"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。",
                                  "en_US": "When `do_sample` is set to true, the sampling strategy is enabled. When `do_sample` is set to false, the sampling strategies such as `temperature` and `top_p` will not take effect. The default value is true."
                              },
                              "default": true
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 30720
                          }
                      ],
                      "pricing": {
                          "input": "0.005",
                          "output": "0.005",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "glm-z1-flash",
                      "label": {
                          "en_US": "glm-z1-flash"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "do_sample",
                              "label": {
                                  "zh_Hans": "采样策略",
                                  "en_US": "Sampling strategy"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。",
                                  "en_US": "When `do_sample` is set to true, the sampling strategy is enabled. When `do_sample` is set to false, the sampling strategies such as `temperature` and `top_p` will not take effect. The default value is true."
                              },
                              "default": true
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 30720
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "glm-z1-flashx",
                      "label": {
                          "en_US": "glm-z1-flashx"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "do_sample",
                              "label": {
                                  "zh_Hans": "采样策略",
                                  "en_US": "Sampling strategy"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。",
                                  "en_US": "When `do_sample` is set to true, the sampling strategy is enabled. When `do_sample` is set to false, the sampling strategies such as `temperature` and `top_p` will not take effect. The default value is true."
                              },
                              "default": true
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 30720
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "glm-3-turbo",
                      "label": {
                          "en_US": "glm-3-turbo"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "do_sample",
                              "label": {
                                  "zh_Hans": "采样策略",
                                  "en_US": "Sampling strategy"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。",
                                  "en_US": "When `do_sample` is set to true, the sampling strategy is enabled. When `do_sample` is set to false, the sampling strategies such as `temperature` and `top_p` will not take effect. The default value is true."
                              },
                              "default": true
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "web_search",
                              "type": "boolean",
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "default": false,
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.001",
                          "output": "0.001",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "glm-4",
                      "label": {
                          "en_US": "glm-4"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "do_sample",
                              "label": {
                                  "zh_Hans": "采样策略",
                                  "en_US": "Sampling strategy"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。",
                                  "en_US": "When `do_sample` is set to true, the sampling strategy is enabled. When `do_sample` is set to false, the sampling strategies such as `temperature` and `top_p` will not take effect. The default value is true."
                              },
                              "default": true
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 4095
                          },
                          {
                              "name": "web_search",
                              "type": "boolean",
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "default": false,
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.1",
                          "output": "0.1",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "glm-4v",
                      "label": {
                          "en_US": "glm-4v"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2048
                      },
                      "features": [
                          "vision"
                      ],
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.6,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "do_sample",
                              "label": {
                                  "zh_Hans": "采样策略",
                                  "en_US": "Sampling strategy"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。",
                                  "en_US": "When `do_sample` is set to true, the sampling strategy is enabled. When `do_sample` is set to false, the sampling strategies such as `temperature` and `top_p` will not take effect. The default value is true."
                              },
                              "default": true
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 1024
                          },
                          {
                              "name": "web_search",
                              "type": "boolean",
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "default": false,
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.05",
                          "output": "0.05",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "glm-4v-plus",
                      "label": {
                          "en_US": "glm-4v-plus"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "features": [
                          "vision",
                          "video"
                      ],
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.6,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "do_sample",
                              "label": {
                                  "zh_Hans": "采样策略",
                                  "en_US": "Sampling strategy"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。",
                                  "en_US": "When `do_sample` is set to true, the sampling strategy is enabled. When `do_sample` is set to false, the sampling strategies such as `temperature` and `top_p` will not take effect. The default value is true."
                              },
                              "default": true
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 1024
                          },
                          {
                              "name": "web_search",
                              "type": "boolean",
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "default": false,
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.01",
                          "output": "0.01",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "glm-4-long",
                      "label": {
                          "en_US": "glm-4-long"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "do_sample",
                              "label": {
                                  "zh_Hans": "采样策略",
                                  "en_US": "Sampling strategy"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。",
                                  "en_US": "When `do_sample` is set to true, the sampling strategy is enabled. When `do_sample` is set to false, the sampling strategies such as `temperature` and `top_p` will not take effect. The default value is true."
                              },
                              "default": true
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 4095
                          },
                          {
                              "name": "web_search",
                              "type": "boolean",
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "default": false,
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.001",
                          "output": "0.001",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "glm-4-plus",
                      "label": {
                          "en_US": "glm-4-plus"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.95,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Sampling temperature, controls the randomness of the output, must be a positive number. The value range is (0.0,1.0], which cannot be equal to 0. The default value is 0.95. The larger the value, the more random and creative the output will be; the smaller the value, The output will be more stable or certain. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "help": {
                                  "zh_Hans": "用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。",
                                  "en_US": "Another method of temperature sampling is called kernel sampling. The value range is (0.0, 1.0) open interval, which cannot be equal to 0 or 1. The default value is 0.7. The model considers the results with top_p probability mass tokens. For example 0.1 means The model decoder only considers tokens from the candidate set with the top 10% probability. It is recommended that you adjust the top_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time."
                              }
                          },
                          {
                              "name": "do_sample",
                              "label": {
                                  "zh_Hans": "采样策略",
                                  "en_US": "Sampling strategy"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效。默认值为 true。",
                                  "en_US": "When `do_sample` is set to true, the sampling strategy is enabled. When `do_sample` is set to false, the sampling strategies such as `temperature` and `top_p` will not take effect. The default value is true."
                              },
                              "default": true
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 4095
                          },
                          {
                              "name": "web_search",
                              "type": "boolean",
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "default": false,
                              "help": {
                                  "zh_Hans": "模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。",
                                  "en_US": "The model has a built-in Internet search service. This parameter controls whether the model refers to Internet search results when generating text. When Internet search is enabled, the model will use the search results as reference information in the text generation process, but the model will \"judge\" whether to use Internet search results based on its internal logic."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.05",
                          "output": "0.05",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "embedding-2",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192
                      },
                      "pricing": {
                          "input": "0.0005",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "embedding-3",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192
                      },
                      "pricing": {
                          "input": "0.0005",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "text_embedding",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 512
                      }
                  }
              ],
              "provider": "zhipuai",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "APIKey"
                          },
                          "placeholder": {
                              "en_US": "Enter your APIKey",
                              "zh_Hans": "在此输入您的 APIKey"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding"
              ]
          }
      },
      {
          "author": "stvlynn",
          "created_at": "2023-12-20T10:00:00.000000Z",
          "description": {
              "en_US": "Deploy local models using LM Studio",
              "zh_Hans": "使用LM Studio部署本地模型",
              "ja_JP": "LM Studio を使用してローカルモデルをデプロイ"
          },
          "icon": "icon.webp",
          "label": {
              "en_US": "LM Studio",
              "zh_Hans": "LM Studio"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.10"
              },
              "version": "0.0.2"
          },
          "name": "lmstudio",
          "plugins": {
              "models": [
                  "provider/lmstudio.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": false,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": false
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.2",
          "model": {
              "provider": "lmstudio",
              "label": {
                  "en_US": "LM Studio"
              },
              "description": {
                  "en_US": "Models provided by lmstudio.",
                  "zh_Hans": "LM Studio 提供的模型。",
                  "ja_JP": "LM Studioが提供するモデル。"
              },
              "icon_small": {
                  "en_US": "icon.webp"
              },
              "icon_large": {
                  "en_US": "icon.webp"
              },
              "background": "#F9FAFB",
              "help": {
                  "title": {
                      "en_US": "How to integrate with LM Studio",
                      "zh_Hans": "如何集成 LM Studio",
                      "ja_JP": "LM Studioとの統合方法"
                  },
                  "url": {
                      "en_US": "https://github.com/stvlynn"
                  }
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding"
              ],
              "configurate_methods": [
                  "customizable-model"
              ],
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "Base URL",
                              "zh_Hans": "基础 URL"
                          },
                          "placeholder": {
                              "en_US": "Base url of LM Studio server, e.g. http://localhost:1234",
                              "zh_Hans": "LM Studio server 的基础 URL，例如 http://localhost:1234",
                              "ja_JP": "LM Studio サーバーの基本 URL、例: http://localhost:1234"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "base_url"
                      },
                      {
                          "default": "chat",
                          "label": {
                              "en_US": "Completion mode",
                              "zh_Hans": "模型类型",
                              "ja_JP": "モデルタイプ"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Chat",
                                      "zh_Hans": "对话",
                                      "ja_JP": "チャット"
                                  },
                                  "value": "chat"
                              },
                              {
                                  "label": {
                                      "en_US": "Completion",
                                      "zh_Hans": "补全",
                                      "ja_JP": "補完"
                                  },
                                  "value": "completion"
                              }
                          ],
                          "placeholder": {
                              "en_US": "Select completion mode",
                              "zh_Hans": "选择对话类型",
                              "ja_JP": "チャットタイプを選択"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "select",
                          "variable": "mode"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Model context size",
                              "zh_Hans": "模型上下文长度",
                              "ja_JP": "モデルコンテキストサイズ"
                          },
                          "placeholder": {
                              "en_US": "Enter your Model context size",
                              "zh_Hans": "在此输入您的模型上下文长度",
                              "ja_JP": "モデルコンテキストサイズを入力"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "context_size"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Upper bound for max tokens",
                              "zh_Hans": "最大 token 上限",
                              "ja_JP": "最大トークン上限"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "text-input",
                          "variable": "max_tokens"
                      },
                      {
                          "default": "1536",
                          "label": {
                              "en_US": "Embedding dimensions",
                              "zh_Hans": "嵌入向量维度",
                              "ja_JP": "埋め込み次元"
                          },
                          "placeholder": {
                              "en_US": "Enter the embedding dimensions",
                              "zh_Hans": "输入嵌入向量维度",
                              "ja_JP": "埋め込み次元を入力"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "value": "text-embedding",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "text-input",
                          "variable": "dimensions"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称",
                          "ja_JP": "モデル名"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称",
                          "ja_JP": "モデル名を入力"
                      }
                  }
              },
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "variable": "openai_api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "type": "secret-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Key",
                              "en_US": "Enter your API Key",
                              "ja_JP": "API キーを入力"
                          }
                      }
                  ]
              },
              "models": [
                  {
                      "model": "gpt-3.5-turbo-16k-0613",
                      "label": {
                          "zh_Hans": "gpt-3.5-turbo-16k-0613",
                          "en_US": "gpt-3.5-turbo-16k-0613"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16385
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 16385
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.003",
                          "output": "0.004",
                          "unit": "0.001",
                          "currency": "USD"
                      },
                      "models": {
                          "default": {
                              "default_model": {
                                  "model": "model",
                                  "label": {
                                      "en_US": "LM Studio Model",
                                      "zh_Hans": "LM Studio 模型"
                                  },
                                  "model_type": "llm",
                                  "features": [
                                      "agent-thought",
                                      "vision"
                                  ],
                                  "model_properties": {
                                      "pricing": {
                                          "input": 0,
                                          "output": 0,
                                          "unit": 0.001,
                                          "currency": "USD"
                                      }
                                  },
                                  "parameter_rules": [
                                      {
                                          "name": "temperature",
                                          "type": "float",
                                          "use_template": "temperature"
                                      },
                                      {
                                          "name": "top_p",
                                          "type": "float",
                                          "use_template": "top_p"
                                      },
                                      {
                                          "name": "presence_penalty",
                                          "type": "float",
                                          "use_template": "presence_penalty"
                                      },
                                      {
                                          "name": "frequency_penalty",
                                          "type": "float",
                                          "use_template": "frequency_penalty"
                                      },
                                      {
                                          "name": "max_tokens",
                                          "label": {
                                              "en_US": "Max Tokens",
                                              "zh_Hans": "最大 Token 数量"
                                          },
                                          "type": "int",
                                          "help": {
                                              "en_US": "The maximum number of tokens to generate."
                                          },
                                          "default": 1000,
                                          "min": 1,
                                          "max": 8000
                                      }
                                  ]
                              }
                          }
                      }
                  }
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/text_embedding/text_embedding.py"
                      ],
                      "provider_source": "provider/lmstudio.py"
                  }
              }
          }
      },
      {
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "huggingface_hub",
          "author": "ssrag",
          "label": {
              "en_US": "Hugging Face Hub"
          },
          "description": {
              "en_US": "Hugging Face Model"
          },
          "icon": "icon_s_en.svg",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "plugins": {
              "models": [
                  "provider/huggingface_hub.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": false
                  },
                  "tool": {
                      "enabled": false
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.4",
          "model": {
              "background": "#FFF8DC",
              "configurate_methods": [
                  "customizable-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/text_embedding/text_embedding.py"
                      ],
                      "provider_source": "provider/huggingface_hub.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API key from Hugging Face Hub",
                      "zh_Hans": "从 Hugging Face Hub 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://huggingface.co/settings/tokens"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "Hugging Face Model"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "default": "hosted_inference_api",
                          "label": {
                              "en_US": "Endpoint Type",
                              "zh_Hans": "端点类型"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Hosted Inference API"
                                  },
                                  "value": "hosted_inference_api"
                              },
                              {
                                  "label": {
                                      "en_US": "Inference Endpoints"
                                  },
                                  "value": "inference_endpoints"
                              }
                          ],
                          "required": true,
                          "type": "radio",
                          "variable": "huggingfacehub_api_type"
                      },
                      {
                          "label": {
                              "en_US": "API Token",
                              "zh_Hans": "API Token"
                          },
                          "placeholder": {
                              "en_US": "Enter your Hugging Face Hub API Token here",
                              "zh_Hans": "在此输入您的 Hugging Face Hub API Token"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "huggingfacehub_api_token"
                      },
                      {
                          "label": {
                              "en_US": "User Name / Organization Name",
                              "zh_Hans": "用户名 / 组织名称"
                          },
                          "placeholder": {
                              "en_US": "Enter your User Name / Organization Name here",
                              "zh_Hans": "在此输入您的用户名 / 组织名称"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "value": "text-embedding",
                                  "variable": "__model_type"
                              },
                              {
                                  "value": "inference_endpoints",
                                  "variable": "huggingfacehub_api_type"
                              }
                          ],
                          "type": "text-input",
                          "variable": "huggingface_namespace"
                      },
                      {
                          "label": {
                              "en_US": "Endpoint URL",
                              "zh_Hans": "端点 URL"
                          },
                          "placeholder": {
                              "en_US": "Enter your Endpoint URL here",
                              "zh_Hans": "在此输入您的端点 URL"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "value": "inference_endpoints",
                                  "variable": "huggingfacehub_api_type"
                              }
                          ],
                          "type": "text-input",
                          "variable": "huggingfacehub_endpoint_url"
                      },
                      {
                          "label": {
                              "en_US": "Task",
                              "zh_Hans": "Task"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Text-to-Text Generation"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "text2text-generation"
                              },
                              {
                                  "label": {
                                      "en_US": "Text Generation",
                                      "zh_Hans": "文本生成"
                                  },
                                  "show_on": [
                                      {
                                          "value": "llm",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "text-generation"
                              },
                              {
                                  "label": {
                                      "en_US": "Feature Extraction"
                                  },
                                  "show_on": [
                                      {
                                          "value": "text-embedding",
                                          "variable": "__model_type"
                                      }
                                  ],
                                  "value": "feature-extraction"
                              }
                          ],
                          "show_on": [
                              {
                                  "value": "inference_endpoints",
                                  "variable": "huggingfacehub_api_type"
                              }
                          ],
                          "type": "select",
                          "variable": "task_type"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      }
                  }
              },
              "models": [],
              "provider": "huggingface_hub",
              "supported_model_types": [
                  "llm",
                  "text-embedding"
              ]
          }
      },
      {
          "version": "0.0.7",
          "type": "plugin",
          "author": "langgenius",
          "name": "jina",
          "description": {
              "en_US": "Embedding and Rerank Model Supported"
          },
          "label": {
              "en_US": "Jina"
          },
          "created_at": "2024-07-12T08:03:44.658609186Z",
          "icon": "icon_s_en.svg",
          "resource": {
              "memory": 1048576,
              "permission": {
                  "tool": {
                      "enabled": true
                  },
                  "model": {
                      "enabled": true,
                      "llm": true
                  }
              }
          },
          "plugins": {
              "models": [
                  "provider/jina.yaml"
              ]
          },
          "meta": {
              "version": "0.0.1",
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "language": "python",
                  "version": "3.12",
                  "entrypoint": "main"
              }
          },
          "model": {
              "provider": "jina",
              "label": {
                  "en_US": "Jina"
              },
              "description": {
                  "en_US": "Embedding and Rerank Model Supported"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "background": "#EFFDFD",
              "help": {
                  "title": {
                      "en_US": "Get your API key from Jina AI",
                      "zh_Hans": "从 Jina 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://jina.ai/"
                  }
              },
              "supported_model_types": [
                  "text-embedding",
                  "rerank"
              ],
              "configurate_methods": [
                  "predefined-model",
                  "customizable-model"
              ],
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "variable": "api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "type": "secret-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Key",
                              "en_US": "Enter your API Key"
                          }
                      }
                  ]
              },
              "model_credential_schema": {
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  },
                  "credential_form_schemas": [
                      {
                          "variable": "api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "type": "secret-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Key",
                              "en_US": "Enter your API Key"
                          }
                      },
                      {
                          "variable": "base_url",
                          "label": {
                              "zh_Hans": "服务器 URL",
                              "en_US": "Base URL"
                          },
                          "type": "text-input",
                          "required": false,
                          "placeholder": {
                              "zh_Hans": "Base URL, e.g. https://api.jina.ai/v1",
                              "en_US": "Base URL, e.g. https://api.jina.ai/v1"
                          }
                      },
                      {
                          "variable": "context_size",
                          "label": {
                              "zh_Hans": "上下文大小",
                              "en_US": "Context size"
                          },
                          "placeholder": {
                              "zh_Hans": "输入上下文大小",
                              "en_US": "Enter context size"
                          },
                          "required": false,
                          "type": "text-input",
                          "default": "8192"
                      }
                  ]
              },
              "models": [
                  {
                      "model": "jina-colbert-v1-en",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 8192
                      }
                  },
                  {
                      "model": "jina-reranker-v1-base-en",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 8192
                      }
                  },
                  {
                      "model": "jina-reranker-v1-tiny-en",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 8192
                      }
                  },
                  {
                      "model": "jina-reranker-v1-turbo-en",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 8192
                      }
                  },
                  {
                      "model": "jina-reranker-v2-base-multilingual",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 8192
                      }
                  },
                  {
                      "model": "jina-clip-v1",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 2048
                      },
                      "pricing": {
                          "input": "0.001",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "jina-clip-v2",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 2048
                      },
                      "pricing": {
                          "input": "0.001",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "jina-embeddings-v2-base-de",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 2048
                      },
                      "pricing": {
                          "input": "0.001",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "jina-embeddings-v2-base-en",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 2048
                      },
                      "pricing": {
                          "input": "0.001",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "jina-embeddings-v2-base-zh",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 2048
                      },
                      "pricing": {
                          "input": "0.001",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "jina-embeddings-v3",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 2048
                      },
                      "pricing": {
                          "input": "0.001",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  }
              ],
              "extra": {
                  "python": {
                      "provider_source": "provider/jina.py",
                      "model_sources": [
                          "models/text_embedding/text_embedding.py",
                          "models/rerank/rerank.py"
                      ]
                  }
              }
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "Models provided by Moonshot, such as moonshot-v1-8k, moonshot-v1-32k, and moonshot-v1-128k.",
              "zh_Hans": "Moonshot 提供的模型，例如 moonshot-v1-8k、moonshot-v1-32k 和 moonshot-v1-128k。"
          },
          "icon": "icon_s_en.png",
          "label": {
              "en_US": "Moonshot",
              "zh_Hans": "月之暗面"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "moonshot",
          "plugins": {
              "models": [
                  "provider/moonshot.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.4",
          "model": {
              "background": "#FFFFFF",
              "configurate_methods": [
                  "predefined-model",
                  "customizable-model"
              ],
              "description": {
                  "en_US": "Models provided by Moonshot, such as moonshot-v1-8k, moonshot-v1-32k, and moonshot-v1-128k.",
                  "zh_Hans": "Moonshot 提供的模型，例如 moonshot-v1-8k、moonshot-v1-32k 和 moonshot-v1-128k。"
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py"
                      ],
                      "provider_source": "provider/moonshot.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API Key from Moonshot",
                      "zh_Hans": "从 Moonshot 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://platform.moonshot.cn/console/api-keys"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.png"
              },
              "icon_small": {
                  "en_US": "icon_s_en.png"
              },
              "label": {
                  "en_US": "Moonshot",
                  "zh_Hans": "月之暗面"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Model context size",
                              "zh_Hans": "模型上下文长度"
                          },
                          "placeholder": {
                              "en_US": "Enter your Model context size",
                              "zh_Hans": "在此输入您的模型上下文长度"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "context_size"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Upper bound for max tokens",
                              "zh_Hans": "最大 token 上限"
                          },
                          "type": "text-input",
                          "variable": "max_tokens"
                      },
                      {
                          "default": "no_call",
                          "label": {
                              "en_US": "Function calling"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Not supported",
                                      "zh_Hans": "不支持"
                                  },
                                  "value": "no_call"
                              },
                              {
                                  "label": {
                                      "en_US": "Tool Call",
                                      "zh_Hans": "Tool Call"
                                  },
                                  "value": "tool_call"
                              }
                          ],
                          "required": false,
                          "type": "select",
                          "variable": "function_calling_type"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  }
              },
              "models": [
                  {
                      "model": "moonshot-v1-128k",
                      "label": {
                          "zh_Hans": "moonshot-v1-128k",
                          "en_US": "moonshot-v1-128k"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.06",
                          "output": "0.06",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "moonshot-v1-32k",
                      "label": {
                          "zh_Hans": "moonshot-v1-32k",
                          "en_US": "moonshot-v1-32k"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 32000
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.024",
                          "output": "0.024",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "moonshot-v1-8k",
                      "label": {
                          "zh_Hans": "moonshot-v1-8k",
                          "en_US": "moonshot-v1-8k"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.012",
                          "output": "0.012",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  }
              ],
              "provider": "moonshot",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "label": {
                              "en_US": "API Base"
                          },
                          "placeholder": {
                              "en_US": "Base URL, e.g. https://api.moonshot.cn/v1",
                              "zh_Hans": "Base URL, 如：https://api.moonshot.cn/v1"
                          },
                          "required": false,
                          "type": "text-input",
                          "variable": "endpoint_url"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm"
              ]
          }
      },
      {
          "version": "0.0.24",
          "type": "plugin",
          "author": "ssrag",
          "name": "bedrock",
          "label": {
              "en_US": "Amazon Bedrock",
              "ja_JP": "Amazon Bedrock",
              "zh_Hans": "Amazon Bedrock",
              "pt_BR": "Amazon Bedrock"
          },
          "description": {
              "en_US": "The models of Amazon Bedrock",
              "ja_JP": "The models of Amazon Bedrock",
              "zh_Hans": "The models of Amazon Bedrock",
              "pt_BR": "The models of Amazon Bedrock"
          },
          "icon": "icon_s_en.svg",
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "text_embedding": true,
                      "rerank": true,
                      "tts": false,
                      "speech2text": false,
                      "moderation": false
                  }
              }
          },
          "plugins": {
              "models": [
                  "provider/bedrock.yaml"
              ]
          },
          "meta": {
              "version": "0.0.1",
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "language": "python",
                  "version": "3.12",
                  "entrypoint": "main"
              }
          },
          "created_at": "2025-02-27T17:55:38.294110+08:00",
          "privacy": "PRIVACY.md",
          "verified": false,
          "model": {
              "provider": "bedrock",
              "label": {
                  "en_US": "Amazon Bedrock"
              },
              "description": {
                  "en_US": "Bedrock LLM Model"
              },
              "background": "#FCFDFF",
              "help": {
                  "title": {
                      "en_US": "Get your Access Key and Secret Access Key from AWS Console"
                  },
                  "url": {
                      "en_US": "https://console.aws.amazon.com/"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding",
                  "rerank"
              ],
              "configurate_methods": [
                  "predefined-model"
              ],
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "variable": "aws_access_key_id",
                          "required": false,
                          "label": {
                              "en_US": "Access Key (If not provided, credentials are obtained from the running environment.)",
                              "zh_Hans": "Access Key"
                          },
                          "type": "secret-input",
                          "placeholder": {
                              "en_US": "Enter your Access Key",
                              "zh_Hans": "在此输入您的 Access Key"
                          }
                      },
                      {
                          "variable": "aws_secret_access_key",
                          "required": false,
                          "label": {
                              "en_US": "Secret Access Key",
                              "zh_Hans": "Secret Access Key"
                          },
                          "type": "secret-input",
                          "placeholder": {
                              "en_US": "Enter your Secret Access Key",
                              "zh_Hans": "在此输入您的 Secret Access Key"
                          }
                      },
                      {
                          "variable": "aws_region",
                          "required": true,
                          "label": {
                              "en_US": "AWS Region",
                              "zh_Hans": "AWS 地区",
                              "ja_JP": "AWS リージョン"
                          },
                          "type": "select",
                          "default": "us-east-1",
                          "options": [
                              {
                                  "value": "us-east-1",
                                  "label": {
                                      "en_US": "US East (N. Virginia)",
                                      "zh_Hans": "美国东部 (弗吉尼亚北部)",
                                      "ja_JP": "米国 (バージニア北部)"
                                  }
                              },
                              {
                                  "value": "us-east-2",
                                  "label": {
                                      "en_US": "US East (Ohio)",
                                      "zh_Hans": "美国东部 (俄亥俄)",
                                      "ja_JP": "米国 (オハイオ)"
                                  }
                              },
                              {
                                  "value": "us-west-2",
                                  "label": {
                                      "en_US": "US West (Oregon)",
                                      "zh_Hans": "美国西部 (俄勒冈州)",
                                      "ja_JP": "米国 (オレゴン)"
                                  }
                              },
                              {
                                  "value": "ap-south-1",
                                  "label": {
                                      "en_US": "Asia Pacific (Mumbai)",
                                      "zh_Hans": "亚太地区（孟买）",
                                      "ja_JP": "アジアパシフィック (ムンバイ)"
                                  }
                              },
                              {
                                  "value": "ap-southeast-1",
                                  "label": {
                                      "en_US": "Asia Pacific (Singapore)",
                                      "zh_Hans": "亚太地区 (新加坡)",
                                      "ja_JP": "アジアパシフィック (シンガポール)"
                                  }
                              },
                              {
                                  "value": "ap-southeast-2",
                                  "label": {
                                      "en_US": "Asia Pacific (Sydney)",
                                      "zh_Hans": "亚太地区 (悉尼)",
                                      "ja_JP": "アジアパシフィック (シドニー)"
                                  }
                              },
                              {
                                  "value": "ap-northeast-1",
                                  "label": {
                                      "en_US": "Asia Pacific (Tokyo)",
                                      "zh_Hans": "亚太地区 (东京)",
                                      "ja_JP": "アジアパシフィック (東京)"
                                  }
                              },
                              {
                                  "value": "ap-northeast-2",
                                  "label": {
                                      "en_US": "Asia Pacific (Seoul)",
                                      "zh_Hans": "亚太地区（首尔）",
                                      "ja_JP": "アジアパシフィック (ソウル)"
                                  }
                              },
                              {
                                  "value": "ca-central-1",
                                  "label": {
                                      "en_US": "Canada (Central)",
                                      "zh_Hans": "加拿大（中部）",
                                      "ja_JP": "カナダ (中部)"
                                  }
                              },
                              {
                                  "value": "eu-central-1",
                                  "label": {
                                      "en_US": "Europe (Frankfurt)",
                                      "zh_Hans": "欧洲 (法兰克福)",
                                      "ja_JP": "欧州 (フランクフルト)"
                                  }
                              },
                              {
                                  "value": "eu-west-1",
                                  "label": {
                                      "en_US": "Europe (Ireland)",
                                      "zh_Hans": "欧洲（爱尔兰）",
                                      "ja_JP": "欧州 (アイルランド)"
                                  }
                              },
                              {
                                  "value": "eu-west-2",
                                  "label": {
                                      "en_US": "Europe (London)",
                                      "zh_Hans": "欧洲西部 (伦敦)",
                                      "ja_JP": "欧州 (ロンドン)"
                                  }
                              },
                              {
                                  "value": "eu-west-3",
                                  "label": {
                                      "en_US": "Europe (Paris)",
                                      "zh_Hans": "欧洲（巴黎）",
                                      "ja_JP": "欧州 (パリ)"
                                  }
                              },
                              {
                                  "value": "sa-east-1",
                                  "label": {
                                      "en_US": "South America (São Paulo)",
                                      "zh_Hans": "南美洲（圣保罗）",
                                      "ja_JP": "南米 (サンパウロ)"
                                  }
                              },
                              {
                                  "value": "us-gov-west-1",
                                  "label": {
                                      "en_US": "AWS GovCloud (US-West)",
                                      "zh_Hans": "AWS GovCloud (US-West)",
                                      "ja_JP": "AWS GovCloud (米国西部)"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "bedrock_endpoint_url",
                          "label": {
                              "zh_Hans": "Bedrock Endpoint URL",
                              "en_US": "Bedrock Endpoint URL"
                          },
                          "type": "text-input",
                          "required": false,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 Bedrock Endpoint URL, 如：https://123456.cloudfront.net",
                              "en_US": "Enter your Bedrock Endpoint URL, e.g. https://123456.cloudfront.net"
                          },
                          "help": {
                              "text": {
                                  "en_US": "Custom endpoint URL for Bedrock API (cannot be used with Proxy URL)",
                                  "zh_Hans": "Bedrock API 的自定义端点 URL（不能与代理 URL 同时使用）"
                              }
                          }
                      },
                      {
                          "variable": "model_for_validation",
                          "required": false,
                          "label": {
                              "en_US": "Available Model Name",
                              "zh_Hans": "可用模型名称"
                          },
                          "type": "text-input",
                          "placeholder": {
                              "en_US": "A model you have access to (e.g. amazon.nova-pro-v1:0) for validation.",
                              "zh_Hans": "为了进行验证，请输入一个您可用的模型名称 (例如：amazon.nova-pro-v1:0)"
                          }
                      },
                      {
                          "variable": "bedrock_proxy_url",
                          "label": {
                              "en_US": "Bedrock Proxy URL",
                              "zh_Hans": "Bedrock Proxy URL"
                          },
                          "type": "text-input",
                          "required": false,
                          "placeholder": {
                              "en_US": "Enter your proxy address (e.g. 127.0.0.1:7890)"
                          },
                          "help": {
                              "text": {
                                  "en_US": "Proxy address for Bedrock API connections (cannot be used with Endpoint URL)",
                                  "zh_Hans": "Bedrock API 连接的代理地址（不能与端点 URL 同时使用）"
                              }
                          }
                      }
                  ]
              },
              "models": [
                  {
                      "model": "ai21",
                      "label": {
                          "en_US": "AI21 Labs"
                      },
                      "icon": "icon_s_en.svg",
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "completion",
                          "context_size": 256000
                      },
                      "parameter_rules": [
                          {
                              "name": "model_name",
                              "label": {
                                  "zh_Hans": "Bedrock 模型",
                                  "en_US": "Bedrock Model"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型名称",
                                  "en_US": "specify model name"
                              },
                              "required": true,
                              "default": "Jamba 1.5 Large",
                              "options": [
                                  "Jamba 1.5 Mini",
                                  "Jamba 1.5 Large"
                              ]
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0.0,
                              "max": 2.0
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_gen_len",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 4096,
                              "min": 1,
                              "max": 4096
                          }
                      ]
                  },
                  {
                      "model": "amazon nova",
                      "label": {
                          "en_US": "Amazon Nova"
                      },
                      "icon": "icon_s_en.svg",
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 300000
                      },
                      "parameter_rules": [
                          {
                              "name": "model_name",
                              "label": {
                                  "zh_Hans": "Bedrock 模型",
                                  "en_US": "Bedrock Model"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型名称",
                                  "en_US": "specify model name"
                              },
                              "required": true,
                              "default": "Nova Pro",
                              "options": [
                                  "Nova Premier",
                                  "Nova Pro",
                                  "Nova Lite",
                                  "Nova Micro"
                              ]
                          },
                          {
                              "name": "cross-region",
                              "label": {
                                  "zh_Hans": "使用跨区域推理",
                                  "en_US": "Use Cross-Region Inference"
                              },
                              "type": "boolean",
                              "required": true,
                              "default": true,
                              "help": {
                                  "zh_Hans": "跨区域推理会自动选择您所在地理区域 AWS 区域 内的最佳位置来处理您的推理请求。",
                                  "en_US": "Cross-Region inference automatically selects the optimal AWS Region within your geography to process your inference request."
                              }
                          },
                          {
                              "name": "system_cache_checkpoint",
                              "label": {
                                  "zh_Hans": "缓存系统提示词",
                                  "en_US": "Cache System Prompt"
                              },
                              "type": "boolean",
                              "required": false,
                              "help": {
                                  "zh_Hans": "在系统消息中启用缓存检查点，可以提高性能并降低成本。",
                                  "en_US": "Enable cache checkpoint in the system message to improve performance and reduce costs."
                              }
                          },
                          {
                              "name": "latest_two_messages_cache_checkpoint",
                              "label": {
                                  "zh_Hans": "缓存用户消息",
                                  "en_US": "Cache User Messages"
                              },
                              "type": "boolean",
                              "required": false,
                              "help": {
                                  "zh_Hans": "在最新的两条用户消息中启用缓存检查点，可以提高性能并降低成本。",
                                  "en_US": "Enable cache checkpoint in the latest two user messages to improve performance and reduce costs."
                              }
                          },
                          {
                              "name": "max_new_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 2048,
                              "min": 1,
                              "max": 5000
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "required": false,
                              "type": "float",
                              "default": 1,
                              "min": 0.0,
                              "max": 1.0,
                              "label": {
                                  "zh_Hans": "生成内容的随机性。",
                                  "en_US": "The amount of randomness injected into the response."
                              }
                          },
                          {
                              "name": "top_p",
                              "required": false,
                              "type": "float",
                              "default": 0.999,
                              "min": 0.0,
                              "max": 1.0,
                              "label": {
                                  "zh_Hans": "在核采样中，Amazon Nova 按概率递减顺序计算每个后续标记的所有选项的累积分布，并在达到 top_p 指定的特定概率时将其切断。您应该更改温度或top_p，但不能同时更改两者。",
                                  "en_US": "In nucleus sampling, Amazon Nova computes the cumulative distribution over all the options for each subsequent token in decreasing probability order and cuts it off once it reaches a particular probability specified by top_p. You should alter either temperature or top_p, but not both."
                              }
                          },
                          {
                              "name": "top_k",
                              "required": false,
                              "type": "int",
                              "default": 0,
                              "min": 0,
                              "max": 500,
                              "label": {
                                  "zh_Hans": "对于每个后续标记，仅从前 K 个选项中进行采样。使用 top_k 删除长尾低概率响应。",
                                  "en_US": "Only sample from the top K options for each subsequent token. Use top_k to remove long tail low probability responses."
                              }
                          }
                      ]
                  },
                  {
                      "model": "anthropic claude",
                      "label": {
                          "en_US": "Anthropic Claude"
                      },
                      "icon": "icon_s_en.svg",
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "model_name",
                              "label": {
                                  "zh_Hans": "Bedrock 模型",
                                  "en_US": "Bedrock Model"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型名称",
                                  "en_US": "specify model name"
                              },
                              "required": true,
                              "default": "Claude 3.7 Sonnet",
                              "options": [
                                  "Claude 4.0 Sonnet",
                                  "Claude 4.0 Opus",
                                  "Claude 3.7 Sonnet",
                                  "Claude 3.5 Sonnet",
                                  "Claude 3.5 Sonnet V2",
                                  "Claude 3 Sonnet",
                                  "Claude 3.5 Haiku",
                                  "Claude 3 Haiku",
                                  "Claude 3 Opus"
                              ]
                          },
                          {
                              "name": "cross-region",
                              "label": {
                                  "zh_Hans": "使用跨区域推理",
                                  "en_US": "Use Cross-Region Inference"
                              },
                              "type": "boolean",
                              "required": true,
                              "default": true,
                              "help": {
                                  "zh_Hans": "跨区域推理会自动选择您所在地理区域 AWS 区域 内的最佳位置来处理您的推理请求。",
                                  "en_US": "Cross-Region inference automatically selects the optimal AWS Region within your geography to process your inference request."
                              }
                          },
                          {
                              "name": "system_cache_checkpoint",
                              "label": {
                                  "zh_Hans": "缓存系统提示词",
                                  "en_US": "Cache System Prompt"
                              },
                              "type": "boolean",
                              "required": false,
                              "help": {
                                  "zh_Hans": "在系统消息中启用缓存检查点，可以提高性能并降低成本。",
                                  "en_US": "Enable cache checkpoint in the system message to improve performance and reduce costs."
                              }
                          },
                          {
                              "name": "latest_two_messages_cache_checkpoint",
                              "label": {
                                  "zh_Hans": "缓存用户消息",
                                  "en_US": "Cache User Messages"
                              },
                              "type": "boolean",
                              "required": false,
                              "help": {
                                  "zh_Hans": "在最新的两条用户消息中启用缓存检查点，可以提高性能并降低成本。",
                                  "en_US": "Enable cache checkpoint in the latest two user messages to improve performance and reduce costs."
                              }
                          },
                          {
                              "name": "reasoning_type",
                              "label": {
                                  "zh_Hans": "推理配置",
                                  "en_US": "Reasoning Type"
                              },
                              "type": "boolean",
                              "required": false,
                              "default": false,
                              "placeholder": {
                                  "zh_Hans": "设置推理配置",
                                  "en_US": "Set reasoning configuration"
                              },
                              "help": {
                                  "zh_Hans": "控制模型的推理能力。启用时，temperature将固定为1且top_p将被禁用。",
                                  "en_US": "Controls the model's reasoning capability. When enabled, temperature will be fixed to 1 and top_p will be disabled."
                              }
                          },
                          {
                              "name": "reasoning_budget",
                              "show_on": [
                                  {
                                      "variable": "reasoning_type",
                                      "value": true
                                  }
                              ],
                              "label": {
                                  "zh_Hans": "推理预算",
                                  "en_US": "Reasoning Budget"
                              },
                              "type": "int",
                              "default": 1024,
                              "min": 0,
                              "max": 128000,
                              "help": {
                                  "zh_Hans": "推理的预算限制（最小1024），必须小于max_tokens。仅在推理类型为enabled时可用。",
                                  "en_US": "Budget limit for reasoning (minimum 1024), must be less than max_tokens. Only available when reasoning type is enabled."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "label": {
                                  "zh_Hans": "最大token数",
                                  "en_US": "Max Tokens"
                              },
                              "type": "int",
                              "default": 4096,
                              "min": 1,
                              "max": 128000,
                              "help": {
                                  "zh_Hans": "停止前生成的最大令牌数。请注意，Anthropic Claude 模型可能会在达到 max_tokens 的值之前停止生成令牌。不同的 Anthropic Claude 模型对此参数具有不同的最大值。",
                                  "en_US": "The maximum number of tokens to generate before stopping. Note that Anthropic Claude models might stop generating tokens before reaching the value of max_tokens. Different Anthropic Claude models have different maximum values for this parameter."
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "required": false,
                              "label": {
                                  "zh_Hans": "模型温度",
                                  "en_US": "Model Temperature"
                              },
                              "type": "float",
                              "default": 1,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "生成内容的随机性。当推理功能启用时，该值将被固定为1。",
                                  "en_US": "The amount of randomness injected into the response. When reasoning is enabled, this value will be fixed to 1."
                              }
                          },
                          {
                              "name": "top_p",
                              "show_on": [
                                  {
                                      "variable": "reasoning_type",
                                      "value": "disabled"
                                  }
                              ],
                              "use_template": "top_p",
                              "label": {
                                  "zh_Hans": "Top P",
                                  "en_US": "Top P"
                              },
                              "required": false,
                              "type": "float",
                              "default": 0.999,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "在核采样中的概率阈值。当推理功能启用时，该参数将被禁用。",
                                  "en_US": "The probability threshold in nucleus sampling. When reasoning is enabled, this parameter will be disabled."
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "required": false,
                              "type": "int",
                              "default": 0,
                              "min": 0,
                              "max": 500,
                              "help": {
                                  "zh_Hans": "对于每个后续标记，仅从前 K 个选项中进行采样。使用 top_k 删除长尾低概率响应。",
                                  "en_US": "Only sample from the top K options for each subsequent token. Use top_k to remove long tail low probability responses."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ]
                  },
                  {
                      "model": "deepseek",
                      "label": {
                          "en_US": "DeepSeek"
                      },
                      "icon": "icon_s_en.svg",
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "model_name",
                              "label": {
                                  "zh_Hans": "Bedrock 模型",
                                  "en_US": "Bedrock Model"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型名称",
                                  "en_US": "specify model name"
                              },
                              "required": true,
                              "default": "DeepSeek R1",
                              "options": [
                                  "DeepSeek R1"
                              ]
                          },
                          {
                              "name": "cross-region",
                              "label": {
                                  "zh_Hans": "使用跨区域推理",
                                  "en_US": "Use Cross-Region Inference"
                              },
                              "type": "boolean",
                              "required": true,
                              "default": true,
                              "help": {
                                  "zh_Hans": "跨区域推理会自动选择您所在地理区域 AWS 区域 内的最佳位置来处理您的推理请求。",
                                  "en_US": "Cross-Region inference automatically selects the optimal AWS Region within your geography to process your inference request."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "label": {
                                  "zh_Hans": "最大token数",
                                  "en_US": "Max Tokens"
                              },
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 128000,
                              "help": {
                                  "zh_Hans": "停止前生成的最大令牌数。",
                                  "en_US": "The maximum number of tokens to generate before stopping."
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "required": false,
                              "label": {
                                  "zh_Hans": "模型温度",
                                  "en_US": "Model Temperature"
                              },
                              "type": "float",
                              "default": 1,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "生成内容的随机性。当推理功能启用时，该值将被固定为1。",
                                  "en_US": "The amount of randomness injected into the response. When reasoning is enabled, this value will be fixed to 1."
                              }
                          },
                          {
                              "name": "top_p",
                              "show_on": [
                                  {
                                      "variable": "reasoning_type",
                                      "value": "disabled"
                                  }
                              ],
                              "use_template": "top_p",
                              "label": {
                                  "zh_Hans": "Top P",
                                  "en_US": "Top P"
                              },
                              "required": false,
                              "type": "float",
                              "default": 0.999,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "在核采样中的概率阈值。当推理功能启用时，该参数将被禁用。",
                                  "en_US": "The probability threshold in nucleus sampling. When reasoning is enabled, this parameter will be disabled."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ]
                  },
                  {
                      "model": "meta",
                      "label": {
                          "en_US": "Meta Llama"
                      },
                      "icon": "icon_s_en.svg",
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "model_name",
                              "label": {
                                  "zh_Hans": "Bedrock 模型",
                                  "en_US": "Bedrock Model"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型名称",
                                  "en_US": "specify model name"
                              },
                              "required": true,
                              "default": "Llama 3.1 70B Instruct",
                              "options": [
                                  "Llama 3 8B Instruct",
                                  "Llama 3 70B Instruct",
                                  "Llama 3.1 8B Instruct",
                                  "Llama 3.1 70B Instruct",
                                  "Llama 3.1 405B Instruct",
                                  "Llama 3.2 11B Instruct",
                                  "Llama 3.2 90B Instruct"
                              ]
                          },
                          {
                              "name": "cross-region",
                              "label": {
                                  "zh_Hans": "使用跨区域推理",
                                  "en_US": "Use Cross-Region Inference"
                              },
                              "type": "boolean",
                              "required": true,
                              "default": true,
                              "help": {
                                  "zh_Hans": "跨区域推理会自动选择您所在地理区域 AWS 区域 内的最佳位置来处理您的推理请求。",
                                  "en_US": "Cross-Region inference automatically selects the optimal AWS Region within your geography to process your inference request."
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_gen_len",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 512,
                              "min": 1,
                              "max": 2048
                          }
                      ]
                  },
                  {
                      "model": "mistral",
                      "label": {
                          "en_US": "Mistral AI"
                      },
                      "icon": "icon_s_en.svg",
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "model_name",
                              "label": {
                                  "zh_Hans": "Bedrock 模型",
                                  "en_US": "Bedrock Model"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型名称",
                                  "en_US": "specify model name"
                              },
                              "required": true,
                              "default": "Mistral Large",
                              "options": [
                                  "Mistral 7B Instruct",
                                  "Mistral Large",
                                  "Mistral Small",
                                  "Mixtral 8x7B Instruct"
                              ]
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "required": false,
                              "default": 0.7
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "required": false,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          }
                      ]
                  },
                  {
                      "model": "amazon.rerank-v1:0",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 5120
                      }
                  },
                  {
                      "model": "cohere.rerank-v3-5:0",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 5120
                      }
                  },
                  {
                      "model": "amazon.titan-embed-text-v1",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192
                      },
                      "pricing": {
                          "input": "0.0001",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "amazon.titan-embed-text-v2:0",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192
                      },
                      "pricing": {
                          "input": "0.00002",
                          "unit": "0.00001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "cohere.embed-english-v3",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 512
                      },
                      "pricing": {
                          "input": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "cohere.embed-multilingual-v3",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 512
                      },
                      "pricing": {
                          "input": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  }
              ],
              "extra": {
                  "python": {
                      "provider_source": "provider/bedrock.py",
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/rerank/rerank.py",
                          "models/text_embedding/text_embedding.py"
                      ]
                  }
              }
          }
      },
      {
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "huggingface_tei",
          "author": "ssrag",
          "label": {
              "en_US": "Text Embedding Inference"
          },
          "description": {
              "en_US": "A blazing fast inference solution for text embeddings models.",
              "zh_Hans": "用于文本嵌入模型的超快速推理解决方案。"
          },
          "icon": "icon_s_en.svg",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "plugins": {
              "models": [
                  "provider/huggingface_tei.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": false
                  },
                  "tool": {
                      "enabled": false
                  }
              }
          },
          "type": "plugin",
          "version": "0.1.0",
          "model": {
              "background": "#FFF8DC",
              "configurate_methods": [
                  "customizable-model"
              ],
              "description": {
                  "en_US": "A blazing fast inference solution for text embeddings models.",
                  "zh_Hans": "用于文本嵌入模型的超快速推理解决方案。"
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/rerank/rerank.py",
                          "models/text_embedding/text_embedding.py"
                      ],
                      "provider_source": "provider/huggingface_tei.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "How to deploy Text Embedding Inference",
                      "zh_Hans": "如何部署 Text Embedding Inference"
                  },
                  "url": {
                      "en_US": "https://github.com/huggingface/text-embeddings-inference"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "Text Embedding Inference"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "Server url",
                              "zh_Hans": "服务器URL"
                          },
                          "placeholder": {
                              "en_US": "Enter the url of your Text Embedding Inference, e.g. http://192.168.1.100:8080",
                              "zh_Hans": "在此输入Text Embedding Inference的服务器地址，如 http://192.168.1.100:8080"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "server_url"
                      },
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": false,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "default": "60",
                          "label": {
                              "en_US": "invoke timeout (unit:second)",
                              "zh_Hans": "调用超时时间 (单位:秒)"
                          },
                          "placeholder": {
                              "en_US": "Enter invoke timeout value",
                              "zh_Hans": "在此输入调用超时时间"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "invoke_timeout"
                      },
                      {
                          "default": "3",
                          "label": {
                              "en_US": "max retries",
                              "zh_Hans": "调用重试次数"
                          },
                          "placeholder": {
                              "en_US": "Enter max retries",
                              "zh_Hans": "在此输入调用重试次数"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "max_retries"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  }
              },
              "models": [],
              "provider": "huggingface_tei",
              "supported_model_types": [
                  "text-embedding",
                  "rerank"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "Models provided by Tencent Hunyuan, such as hunyuan-standard, hunyuan-standard-256k, hunyuan-pro, hunyuan-role, hunyuan-large, hunyuan-large-role, hunyuan-turbo-latest, hunyuan-large-longcontext, hunyuan-turbo, hunyuan-vision, hunyuan-turbo-vision, hunyuan-functioncall and hunyuan-lite.",
              "zh_Hans": "腾讯混元提供的模型，例如 hunyuan-standard、 hunyuan-standard-256k, hunyuan-pro, hunyuan-role, hunyuan-large, hunyuan-large-role, hunyuan-turbo-latest, hunyuan-large-longcontext, hunyuan-turbo, hunyuan-vision, hunyuan-turbo-vision, hunyuan-functioncall 和 hunyuan-lite。"
          },
          "icon": "icon_s_en.png",
          "label": {
              "en_US": "Hunyuan",
              "zh_Hans": "腾讯混元"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "hunyuan",
          "plugins": {
              "models": [
                  "provider/hunyuan.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.5",
          "model": {
              "background": "#F6F7F7",
              "configurate_methods": [
                  "predefined-model"
              ],
              "description": {
                  "en_US": "Models provided by Tencent Hunyuan, such as hunyuan-standard, hunyuan-standard-256k, hunyuan-pro and hunyuan-lite.",
                  "zh_Hans": "腾讯混元提供的模型，例如 hunyuan-standard、 hunyuan-standard-256k, hunyuan-pro 和 hunyuan-lite。"
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/text_embedding/text_embedding.py"
                      ],
                      "provider_source": "provider/hunyuan.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API Key from Tencent Hunyuan",
                      "zh_Hans": "从腾讯混元获取 API Key"
                  },
                  "url": {
                      "en_US": "https://console.cloud.tencent.com/cam/capi"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.png"
              },
              "icon_small": {
                  "en_US": "icon_s_en.png"
              },
              "label": {
                  "en_US": "Hunyuan",
                  "zh_Hans": "腾讯混元"
              },
              "models": [
                  {
                      "model": "hunyuan-functioncall",
                      "label": {
                          "zh_Hans": "hunyuan-functioncall",
                          "en_US": "hunyuan-functioncall"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 32000
                          },
                          {
                              "name": "enable_enhance",
                              "label": {
                                  "zh_Hans": "功能增强",
                                  "en_US": "Enable Enhancement"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "功能增强（如搜索）开关，关闭时将直接由主模型生成回复内容，可以降低响应时延（对于流式输出时的首字时延尤为明显）。但在少数场景里，回复效果可能会下降。",
                                  "en_US": "Allow the model to perform external search to enhance the generation results."
                              },
                              "required": false,
                              "default": true
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.008",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "hunyuan-large-longcontext",
                      "label": {
                          "zh_Hans": "hunyuan-large-longcontext",
                          "en_US": "hunyuan-large-longcontext"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 134000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 134000
                          },
                          {
                              "name": "enable_enhance",
                              "label": {
                                  "zh_Hans": "功能增强",
                                  "en_US": "Enable Enhancement"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "功能增强（如搜索）开关，关闭时将直接由主模型生成回复内容，可以降低响应时延（对于流式输出时的首字时延尤为明显）。但在少数场景里，回复效果可能会下降。",
                                  "en_US": "Allow the model to perform external search to enhance the generation results."
                              },
                              "required": false,
                              "default": true
                          }
                      ],
                      "pricing": {
                          "input": "0.006",
                          "output": "0.018",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "hunyuan-large-role",
                      "label": {
                          "zh_Hans": "hunyuan-large-role",
                          "en_US": "hunyuan-large-role"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 32000
                          },
                          {
                              "name": "enable_enhance",
                              "label": {
                                  "zh_Hans": "功能增强",
                                  "en_US": "Enable Enhancement"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "功能增强（如搜索）开关，关闭时将直接由主模型生成回复内容，可以降低响应时延（对于流式输出时的首字时延尤为明显）。但在少数场景里，回复效果可能会下降。",
                                  "en_US": "Allow the model to perform external search to enhance the generation results."
                              },
                              "required": false,
                              "default": true
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.008",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "hunyuan-large",
                      "label": {
                          "zh_Hans": "hunyuan-large",
                          "en_US": "hunyuan-large"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 32000
                          },
                          {
                              "name": "enable_enhance",
                              "label": {
                                  "zh_Hans": "功能增强",
                                  "en_US": "Enable Enhancement"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "功能增强（如搜索）开关，关闭时将直接由主模型生成回复内容，可以降低响应时延（对于流式输出时的首字时延尤为明显）。但在少数场景里，回复效果可能会下降。",
                                  "en_US": "Allow the model to perform external search to enhance the generation results."
                              },
                              "required": false,
                              "default": true
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.012",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "hunyuan-lite",
                      "label": {
                          "zh_Hans": "hunyuan-lite",
                          "en_US": "hunyuan-lite"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 256000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 256000
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "hunyuan-pro",
                      "label": {
                          "zh_Hans": "hunyuan-pro",
                          "en_US": "hunyuan-pro"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 32000
                          },
                          {
                              "name": "enable_enhance",
                              "label": {
                                  "zh_Hans": "功能增强",
                                  "en_US": "Enable Enhancement"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "功能增强（如搜索）开关，关闭时将直接由主模型生成回复内容，可以降低响应时延（对于流式输出时的首字时延尤为明显）。但在少数场景里，回复效果可能会下降。",
                                  "en_US": "Allow the model to perform external search to enhance the generation results."
                              },
                              "required": false,
                              "default": true
                          }
                      ],
                      "pricing": {
                          "input": "0.03",
                          "output": "0.10",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "hunyuan-role",
                      "label": {
                          "zh_Hans": "hunyuan-role",
                          "en_US": "hunyuan-role"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 32000
                          },
                          {
                              "name": "enable_enhance",
                              "label": {
                                  "zh_Hans": "功能增强",
                                  "en_US": "Enable Enhancement"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "功能增强（如搜索）开关，关闭时将直接由主模型生成回复内容，可以降低响应时延（对于流式输出时的首字时延尤为明显）。但在少数场景里，回复效果可能会下降。",
                                  "en_US": "Allow the model to perform external search to enhance the generation results."
                              },
                              "required": false,
                              "default": true
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.008",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "hunyuan-standard-256K",
                      "label": {
                          "zh_Hans": "hunyuan-standard-256K",
                          "en_US": "hunyuan-standard-256K"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 256000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 256000
                          },
                          {
                              "name": "enable_enhance",
                              "label": {
                                  "zh_Hans": "功能增强",
                                  "en_US": "Enable Enhancement"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "功能增强（如搜索）开关，关闭时将直接由主模型生成回复内容，可以降低响应时延（对于流式输出时的首字时延尤为明显）。但在少数场景里，回复效果可能会下降。",
                                  "en_US": "Allow the model to perform external search to enhance the generation results."
                              },
                              "required": false,
                              "default": true
                          }
                      ],
                      "pricing": {
                          "input": "0.015",
                          "output": "0.06",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "hunyuan-standard",
                      "label": {
                          "zh_Hans": "hunyuan-standard",
                          "en_US": "hunyuan-standard"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 32000
                          },
                          {
                              "name": "enable_enhance",
                              "label": {
                                  "zh_Hans": "功能增强",
                                  "en_US": "Enable Enhancement"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "功能增强（如搜索）开关，关闭时将直接由主模型生成回复内容，可以降低响应时延（对于流式输出时的首字时延尤为明显）。但在少数场景里，回复效果可能会下降。",
                                  "en_US": "Allow the model to perform external search to enhance the generation results."
                              },
                              "required": false,
                              "default": true
                          }
                      ],
                      "pricing": {
                          "input": "0.0045",
                          "output": "0.0005",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "hunyuan-turbo-latest",
                      "label": {
                          "zh_Hans": "hunyuan-turbo-latest",
                          "en_US": "hunyuan-turbo-latest"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 32000
                          },
                          {
                              "name": "enable_enhance",
                              "label": {
                                  "zh_Hans": "功能增强",
                                  "en_US": "Enable Enhancement"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "功能增强（如搜索）开关，关闭时将直接由主模型生成回复内容，可以降低响应时延（对于流式输出时的首字时延尤为明显）。但在少数场景里，回复效果可能会下降。",
                                  "en_US": "Allow the model to perform external search to enhance the generation results."
                              },
                              "required": false,
                              "default": true
                          }
                      ],
                      "pricing": {
                          "input": "0.015",
                          "output": "0.05",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "hunyuan-turbo-vision",
                      "label": {
                          "zh_Hans": "hunyuan-turbo-vision",
                          "en_US": "hunyuan-turbo-vision"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 8000
                          },
                          {
                              "name": "enable_enhance",
                              "label": {
                                  "zh_Hans": "功能增强",
                                  "en_US": "Enable Enhancement"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "功能增强（如搜索）开关，关闭时将直接由主模型生成回复内容，可以降低响应时延（对于流式输出时的首字时延尤为明显）。但在少数场景里，回复效果可能会下降。",
                                  "en_US": "Allow the model to perform external search to enhance the generation results."
                              },
                              "required": false,
                              "default": true
                          }
                      ],
                      "pricing": {
                          "input": "0.08",
                          "output": "0.08",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "hunyuan-turbo",
                      "label": {
                          "zh_Hans": "hunyuan-turbo",
                          "en_US": "hunyuan-turbo"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 32000
                          },
                          {
                              "name": "enable_enhance",
                              "label": {
                                  "zh_Hans": "功能增强",
                                  "en_US": "Enable Enhancement"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "功能增强（如搜索）开关，关闭时将直接由主模型生成回复内容，可以降低响应时延（对于流式输出时的首字时延尤为明显）。但在少数场景里，回复效果可能会下降。",
                                  "en_US": "Allow the model to perform external search to enhance the generation results."
                              },
                              "required": false,
                              "default": true
                          }
                      ],
                      "pricing": {
                          "input": "0.015",
                          "output": "0.05",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "hunyuan-vision",
                      "label": {
                          "zh_Hans": "hunyuan-vision",
                          "en_US": "hunyuan-vision"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 8000
                          },
                          {
                              "name": "enable_enhance",
                              "label": {
                                  "zh_Hans": "功能增强",
                                  "en_US": "Enable Enhancement"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "功能增强（如搜索）开关，关闭时将直接由主模型生成回复内容，可以降低响应时延（对于流式输出时的首字时延尤为明显）。但在少数场景里，回复效果可能会下降。",
                                  "en_US": "Allow the model to perform external search to enhance the generation results."
                              },
                              "required": false,
                              "default": true
                          }
                      ],
                      "pricing": {
                          "input": "0.018",
                          "output": "0.018",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "lke-text-embedding-v1",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 1024,
                          "max_chunks": 1
                      }
                  }
              ],
              "provider": "hunyuan",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "Secret ID"
                          },
                          "placeholder": {
                              "en_US": "Enter your Secret ID",
                              "zh_Hans": "在此输入您的 Secret ID"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "secret_id"
                      },
                      {
                          "label": {
                              "en_US": "Secret Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your Secret Key",
                              "zh_Hans": "在此输入您的 Secret Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "secret_key"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "WenXin",
              "zh_Hans": "文心一言"
          },
          "icon": "icon_s_en.png",
          "label": {
              "en_US": "WenXin",
              "zh_Hans": "文心一言"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "wenxin",
          "plugins": {
              "models": [
                  "provider/wenxin.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {}
          },
          "type": "plugin",
          "version": "0.0.6",
          "model": {
              "background": "#E8F5FE",
              "configurate_methods": [
                  "predefined-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/rerank/rerank.py",
                          "models/text_embedding/text_embedding.py"
                      ],
                      "provider_source": "provider/wenxin.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API Key from WenXin",
                      "zh_Hans": "从文心一言获取您的 API Key"
                  },
                  "url": {
                      "en_US": "https://cloud.baidu.com/wenxin.html"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.png",
                  "zh_Hans": "icon_l_zh.png"
              },
              "icon_small": {
                  "en_US": "icon_s_en.png",
                  "zh_Hans": "icon_s_en.png"
              },
              "label": {
                  "en_US": "WenXin",
                  "zh_Hans": "文心一言"
              },
              "models": [
                  {
                      "model": "ernie-3.5-128k",
                      "label": {
                          "en_US": "Ernie-3.5-128K"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.8
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 2,
                              "max": 4096
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "default": 1.0,
                              "min": 1.0,
                              "max": 2.0
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "disable_search",
                              "label": {
                                  "zh_Hans": "禁用搜索",
                                  "en_US": "Disable Search"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "禁用模型自行进行外部搜索。",
                                  "en_US": "Disable the model to perform external search."
                              },
                              "required": false
                          }
                      ]
                  },
                  {
                      "model": "ernie-3.5-4k-0205",
                      "label": {
                          "en_US": "Ernie-3.5-4k-0205"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.8
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 2,
                              "max": 2048
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "disable_search",
                              "label": {
                                  "zh_Hans": "禁用搜索",
                                  "en_US": "Disable Search"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "禁用模型自行进行外部搜索。",
                                  "en_US": "Disable the model to perform external search."
                              },
                              "required": false
                          }
                      ],
                      "deprecated": true
                  },
                  {
                      "model": "ernie-3.5-8k-0205",
                      "label": {
                          "en_US": "Ernie-3.5-8K-0205"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.8
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 2,
                              "max": 2048
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "disable_search",
                              "label": {
                                  "zh_Hans": "禁用搜索",
                                  "en_US": "Disable Search"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "禁用模型自行进行外部搜索。",
                                  "en_US": "Disable the model to perform external search."
                              },
                              "required": false
                          }
                      ],
                      "deprecated": true
                  },
                  {
                      "model": "ernie-3.5-8k-1222",
                      "label": {
                          "en_US": "Ernie-3.5-8K-1222"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.8
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 2,
                              "max": 2048
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "disable_search",
                              "label": {
                                  "zh_Hans": "禁用搜索",
                                  "en_US": "Disable Search"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "禁用模型自行进行外部搜索。",
                                  "en_US": "Disable the model to perform external search."
                              },
                              "required": false
                          }
                      ],
                      "deprecated": true
                  },
                  {
                      "model": "ernie-3.5-8k",
                      "label": {
                          "en_US": "Ernie-3.5-8K"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.8
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 2,
                              "max": 2048
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "default": 1.0,
                              "min": 1.0,
                              "max": 2.0
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "disable_search",
                              "label": {
                                  "zh_Hans": "禁用搜索",
                                  "en_US": "Disable Search"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "禁用模型自行进行外部搜索。",
                                  "en_US": "Disable the model to perform external search."
                              },
                              "required": false
                          }
                      ]
                  },
                  {
                      "model": "ernie-4.0-8k-latest",
                      "label": {
                          "en_US": "Ernie-4.0-8K-Latest"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.8
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 2,
                              "max": 2048
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "default": 1.0,
                              "min": 1.0,
                              "max": 2.0
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "disable_search",
                              "label": {
                                  "zh_Hans": "禁用搜索",
                                  "en_US": "Disable Search"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "禁用模型自行进行外部搜索。",
                                  "en_US": "Disable the model to perform external search."
                              },
                              "required": false
                          }
                      ]
                  },
                  {
                      "model": "ernie-4.0-8k",
                      "label": {
                          "en_US": "Ernie-4.0-8K"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.8
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 2,
                              "max": 2048
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "default": 1.0,
                              "min": 1.0,
                              "max": 2.0
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "disable_search",
                              "label": {
                                  "zh_Hans": "禁用搜索",
                                  "en_US": "Disable Search"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "禁用模型自行进行外部搜索。",
                                  "en_US": "Disable the model to perform external search."
                              },
                              "required": false
                          }
                      ]
                  },
                  {
                      "model": "ernie-4.0-turbo-128k",
                      "label": {
                          "en_US": "Ernie-4.0-turbo-128K"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.8
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 2,
                              "max": 4096
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "default": 1.0,
                              "min": 1.0,
                              "max": 2.0
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "disable_search",
                              "label": {
                                  "zh_Hans": "禁用搜索",
                                  "en_US": "Disable Search"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "禁用模型自行进行外部搜索。",
                                  "en_US": "Disable the model to perform external search."
                              },
                              "required": false
                          }
                      ]
                  },
                  {
                      "model": "ernie-4.0-turbo-8k-preview",
                      "label": {
                          "en_US": "Ernie-4.0-turbo-8k-preview"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.8
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 2,
                              "max": 2048
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "default": 1.0,
                              "min": 1.0,
                              "max": 2.0
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "disable_search",
                              "label": {
                                  "zh_Hans": "禁用搜索",
                                  "en_US": "Disable Search"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "禁用模型自行进行外部搜索。",
                                  "en_US": "Disable the model to perform external search."
                              },
                              "required": false
                          }
                      ]
                  },
                  {
                      "model": "ernie-4.0-turbo-8k",
                      "label": {
                          "en_US": "Ernie-4.0-turbo-8K"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.8
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 2,
                              "max": 2048
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "default": 1.0,
                              "min": 1.0,
                              "max": 2.0
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "disable_search",
                              "label": {
                                  "zh_Hans": "禁用搜索",
                                  "en_US": "Disable Search"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "禁用模型自行进行外部搜索。",
                                  "en_US": "Disable the model to perform external search."
                              },
                              "required": false
                          }
                      ]
                  },
                  {
                      "model": "ernie-bot-4",
                      "label": {
                          "en_US": "Ernie Bot 4"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4800
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.8
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 256,
                              "min": 1,
                              "max": 4800
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "disable_search",
                              "label": {
                                  "zh_Hans": "禁用搜索",
                                  "en_US": "Disable Search"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "禁用模型自行进行外部搜索。",
                                  "en_US": "Disable the model to perform external search."
                              },
                              "required": false
                          }
                      ],
                      "deprecated": true
                  },
                  {
                      "model": "ernie-bot-8k",
                      "label": {
                          "en_US": "Ernie Bot 8k"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.8
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 1024,
                              "min": 1,
                              "max": 8000
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "disable_search",
                              "label": {
                                  "zh_Hans": "禁用搜索",
                                  "en_US": "Disable Search"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "禁用模型自行进行外部搜索。",
                                  "en_US": "Disable the model to perform external search."
                              },
                              "required": false
                          }
                      ],
                      "deprecated": true
                  },
                  {
                      "model": "ernie-bot-turbo",
                      "label": {
                          "en_US": "Ernie Bot Turbo"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 11200
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.8
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 1024,
                              "min": 1,
                              "max": 11200
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "deprecated": true
                  },
                  {
                      "model": "ernie-bot",
                      "label": {
                          "en_US": "Ernie Bot"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4800
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.8
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 256,
                              "min": 1,
                              "max": 4800
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "disable_search",
                              "label": {
                                  "zh_Hans": "禁用搜索",
                                  "en_US": "Disable Search"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "禁用模型自行进行外部搜索。",
                                  "en_US": "Disable the model to perform external search."
                              },
                              "required": false
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "deprecated": true
                  },
                  {
                      "model": "ernie-character-8k-0321",
                      "label": {
                          "en_US": "ERNIE-Character-8K-0321"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.95
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1.0,
                              "default": 0.7
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 2,
                              "max": 1024
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "default": 1.0,
                              "min": 1.0,
                              "max": 2.0
                          }
                      ],
                      "deprecated": true
                  },
                  {
                      "model": "ernie-character-8k-0321",
                      "label": {
                          "en_US": "ERNIE-Character-8K"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.95
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1.0,
                              "default": 0.7
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 2,
                              "max": 1024
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "default": 1.0,
                              "min": 1.0,
                              "max": 2.0
                          }
                      ]
                  },
                  {
                      "model": "ernie-lite-8k-0308",
                      "label": {
                          "en_US": "ERNIE-Lite-8K-0308"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.95
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1.0,
                              "default": 0.7
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 2,
                              "max": 2048
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "default": 1.0,
                              "min": 1.0,
                              "max": 2.0
                          }
                      ],
                      "deprecated": true
                  },
                  {
                      "model": "ernie-lite-8k-0922",
                      "label": {
                          "en_US": "ERNIE-Lite-8K-0922"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.95
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1.0,
                              "default": 0.7
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 2,
                              "max": 1024
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "default": 1.0,
                              "min": 1.0,
                              "max": 2.0
                          }
                      ],
                      "deprecated": true
                  },
                  {
                      "model": "ernie-lite-pro-128k",
                      "label": {
                          "en_US": "Ernie-Lite-Pro-128K"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.8
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "min_output_tokens",
                              "label": {
                                  "en_US": "Min Output Tokens",
                                  "zh_Hans": "最小输出Token数"
                              },
                              "use_template": "max_tokens",
                              "min": 2,
                              "max": 2048,
                              "help": {
                                  "zh_Hans": "指定模型最小输出token数",
                                  "en_US": "Specifies the lower limit on the length of generated results."
                              }
                          },
                          {
                              "name": "max_output_tokens",
                              "label": {
                                  "en_US": "Max Output Tokens",
                                  "zh_Hans": "最大输出Token数"
                              },
                              "use_template": "max_tokens",
                              "min": 2,
                              "max": 2048,
                              "default": 2048,
                              "help": {
                                  "zh_Hans": "指定模型最大输出token数",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "default": 1.0,
                              "min": 1.0,
                              "max": 2.0
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          }
                      ]
                  },
                  {
                      "model": "ernie-speed-128k",
                      "label": {
                          "en_US": "ERNIE-Speed-128K"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.95
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1.0,
                              "default": 0.7
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 2,
                              "max": 4096
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "default": 1.0,
                              "min": 1.0,
                              "max": 2.0
                          }
                      ]
                  },
                  {
                      "model": "ernie-speed-8k",
                      "label": {
                          "en_US": "ERNIE-Speed-8K"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.95
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1.0,
                              "default": 0.7
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 2,
                              "max": 2048
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "default": 1.0,
                              "min": 1.0,
                              "max": 2.0
                          }
                      ]
                  },
                  {
                      "model": "ernie-speed-appbuilder",
                      "label": {
                          "en_US": "ERNIE-Speed-AppBuilder"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.95
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1.0,
                              "default": 0.7
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "default": 1.0,
                              "min": 1.0,
                              "max": 2.0
                          }
                      ]
                  },
                  {
                      "model": "ernie-speed-pro-128k",
                      "label": {
                          "en_US": "Ernie-speed-pro-128k"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.8
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 2,
                              "max": 4096
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "disable_search",
                              "label": {
                                  "zh_Hans": "禁用搜索",
                                  "en_US": "Disable Search"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "禁用模型自行进行外部搜索。",
                                  "en_US": "Disable the model to perform external search."
                              },
                              "required": false
                          }
                      ]
                  },
                  {
                      "model": "yi_34b_chat",
                      "label": {
                          "en_US": "yi_34b_chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.1,
                              "max": 1.0,
                              "default": 0.95
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1.0,
                              "default": 0.7
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 2,
                              "max": 4096
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "default": 1.0,
                              "min": 1.0,
                              "max": 2.0
                          }
                      ]
                  },
                  {
                      "model": "bce-reranker-base_v1",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 4096
                      },
                      "pricing": {
                          "input": "0.0005",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "bge-large-en",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 512,
                          "max_chunks": 16
                      },
                      "pricing": {
                          "input": "0.0005",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "bge-large-zh",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 512,
                          "max_chunks": 16
                      },
                      "pricing": {
                          "input": "0.0005",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "embedding-v1",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 384,
                          "max_chunks": 16
                      },
                      "pricing": {
                          "input": "0.0005",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "tao-8k",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 1
                      },
                      "pricing": {
                          "input": "0.0005",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  }
              ],
              "provider": "wenxin",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "label": {
                              "en_US": "Secret Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your Secret Key",
                              "zh_Hans": "在此输入您的 Secret Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "secret_key"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding",
                  "rerank"
              ]
          }
      },
      {
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "cohere",
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "Cohere",
              "zh_Hans": "Cohere"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "Cohere"
          },
          "plugins": {
              "models": [
                  "provider/cohere.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": false
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.8",
          "model": {
              "background": "#ECE9E3",
              "configurate_methods": [
                  "predefined-model",
                  "customizable-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/rerank/rerank.py",
                          "models/text_embedding/text_embedding.py"
                      ],
                      "provider_source": "provider/cohere.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API key from cohere",
                      "zh_Hans": "从 cohere 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://dashboard.cohere.com/api-keys"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "Cohere",
                  "zh_Hans": "Cohere"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "default": "chat",
                          "label": {
                              "en_US": "Completion mode"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Completion",
                                      "zh_Hans": "补全"
                                  },
                                  "value": "completion"
                              },
                              {
                                  "label": {
                                      "en_US": "Chat",
                                      "zh_Hans": "对话"
                                  },
                                  "value": "chat"
                              }
                          ],
                          "placeholder": {
                              "en_US": "Select completion mode",
                              "zh_Hans": "选择对话类型"
                          },
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "select",
                          "variable": "mode"
                      },
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "label": {
                              "en_US": "API Base",
                              "zh_Hans": "API Base"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Base, e.g. https://api.cohere.ai/v1",
                              "zh_Hans": "在此输入您的 API Base，如 https://api.cohere.ai/v1"
                          },
                          "required": false,
                          "type": "text-input",
                          "variable": "base_url"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  }
              },
              "models": [
                  {
                      "model": "c4ai-aya-expanse-32b",
                      "label": {
                          "en_US": "c4ai-aya-expanse-32b"
                      },
                      "model_type": "llm",
                      "features": [
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.3,
                              "max": 1.0
                          },
                          {
                              "name": "p",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0.01,
                              "max": 0.99
                          },
                          {
                              "name": "k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.5",
                          "output": "1.5",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "c4ai-aya-expanse-8b",
                      "label": {
                          "en_US": "c4ai-aya-expanse-8b"
                      },
                      "model_type": "llm",
                      "features": [
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.3,
                              "max": 1.0
                          },
                          {
                              "name": "p",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0.01,
                              "max": 0.99
                          },
                          {
                              "name": "k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.5",
                          "output": "1.5",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "command-a-03-2025",
                      "label": {
                          "en_US": "command-a-03-2025"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 256000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.3,
                              "max": 1.0
                          },
                          {
                              "name": "p",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0.01,
                              "max": 0.99
                          },
                          {
                              "name": "k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "2.5",
                          "output": "10",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "command-chat",
                      "label": {
                          "zh_Hans": "command-chat",
                          "en_US": "command-chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "max": 5.0
                          },
                          {
                              "name": "p",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0.01,
                              "max": 0.99
                          },
                          {
                              "name": "k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "max": 4096
                          },
                          {
                              "name": "preamble_override",
                              "label": {
                                  "zh_Hans": "前导文本",
                                  "en_US": "Preamble"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "当指定时，将使用提供的前导文本替换默认的 Cohere 前导文本。",
                                  "en_US": "When specified, the default Cohere preamble will be replaced with the provided one."
                              },
                              "required": false
                          },
                          {
                              "name": "prompt_truncation",
                              "label": {
                                  "zh_Hans": "提示截断",
                                  "en_US": "Prompt Truncation"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定如何构造 Prompt。当 prompt_truncation 设置为 \"AUTO\" 时，将会丢弃一些来自聊天记录的元素，以尝试构造一个符合模型上下文长度限制的 Prompt。",
                                  "en_US": "Dictates how the prompt will be constructed. With prompt_truncation set to \"AUTO\", some elements from chat histories will be dropped in an attempt to construct a prompt that fits within the model's context length limit."
                              },
                              "required": true,
                              "default": "AUTO",
                              "options": [
                                  "AUTO",
                                  "OFF"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "1.0",
                          "output": "2.0",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "command-light-chat",
                      "label": {
                          "zh_Hans": "command-light-chat",
                          "en_US": "command-light-chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "max": 5.0
                          },
                          {
                              "name": "p",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0.01,
                              "max": 0.99
                          },
                          {
                              "name": "k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "max": 4096
                          },
                          {
                              "name": "preamble_override",
                              "label": {
                                  "zh_Hans": "前导文本",
                                  "en_US": "Preamble"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "当指定时，将使用提供的前导文本替换默认的 Cohere 前导文本。",
                                  "en_US": "When specified, the default Cohere preamble will be replaced with the provided one."
                              },
                              "required": false
                          },
                          {
                              "name": "prompt_truncation",
                              "label": {
                                  "zh_Hans": "提示截断",
                                  "en_US": "Prompt Truncation"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定如何构造 Prompt。当 prompt_truncation 设置为 \"AUTO\" 时，将会丢弃一些来自聊天记录的元素，以尝试构造一个符合模型上下文长度限制的 Prompt。",
                                  "en_US": "Dictates how the prompt will be constructed. With prompt_truncation set to \"AUTO\", some elements from chat histories will be dropped in an attempt to construct a prompt that fits within the model's context length limit."
                              },
                              "required": true,
                              "default": "AUTO",
                              "options": [
                                  "AUTO",
                                  "OFF"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.3",
                          "output": "0.6",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "command-light-nightly-chat",
                      "label": {
                          "zh_Hans": "command-light-nightly-chat",
                          "en_US": "command-light-nightly-chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "max": 5.0
                          },
                          {
                              "name": "p",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0.01,
                              "max": 0.99
                          },
                          {
                              "name": "k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "max": 4096
                          },
                          {
                              "name": "preamble_override",
                              "label": {
                                  "zh_Hans": "前导文本",
                                  "en_US": "Preamble"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "当指定时，将使用提供的前导文本替换默认的 Cohere 前导文本。",
                                  "en_US": "When specified, the default Cohere preamble will be replaced with the provided one."
                              },
                              "required": false
                          },
                          {
                              "name": "prompt_truncation",
                              "label": {
                                  "zh_Hans": "提示截断",
                                  "en_US": "Prompt Truncation"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定如何构造 Prompt。当 prompt_truncation 设置为 \"AUTO\" 时，将会丢弃一些来自聊天记录的元素，以尝试构造一个符合模型上下文长度限制的 Prompt。",
                                  "en_US": "Dictates how the prompt will be constructed. With prompt_truncation set to \"AUTO\", some elements from chat histories will be dropped in an attempt to construct a prompt that fits within the model's context length limit."
                              },
                              "required": true,
                              "default": "AUTO",
                              "options": [
                                  "AUTO",
                                  "OFF"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.3",
                          "output": "0.6",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "command-light-nightly",
                      "label": {
                          "zh_Hans": "command-light-nightly",
                          "en_US": "command-light-nightly"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "completion",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "max": 5.0
                          },
                          {
                              "name": "p",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0.01,
                              "max": 0.99
                          },
                          {
                              "name": "k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.3",
                          "output": "0.6",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "command-light",
                      "label": {
                          "zh_Hans": "command-light",
                          "en_US": "command-light"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "completion",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "max": 5.0
                          },
                          {
                              "name": "p",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0.01,
                              "max": 0.99
                          },
                          {
                              "name": "k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.3",
                          "output": "0.6",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "command-nightly-chat",
                      "label": {
                          "zh_Hans": "command-nightly-chat",
                          "en_US": "command-nightly-chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.3,
                              "max": 1.0
                          },
                          {
                              "name": "p",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0.01,
                              "max": 0.99
                          },
                          {
                              "name": "k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "max": 4096
                          },
                          {
                              "name": "preamble_override",
                              "label": {
                                  "zh_Hans": "前导文本",
                                  "en_US": "Preamble"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "当指定时，将使用提供的前导文本替换默认的 Cohere 前导文本。",
                                  "en_US": "When specified, the default Cohere preamble will be replaced with the provided one."
                              },
                              "required": false
                          },
                          {
                              "name": "prompt_truncation",
                              "label": {
                                  "zh_Hans": "提示截断",
                                  "en_US": "Prompt Truncation"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定如何构造 Prompt。当 prompt_truncation 设置为 \"AUTO\" 时，将会丢弃一些来自聊天记录的元素，以尝试构造一个符合模型上下文长度限制的 Prompt。",
                                  "en_US": "Dictates how the prompt will be constructed. With prompt_truncation set to \"AUTO\", some elements from chat histories will be dropped in an attempt to construct a prompt that fits within the model's context length limit."
                              },
                              "required": true,
                              "default": "AUTO",
                              "options": [
                                  "AUTO",
                                  "OFF"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "1.0",
                          "output": "2.0",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "command-nightly",
                      "label": {
                          "zh_Hans": "command-nightly",
                          "en_US": "command-nightly"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "completion",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "max": 5.0
                          },
                          {
                              "name": "p",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0.01,
                              "max": 0.99
                          },
                          {
                              "name": "k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "1.0",
                          "output": "2.0",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "command-r-03-2024",
                      "label": {
                          "en_US": "command-r-03-2024"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.3,
                              "max": 1.0
                          },
                          {
                              "name": "p",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0.01,
                              "max": 0.99
                          },
                          {
                              "name": "k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.5",
                          "output": "1.5",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "command-r-08-2024",
                      "label": {
                          "en_US": "command-r-08-2024"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.3,
                              "max": 1.0
                          },
                          {
                              "name": "p",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0.01,
                              "max": 0.99
                          },
                          {
                              "name": "k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.15",
                          "output": "0.60",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "command-r-plus-04-2024",
                      "label": {
                          "en_US": "command-r-plus-04-2024"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.3,
                              "max": 1.0
                          },
                          {
                              "name": "p",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0.01,
                              "max": 0.99
                          },
                          {
                              "name": "k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "3",
                          "output": "15",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "command-r-plus-08-2024",
                      "label": {
                          "en_US": "command-r-plus-08-2024"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.3,
                              "max": 1.0
                          },
                          {
                              "name": "p",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0.01,
                              "max": 0.99
                          },
                          {
                              "name": "k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "2.50",
                          "output": "10.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "command-r-plus",
                      "label": {
                          "en_US": "command-r-plus"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.3,
                              "max": 1.0
                          },
                          {
                              "name": "p",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0.01,
                              "max": 0.99
                          },
                          {
                              "name": "k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "3",
                          "output": "15",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "command-r",
                      "label": {
                          "en_US": "command-r"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.3,
                              "max": 1.0
                          },
                          {
                              "name": "p",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0.01,
                              "max": 0.99
                          },
                          {
                              "name": "k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.5",
                          "output": "1.5",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "command-r7b-12-2024",
                      "label": {
                          "en_US": "command-r7b-12-2024"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.3,
                              "max": 1.0
                          },
                          {
                              "name": "p",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0.01,
                              "max": 0.99
                          },
                          {
                              "name": "k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.0375",
                          "output": "0.15",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "command-r7b-arabic-02-2025",
                      "label": {
                          "en_US": "command-r7b-arabic-02-2025"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.3,
                              "max": 1.0
                          },
                          {
                              "name": "p",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0.01,
                              "max": 0.99
                          },
                          {
                              "name": "k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.5",
                          "output": "1.5",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "command",
                      "label": {
                          "zh_Hans": "command",
                          "en_US": "command"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "completion",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "max": 5.0
                          },
                          {
                              "name": "p",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0.01,
                              "max": 0.99
                          },
                          {
                              "name": "k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "1.0",
                          "output": "2.0",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "rerank-english-v3.0",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 5120
                      }
                  },
                  {
                      "model": "rerank-multilingual-v3.0",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 5120
                      }
                  },
                  {
                      "model": "rerank-v3.5",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 5120
                      }
                  },
                  {
                      "model": "embed-english-light-v2.0",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 1024,
                          "max_chunks": 48
                      },
                      "pricing": {
                          "input": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "embed-english-light-v3.0",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 384,
                          "max_chunks": 48
                      },
                      "pricing": {
                          "input": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "embed-english-v2.0",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 4096,
                          "max_chunks": 48
                      },
                      "pricing": {
                          "input": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "embed-english-v3.0",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 1024,
                          "max_chunks": 48
                      },
                      "pricing": {
                          "input": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "embed-multilingual-light-v3.0",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 384,
                          "max_chunks": 48
                      },
                      "pricing": {
                          "input": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "embed-multilingual-v2.0",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 768,
                          "max_chunks": 48
                      },
                      "pricing": {
                          "input": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "embed-multilingual-v3.0",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 1024,
                          "max_chunks": 48
                      },
                      "pricing": {
                          "input": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  }
              ],
              "provider": "cohere",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key",
                              "zh_Hans": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "show_on": [],
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "label": {
                              "en_US": "API Base",
                              "zh_Hans": "API Base"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Base, e.g. https://api.cohere.ai/v1",
                              "zh_Hans": "在此输入您的 API Base，如 https://api.cohere.ai/v1"
                          },
                          "required": false,
                          "type": "text-input",
                          "variable": "base_url"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding",
                  "rerank"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "Minimax AI models for LLM, text embedding, and text-to-speech",
              "zh_Hans": "Minimax AI 提供的大语言模型、文本嵌入和语音合成服务"
          },
          "icon": "icon_s_en.png",
          "label": {
              "en_US": "Minimax"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "minimax",
          "plugins": {
              "models": [
                  "provider/minimax.yaml"
              ]
          },
          "resource": {
              "memory": 1048576,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": false,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": true
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.8",
          "model": {
              "background": "#FFEFEF",
              "configurate_methods": [
                  "predefined-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/text_embedding/text_embedding.py",
                          "models/tts/tts.py"
                      ],
                      "provider_source": "provider/minimax.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API Key from Minimax",
                      "zh_Hans": "从 Minimax 获取您的 API Key"
                  },
                  "url": {
                      "en_US": "https://platform.minimaxi.com/user-center/basic-information/interface-key"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.png"
              },
              "icon_small": {
                  "en_US": "icon_s_en.png"
              },
              "label": {
                  "en_US": "Minimax"
              },
              "models": [
                  {
                      "model": "abab5-chat",
                      "label": {
                          "en_US": "Abab5-Chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 6144
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 6144,
                              "min": 1,
                              "max": 6144
                          },
                          {
                              "name": "mask_sensitive_info",
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "隐私保护",
                                  "en_US": "Moderate"
                              },
                              "help": {
                                  "zh_Hans": "对输出中易涉及隐私问题的文本信息进行打码，目前包括但不限于邮箱、域名、链接、证件号、家庭住址等，默认true，即开启打码",
                                  "en_US": "Mask the sensitive info of the generated content, such as email/domain/link/address/phone/id.."
                              }
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          }
                      ],
                      "pricing": {
                          "input": "0.015",
                          "output": "0.015",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "abab5.5-chat",
                      "label": {
                          "en_US": "Abab5.5-Chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16384
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.01,
                              "max": 1,
                              "default": 0.9
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0.01,
                              "max": 1,
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 6144,
                              "min": 1,
                              "max": 16384
                          },
                          {
                              "name": "mask_sensitive_info",
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "隐私保护",
                                  "en_US": "Moderate"
                              },
                              "help": {
                                  "zh_Hans": "对输出中易涉及隐私问题的文本信息进行打码，目前包括但不限于邮箱、域名、链接、证件号、家庭住址等，默认true，即开启打码",
                                  "en_US": "Mask the sensitive info of the generated content, such as email/domain/link/address/phone/id.."
                              }
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "plugin_web_search",
                              "required": false,
                              "default": false,
                              "type": "boolean",
                              "label": {
                                  "en_US": "Enable Web Search",
                                  "zh_Hans": "开启网页搜索"
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.015",
                          "output": "0.015",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "abab5.5s-chat",
                      "label": {
                          "en_US": "Abab5.5s-Chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.01,
                              "max": 1,
                              "default": 0.9
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0.01,
                              "max": 1,
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 3072,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "mask_sensitive_info",
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "隐私保护",
                                  "en_US": "Moderate"
                              },
                              "help": {
                                  "zh_Hans": "对输出中易涉及隐私问题的文本信息进行打码，目前包括但不限于邮箱、域名、链接、证件号、家庭住址等，默认true，即开启打码",
                                  "en_US": "Mask the sensitive info of the generated content, such as email/domain/link/address/phone/id.."
                              }
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          }
                      ],
                      "pricing": {
                          "input": "0.005",
                          "output": "0.005",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "abab6-chat",
                      "label": {
                          "en_US": "Abab6-Chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.01,
                              "max": 1,
                              "default": 0.1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0.01,
                              "max": 1,
                              "default": 0.9
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 2048,
                              "min": 1,
                              "max": 32768
                          },
                          {
                              "name": "mask_sensitive_info",
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "隐私保护",
                                  "en_US": "Moderate"
                              },
                              "help": {
                                  "zh_Hans": "对输出中易涉及隐私问题的文本信息进行打码，目前包括但不限于邮箱、域名、链接、证件号、家庭住址等，默认true，即开启打码",
                                  "en_US": "Mask the sensitive info of the generated content, such as email/domain/link/address/phone/id.."
                              }
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          }
                      ],
                      "pricing": {
                          "input": "0.1",
                          "output": "0.1",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "abab6.5-chat",
                      "label": {
                          "en_US": "Abab6.5-Chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.01,
                              "max": 1,
                              "default": 0.1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0.01,
                              "max": 1,
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 2048,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "mask_sensitive_info",
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "隐私保护",
                                  "en_US": "Moderate"
                              },
                              "help": {
                                  "zh_Hans": "对输出中易涉及隐私问题的文本信息进行打码，目前包括但不限于邮箱、域名、链接、证件号、家庭住址等，默认true，即开启打码",
                                  "en_US": "Mask the sensitive info of the generated content, such as email/domain/link/address/phone/id.."
                              }
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          }
                      ],
                      "pricing": {
                          "input": "0.03",
                          "output": "0.03",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "abab6.5s-chat",
                      "label": {
                          "en_US": "Abab6.5s-Chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 245760
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.01,
                              "max": 1,
                              "default": 0.1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0.01,
                              "max": 1,
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 2048,
                              "min": 1,
                              "max": 245760
                          },
                          {
                              "name": "mask_sensitive_info",
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "隐私保护",
                                  "en_US": "Moderate"
                              },
                              "help": {
                                  "zh_Hans": "对输出中易涉及隐私问题的文本信息进行打码，目前包括但不限于邮箱、域名、链接、证件号、家庭住址等，默认true，即开启打码",
                                  "en_US": "Mask the sensitive info of the generated content, such as email/domain/link/address/phone/id.."
                              }
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          }
                      ],
                      "pricing": {
                          "input": "0.01",
                          "output": "0.01",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "abab6.5t-chat",
                      "label": {
                          "en_US": "Abab6.5t-Chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.01,
                              "max": 1,
                              "default": 0.9
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0.01,
                              "max": 1,
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 3072,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "mask_sensitive_info",
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "隐私保护",
                                  "en_US": "Moderate"
                              },
                              "help": {
                                  "zh_Hans": "对输出中易涉及隐私问题的文本信息进行打码，目前包括但不限于邮箱、域名、链接、证件号、家庭住址等，默认true，即开启打码",
                                  "en_US": "Mask the sensitive info of the generated content, such as email/domain/link/address/phone/id.."
                              }
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          }
                      ],
                      "pricing": {
                          "input": "0.005",
                          "output": "0.005",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "abab7-chat-preview",
                      "label": {
                          "en_US": "Abab7-chat-preview"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 245760
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.01,
                              "max": 1,
                              "default": 0.1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0.01,
                              "max": 1,
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 2048,
                              "min": 1,
                              "max": 245760
                          },
                          {
                              "name": "mask_sensitive_info",
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "隐私保护",
                                  "en_US": "Moderate"
                              },
                              "help": {
                                  "zh_Hans": "对输出中易涉及隐私问题的文本信息进行打码，目前包括但不限于邮箱、域名、链接、证件号、家庭住址等，默认true，即开启打码",
                                  "en_US": "Mask the sensitive info of the generated content, such as email/domain/link/address/phone/id.."
                              }
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          }
                      ],
                      "pricing": {
                          "input": "0.1",
                          "output": "0.1",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "minimax-m1",
                      "label": {
                          "en_US": "MiniMax-M1"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1000000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.01,
                              "max": 1,
                              "default": 0.1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0.01,
                              "max": 1,
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 8192,
                              "min": 1,
                              "max": 1000000
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          }
                      ],
                      "pricing": {
                          "input": "0.8",
                          "output": "2.4",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "minimax-text-01",
                      "label": {
                          "en_US": "Minimax-Text-01"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1000192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0.01,
                              "max": 1,
                              "default": 0.1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0.01,
                              "max": 1,
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 2048,
                              "min": 1,
                              "max": 1000192
                          },
                          {
                              "name": "mask_sensitive_info",
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "隐私保护",
                                  "en_US": "Moderate"
                              },
                              "help": {
                                  "zh_Hans": "对输出中易涉及隐私问题的文本信息进行打码，目前包括但不限于邮箱、域名、链接、证件号、家庭住址等，默认true，即开启打码",
                                  "en_US": "Mask the sensitive info of the generated content, such as email/domain/link/address/phone/id.."
                              }
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          }
                      ],
                      "pricing": {
                          "input": "0.001",
                          "output": "0.008",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "embo-01",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 4096,
                          "max_chunks": 1
                      },
                      "pricing": {
                          "input": "0.0005",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "speech-01-hd",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "male-qn-qingse",
                          "voices": [
                              {
                                  "name": "青涩青年音色",
                                  "mode": "male-qn-qingse",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "精英青年音色",
                                  "mode": "male-qn-jingying",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "霸道青年音色",
                                  "mode": "male-qn-badao",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "青年大学生音色",
                                  "mode": "male-qn-daxuesheng",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "少女音色",
                                  "mode": "female-shaonv",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "御姐音色",
                                  "mode": "female-yujie",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "成熟女性音色",
                                  "mode": "female-chengshu",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "甜美女性音色",
                                  "mode": "female-tianmei",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "男性主持人",
                                  "mode": "presenter_male",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "女性主持人",
                                  "mode": "presenter_female",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "男性有声书1",
                                  "mode": "audiobook_male_1",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "男性有声书2",
                                  "mode": "audiobook_male_2",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "女性有声书1",
                                  "mode": "audiobook_female_1",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "女性有声书2",
                                  "mode": "audiobook_female_2",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "青涩青年音色(精品版)",
                                  "mode": "male-qn-qingse-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "精英青年音色(精品版)",
                                  "mode": "male-qn-jingying-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "霸道青年音色(精品版)",
                                  "mode": "male-qn-badao-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "青年大学生音色(精品版)",
                                  "mode": "male-qn-daxuesheng-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "少女音色(精品版)",
                                  "mode": "female-shaonv-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "御姐音色(精品版)",
                                  "mode": "female-yujie-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "成熟女性音色(精品版)",
                                  "mode": "female-chengshu-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "甜美女性音色(精品版)",
                                  "mode": "female-tianmei-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "聪明男童",
                                  "mode": "clever_boy",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "可爱男童",
                                  "mode": "cute_boy",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "萌萌女童",
                                  "mode": "lovely_girl",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "卡通猪小琪",
                                  "mode": "cartoon_pig",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "病娇弟弟",
                                  "mode": "bingjiao_didi",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "俊朗男友",
                                  "mode": "junlang_nanyou",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "纯真学弟",
                                  "mode": "chunzhen_xuedi",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "冷淡学长",
                                  "mode": "lengdan_xiongzhang",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "霸道少爷",
                                  "mode": "badao_shaoye",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "甜心小玲",
                                  "mode": "tianxin_xiaoling",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "俏皮萌妹",
                                  "mode": "qiaopi_mengmei",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "妩媚御姐",
                                  "mode": "wumei_yujie",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "嗲嗲学妹",
                                  "mode": "diadia_xuemei",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "淡雅学姐",
                                  "mode": "danya_xuejie",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "Santa Claus",
                                  "mode": "Santa_Claus",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Grinch",
                                  "mode": "Grinch",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Rudolph",
                                  "mode": "Rudolph",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Arnold",
                                  "mode": "Arnold",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Charming Santa",
                                  "mode": "Charming_Santa",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Charming Lady",
                                  "mode": "Charming_Lady",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Sweet Girl",
                                  "mode": "Sweet_Girl",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Cute Elf",
                                  "mode": "Cute_Elf",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Attractive Girl",
                                  "mode": "Attractive_Girl",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Serene Woman",
                                  "mode": "Serene_Woman",
                                  "language": [
                                      "en-US"
                                  ]
                              }
                          ],
                          "word_limit": 8000,
                          "audio_type": "mp3",
                          "max_workers": 5
                      },
                      "pricing": {
                          "input": "1",
                          "output": "0",
                          "unit": "0.0001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "speech-01-turbo",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "male-qn-qingse",
                          "voices": [
                              {
                                  "name": "青涩青年音色",
                                  "mode": "male-qn-qingse",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "精英青年音色",
                                  "mode": "male-qn-jingying",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "霸道青年音色",
                                  "mode": "male-qn-badao",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "青年大学生音色",
                                  "mode": "male-qn-daxuesheng",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "少女音色",
                                  "mode": "female-shaonv",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "御姐音色",
                                  "mode": "female-yujie",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "成熟女性音色",
                                  "mode": "female-chengshu",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "甜美女性音色",
                                  "mode": "female-tianmei",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "男性主持人",
                                  "mode": "presenter_male",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "女性主持人",
                                  "mode": "presenter_female",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "男性有声书1",
                                  "mode": "audiobook_male_1",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "男性有声书2",
                                  "mode": "audiobook_male_2",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "女性有声书1",
                                  "mode": "audiobook_female_1",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "女性有声书2",
                                  "mode": "audiobook_female_2",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "青涩青年音色(精品版)",
                                  "mode": "male-qn-qingse-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "精英青年音色(精品版)",
                                  "mode": "male-qn-jingying-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "霸道青年音色(精品版)",
                                  "mode": "male-qn-badao-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "青年大学生音色(精品版)",
                                  "mode": "male-qn-daxuesheng-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "少女音色(精品版)",
                                  "mode": "female-shaonv-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "御姐音色(精品版)",
                                  "mode": "female-yujie-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "成熟女性音色(精品版)",
                                  "mode": "female-chengshu-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "甜美女性音色(精品版)",
                                  "mode": "female-tianmei-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "聪明男童",
                                  "mode": "clever_boy",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "可爱男童",
                                  "mode": "cute_boy",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "萌萌女童",
                                  "mode": "lovely_girl",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "卡通猪小琪",
                                  "mode": "cartoon_pig",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "病娇弟弟",
                                  "mode": "bingjiao_didi",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "俊朗男友",
                                  "mode": "junlang_nanyou",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "纯真学弟",
                                  "mode": "chunzhen_xuedi",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "冷淡学长",
                                  "mode": "lengdan_xiongzhang",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "霸道少爷",
                                  "mode": "badao_shaoye",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "甜心小玲",
                                  "mode": "tianxin_xiaoling",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "俏皮萌妹",
                                  "mode": "qiaopi_mengmei",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "妩媚御姐",
                                  "mode": "wumei_yujie",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "嗲嗲学妹",
                                  "mode": "diadia_xuemei",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "淡雅学姐",
                                  "mode": "danya_xuejie",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "Santa Claus",
                                  "mode": "Santa_Claus",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Grinch",
                                  "mode": "Grinch",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Rudolph",
                                  "mode": "Rudolph",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Arnold",
                                  "mode": "Arnold",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Charming Santa",
                                  "mode": "Charming_Santa",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Charming Lady",
                                  "mode": "Charming_Lady",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Sweet Girl",
                                  "mode": "Sweet_Girl",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Cute Elf",
                                  "mode": "Cute_Elf",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Attractive Girl",
                                  "mode": "Attractive_Girl",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Serene Woman",
                                  "mode": "Serene_Woman",
                                  "language": [
                                      "en-US"
                                  ]
                              }
                          ],
                          "word_limit": 8000,
                          "audio_type": "mp3",
                          "max_workers": 5
                      },
                      "pricing": {
                          "input": "1",
                          "output": "0",
                          "unit": "0.0001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "speech-02-hd",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "male-qn-qingse",
                          "voices": [
                              {
                                  "name": "青涩青年音色",
                                  "mode": "male-qn-qingse",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "精英青年音色",
                                  "mode": "male-qn-jingying",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "霸道青年音色",
                                  "mode": "male-qn-badao",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "青年大学生音色",
                                  "mode": "male-qn-daxuesheng",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "少女音色",
                                  "mode": "female-shaonv",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "御姐音色",
                                  "mode": "female-yujie",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "成熟女性音色",
                                  "mode": "female-chengshu",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "甜美女性音色",
                                  "mode": "female-tianmei",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "男性主持人",
                                  "mode": "presenter_male",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "女性主持人",
                                  "mode": "presenter_female",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "男性有声书1",
                                  "mode": "audiobook_male_1",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "男性有声书2",
                                  "mode": "audiobook_male_2",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "女性有声书1",
                                  "mode": "audiobook_female_1",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "女性有声书2",
                                  "mode": "audiobook_female_2",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "青涩青年音色(精品版)",
                                  "mode": "male-qn-qingse-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "精英青年音色(精品版)",
                                  "mode": "male-qn-jingying-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "霸道青年音色(精品版)",
                                  "mode": "male-qn-badao-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "青年大学生音色(精品版)",
                                  "mode": "male-qn-daxuesheng-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "少女音色(精品版)",
                                  "mode": "female-shaonv-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "御姐音色(精品版)",
                                  "mode": "female-yujie-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "成熟女性音色(精品版)",
                                  "mode": "female-chengshu-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "甜美女性音色(精品版)",
                                  "mode": "female-tianmei-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "聪明男童",
                                  "mode": "clever_boy",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "可爱男童",
                                  "mode": "cute_boy",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "萌萌女童",
                                  "mode": "lovely_girl",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "卡通猪小琪",
                                  "mode": "cartoon_pig",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "病娇弟弟",
                                  "mode": "bingjiao_didi",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "俊朗男友",
                                  "mode": "junlang_nanyou",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "纯真学弟",
                                  "mode": "chunzhen_xuedi",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "冷淡学长",
                                  "mode": "lengdan_xiongzhang",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "霸道少爷",
                                  "mode": "badao_shaoye",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "甜心小玲",
                                  "mode": "tianxin_xiaoling",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "俏皮萌妹",
                                  "mode": "qiaopi_mengmei",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "妩媚御姐",
                                  "mode": "wumei_yujie",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "嗲嗲学妹",
                                  "mode": "diadia_xuemei",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "淡雅学姐",
                                  "mode": "danya_xuejie",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "Santa Claus",
                                  "mode": "Santa_Claus",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Grinch",
                                  "mode": "Grinch",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Rudolph",
                                  "mode": "Rudolph",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Arnold",
                                  "mode": "Arnold",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Charming Santa",
                                  "mode": "Charming_Santa",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Charming Lady",
                                  "mode": "Charming_Lady",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Sweet Girl",
                                  "mode": "Sweet_Girl",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Cute Elf",
                                  "mode": "Cute_Elf",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Attractive Girl",
                                  "mode": "Attractive_Girl",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Serene Woman",
                                  "mode": "Serene_Woman",
                                  "language": [
                                      "en-US"
                                  ]
                              }
                          ],
                          "word_limit": 8000,
                          "audio_type": "mp3",
                          "max_workers": 5
                      },
                      "pricing": {
                          "input": "1",
                          "output": "0",
                          "unit": "0.0001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "speech-02-turbo",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "male-qn-qingse",
                          "voices": [
                              {
                                  "name": "青涩青年音色",
                                  "mode": "male-qn-qingse",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "精英青年音色",
                                  "mode": "male-qn-jingying",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "霸道青年音色",
                                  "mode": "male-qn-badao",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "青年大学生音色",
                                  "mode": "male-qn-daxuesheng",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "少女音色",
                                  "mode": "female-shaonv",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "御姐音色",
                                  "mode": "female-yujie",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "成熟女性音色",
                                  "mode": "female-chengshu",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "甜美女性音色",
                                  "mode": "female-tianmei",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "男性主持人",
                                  "mode": "presenter_male",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "女性主持人",
                                  "mode": "presenter_female",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "男性有声书1",
                                  "mode": "audiobook_male_1",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "男性有声书2",
                                  "mode": "audiobook_male_2",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "女性有声书1",
                                  "mode": "audiobook_female_1",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "女性有声书2",
                                  "mode": "audiobook_female_2",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "青涩青年音色(精品版)",
                                  "mode": "male-qn-qingse-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "精英青年音色(精品版)",
                                  "mode": "male-qn-jingying-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "霸道青年音色(精品版)",
                                  "mode": "male-qn-badao-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "青年大学生音色(精品版)",
                                  "mode": "male-qn-daxuesheng-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "少女音色(精品版)",
                                  "mode": "female-shaonv-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "御姐音色(精品版)",
                                  "mode": "female-yujie-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "成熟女性音色(精品版)",
                                  "mode": "female-chengshu-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "甜美女性音色(精品版)",
                                  "mode": "female-tianmei-jingpin",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "聪明男童",
                                  "mode": "clever_boy",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "可爱男童",
                                  "mode": "cute_boy",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "萌萌女童",
                                  "mode": "lovely_girl",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "卡通猪小琪",
                                  "mode": "cartoon_pig",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "病娇弟弟",
                                  "mode": "bingjiao_didi",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "俊朗男友",
                                  "mode": "junlang_nanyou",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "纯真学弟",
                                  "mode": "chunzhen_xuedi",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "冷淡学长",
                                  "mode": "lengdan_xiongzhang",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "霸道少爷",
                                  "mode": "badao_shaoye",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "甜心小玲",
                                  "mode": "tianxin_xiaoling",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "俏皮萌妹",
                                  "mode": "qiaopi_mengmei",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "妩媚御姐",
                                  "mode": "wumei_yujie",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "嗲嗲学妹",
                                  "mode": "diadia_xuemei",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "淡雅学姐",
                                  "mode": "danya_xuejie",
                                  "language": [
                                      "zh-Hans"
                                  ]
                              },
                              {
                                  "name": "Santa Claus",
                                  "mode": "Santa_Claus",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Grinch",
                                  "mode": "Grinch",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Rudolph",
                                  "mode": "Rudolph",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Arnold",
                                  "mode": "Arnold",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Charming Santa",
                                  "mode": "Charming_Santa",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Charming Lady",
                                  "mode": "Charming_Lady",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Sweet Girl",
                                  "mode": "Sweet_Girl",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Cute Elf",
                                  "mode": "Cute_Elf",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Attractive Girl",
                                  "mode": "Attractive_Girl",
                                  "language": [
                                      "en-US"
                                  ]
                              },
                              {
                                  "name": "Serene Woman",
                                  "mode": "Serene_Woman",
                                  "language": [
                                      "en-US"
                                  ]
                              }
                          ],
                          "word_limit": 8000,
                          "audio_type": "mp3",
                          "max_workers": 5
                      },
                      "pricing": {
                          "input": "1",
                          "output": "0",
                          "unit": "0.0001",
                          "currency": "RMB"
                      }
                  }
              ],
              "provider": "minimax",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "minimax_api_key"
                      },
                      {
                          "label": {
                              "en_US": "Group ID"
                          },
                          "placeholder": {
                              "en_US": "Enter your group ID",
                              "zh_Hans": "在此输入您的 Group ID"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "minimax_group_id"
                      },
                      {
                          "default": "https://api.minimaxi.com",
                          "label": {
                              "en_US": "API Base",
                              "zh_Hans": "API Base"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Base",
                              "zh_Hans": "在此输入您的 API Base"
                          },
                          "required": false,
                          "type": "text-input",
                          "variable": "endpoint_url"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding",
                  "tts"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "LocalAI"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "LocalAI"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "localai",
          "plugins": {
              "models": [
                  "provider/localai.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.3",
          "model": {
              "background": "#F3F4F6",
              "configurate_methods": [
                  "customizable-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/rerank/rerank.py",
                          "models/text_embedding/text_embedding.py",
                          "models/speech2text/speech2text.py"
                      ],
                      "provider_source": "provider/localai.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "How to deploy LocalAI",
                      "zh_Hans": "如何部署 LocalAI"
                  },
                  "url": {
                      "en_US": "https://github.com/go-skynet/LocalAI"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "LocalAI"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "default": "chat_completion",
                          "label": {
                              "en_US": "Completion type"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Completion",
                                      "zh_Hans": "补全"
                                  },
                                  "value": "completion"
                              },
                              {
                                  "label": {
                                      "en_US": "ChatCompletion",
                                      "zh_Hans": "对话"
                                  },
                                  "value": "chat_completion"
                              }
                          ],
                          "placeholder": {
                              "en_US": "Select completion type",
                              "zh_Hans": "选择对话类型"
                          },
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "select",
                          "variable": "completion_type"
                      },
                      {
                          "label": {
                              "en_US": "Server url",
                              "zh_Hans": "服务器URL"
                          },
                          "placeholder": {
                              "en_US": "Enter the url of your LocalAI, e.g. http://192.168.1.100:8080",
                              "zh_Hans": "在此输入LocalAI的服务器地址，如 http://192.168.1.100:8080"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "server_url"
                      },
                      {
                          "label": {
                              "en_US": "Context size",
                              "zh_Hans": "上下文大小"
                          },
                          "placeholder": {
                              "en_US": "Enter context size",
                              "zh_Hans": "输入上下文大小"
                          },
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "text-input",
                          "variable": "context_size"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  }
              },
              "provider": "localai",
              "supported_model_types": [
                  "llm",
                  "text-embedding",
                  "rerank",
                  "speech2text"
              ],
              "models": []
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "xAI is a company working on building artificial intelligence to accelerate human scientific discovery. We are guided by our mission to advance our collective understanding of the universe."
          },
          "icon": "x-ai-logo.svg",
          "label": {
              "en_US": "xAI"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "x",
          "plugins": {
              "models": [
                  "provider/x.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.9",
          "model": {
              "configurate_methods": [
                  "predefined-model"
              ],
              "description": {
                  "en_US": "xAI is a company working on building artificial intelligence to accelerate human scientific discovery. We are guided by our mission to advance our collective understanding of the universe."
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py"
                      ],
                      "provider_source": "provider/x.py"
                  }
              },
              "models": [
                  {
                      "model": "grok-2-1212",
                      "label": {
                          "en_US": "grok-2-1212"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1.0,
                              "min": 0.0,
                              "max": 2.0
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2.0,
                              "max": 2.0
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2.0,
                              "max": 2.0
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "2.00",
                          "output": "10.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "grok-2-vision-1212",
                      "label": {
                          "en_US": "grok-2-vision-1212"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1.0,
                              "min": 0.0,
                              "max": 2.0
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2.0,
                              "max": 2.0
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2.0,
                              "max": 2.0
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "2.00",
                          "output": "10.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "grok-3-fast",
                      "label": {
                          "en_US": "grok-3-fast"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1.0,
                              "min": 0.0,
                              "max": 2.0
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2.0,
                              "max": 2.0
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          },
                          {
                              "name": "search_parameters",
                              "label": {
                                  "zh_Hans": "联网搜索参数",
                                  "en_US": "Live Search Parameters"
                              },
                              "type": "text",
                              "default": "{\n  \"mode\": \"auto\"\n}",
                              "help": {
                                  "zh_Hans": "传递给联网搜索的参数，具体参数见 https://docs.x.ai/docs/api-reference#chat-completions",
                                  "en_US": "Parameters to pass to the live search, see https://docs.x.ai/docs/api-reference#chat-completions"
                              },
                              "required": false
                          }
                      ],
                      "pricing": {
                          "input": "5.00",
                          "output": "25.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "grok-3-mini-fast",
                      "label": {
                          "en_US": "grok-3-mini-fast"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1.0,
                              "min": 0.0,
                              "max": 2.0
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2.0,
                              "max": 2.0
                          },
                          {
                              "name": "reasoning_effort",
                              "label": {
                                  "zh_Hans": "推理工作",
                                  "en_US": "reasoning_effort"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "限制推理模型的推理工作",
                                  "en_US": "constrains effort on reasoning for reasoning models"
                              },
                              "required": false,
                              "options": [
                                  "low",
                                  "high"
                              ]
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          },
                          {
                              "name": "search_parameters",
                              "label": {
                                  "zh_Hans": "联网搜索参数",
                                  "en_US": "Live Search Parameters"
                              },
                              "type": "text",
                              "default": "{\n  \"mode\": \"auto\"\n}",
                              "help": {
                                  "zh_Hans": "传递给联网搜索的参数，具体参数见 https://docs.x.ai/docs/api-reference#chat-completions",
                                  "en_US": "Parameters to pass to the live search, see https://docs.x.ai/docs/api-reference#chat-completions"
                              },
                              "required": false
                          }
                      ],
                      "pricing": {
                          "input": "0.60",
                          "output": "4.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "grok-3-mini",
                      "label": {
                          "en_US": "grok-3-mini"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1.0,
                              "min": 0.0,
                              "max": 2.0
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2.0,
                              "max": 2.0
                          },
                          {
                              "name": "reasoning_effort",
                              "label": {
                                  "zh_Hans": "推理工作",
                                  "en_US": "reasoning_effort"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "限制推理模型的推理工作",
                                  "en_US": "constrains effort on reasoning for reasoning models"
                              },
                              "required": false,
                              "options": [
                                  "low",
                                  "high"
                              ]
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          },
                          {
                              "name": "search_parameters",
                              "label": {
                                  "zh_Hans": "联网搜索参数",
                                  "en_US": "Live Search Parameters"
                              },
                              "type": "text",
                              "default": "{\n  \"mode\": \"auto\"\n}",
                              "help": {
                                  "zh_Hans": "传递给联网搜索的参数，具体参数见 https://docs.x.ai/docs/api-reference#chat-completions",
                                  "en_US": "Parameters to pass to the live search, see https://docs.x.ai/docs/api-reference#chat-completions"
                              },
                              "required": false
                          }
                      ],
                      "pricing": {
                          "input": "0.30",
                          "output": "0.50",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "grok-3",
                      "label": {
                          "en_US": "grok-3"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1.0,
                              "min": 0.0,
                              "max": 2.0
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2.0,
                              "max": 2.0
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          },
                          {
                              "name": "search_parameters",
                              "label": {
                                  "zh_Hans": "联网搜索参数",
                                  "en_US": "Live Search Parameters"
                              },
                              "type": "text",
                              "default": "{\n  \"mode\": \"auto\"\n}",
                              "help": {
                                  "zh_Hans": "传递给联网搜索的参数，具体参数见 https://docs.x.ai/docs/api-reference#chat-completions",
                                  "en_US": "Parameters to pass to the live search, see https://docs.x.ai/docs/api-reference#chat-completions"
                              },
                              "required": false
                          }
                      ],
                      "pricing": {
                          "input": "3.00",
                          "output": "15.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  }
              ],
              "help": {
                  "title": {
                      "en_US": "Get your token from xAI",
                      "zh_Hans": "从 xAI 获取 token"
                  },
                  "url": {
                      "en_US": "https://x.ai/api"
                  }
              },
              "icon_large": {
                  "en_US": "x-ai-logo.svg"
              },
              "icon_small": {
                  "en_US": "x-ai-logo.svg"
              },
              "label": {
                  "en_US": "xAI"
              },
              "provider": "x",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "default": "grok-3-mini",
                          "label": {
                              "en_US": "Model",
                              "zh_Hans": "模型"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "grok-3-mini"
                                  },
                                  "value": "grok-3-mini"
                              },
                              {
                                  "label": {
                                      "en_US": "grok-3"
                                  },
                                  "value": "grok-3"
                              },
                              {
                                  "label": {
                                      "en_US": "grok-3-fast"
                                  },
                                  "value": "grok-3-fast"
                              },
                              {
                                  "label": {
                                      "en_US": "grok-3-mini-fast"
                                  },
                                  "value": "grok-3-mini-fast"
                              },
                              {
                                  "label": {
                                      "en_US": "grok-2-1212"
                                  },
                                  "value": "grok-2-1212"
                              },
                              {
                                  "label": {
                                      "en_US": "grok-2-vision-1212"
                                  },
                                  "value": "grok-2-vision-1212"
                              }
                          ],
                          "required": false,
                          "type": "select",
                          "variable": "model"
                      },
                      {
                          "default": "https://api.x.ai/v1",
                          "label": {
                              "en_US": "API Base"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Base",
                              "zh_Hans": "在此输入您的 API Base"
                          },
                          "required": false,
                          "type": "text-input",
                          "variable": "endpoint_url"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "GPUStack is an open-source GPU cluster manager for running AI models.",
              "zh_Hans": "GPUStack 是一个专为运行 AI 模型而设计的开源 GPU 集群管理器，致力于支持基于任何品牌的异构 GPU 构建统一管理的算力集群"
          },
          "icon": "icon_s_en.png",
          "label": {
              "en_US": "GPUStack"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "gpustack",
          "plugins": {
              "models": [
                  "provider/gpustack.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": true,
                      "text_embedding": true,
                      "tts": true
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.8",
          "model": {
              "configurate_methods": [
                  "customizable-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/rerank/rerank.py",
                          "models/speech2text/speech2text.py",
                          "models/tts/tts.py",
                          "models/text_embedding/text_embedding.py"
                      ],
                      "provider_source": "provider/gpustack.py"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.png"
              },
              "icon_small": {
                  "en_US": "icon_s_en.png"
              },
              "label": {
                  "en_US": "GPUStack"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "Server URL",
                              "zh_Hans": "服务器地址"
                          },
                          "placeholder": {
                              "en_US": "Enter the GPUStack server URL, e.g. http://192.168.1.100",
                              "zh_Hans": "输入 GPUStack 的服务器地址，如 http://192.168.1.100"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "endpoint_url"
                      },
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "default": "chat",
                          "label": {
                              "en_US": "Completion mode"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Completion",
                                      "zh_Hans": "补全"
                                  },
                                  "value": "completion"
                              },
                              {
                                  "label": {
                                      "en_US": "Chat",
                                      "zh_Hans": "对话"
                                  },
                                  "value": "chat"
                              }
                          ],
                          "placeholder": {
                              "en_US": "Select completion type",
                              "zh_Hans": "选择补全类型"
                          },
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "select",
                          "variable": "mode"
                      },
                      {
                          "default": "8192",
                          "label": {
                              "en_US": "Model context size",
                              "zh_Hans": "模型上下文长度"
                          },
                          "placeholder": {
                              "en_US": "Enter your Model context size",
                              "zh_Hans": "输入您的模型上下文长度"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "context_size"
                      },
                      {
                          "default": "8192",
                          "label": {
                              "en_US": "Upper bound for max tokens",
                              "zh_Hans": "最大 token 上限"
                          },
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "text-input",
                          "variable": "max_tokens_to_sample"
                      },
                      {
                          "variable": "agent_thought_support",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "en_US": "Agent Thought"
                          },
                          "type": "select",
                          "required": false,
                          "default": "not_supported",
                          "options": [
                              {
                                  "value": "supported",
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  }
                              },
                              {
                                  "value": "not_supported",
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  }
                              }
                          ]
                      },
                      {
                          "default": "no_call",
                          "label": {
                              "en_US": "Function calling"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Function Call",
                                      "zh_Hans": "Function Call"
                                  },
                                  "value": "function_call"
                              },
                              {
                                  "label": {
                                      "en_US": "Tool Call",
                                      "zh_Hans": "Tool Call"
                                  },
                                  "value": "tool_call"
                              },
                              {
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  },
                                  "value": "no_call"
                              }
                          ],
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "select",
                          "variable": "function_calling_type"
                      },
                      {
                          "default": "not_support",
                          "label": {
                              "en_US": "Stream Function Calling"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Supported",
                                      "zh_Hans": "支持"
                                  },
                                  "value": "supported"
                              },
                              {
                                  "label": {
                                      "en_US": "Not Supported",
                                      "zh_Hans": "不支持"
                                  },
                                  "value": "not_support"
                              }
                          ],
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "select",
                          "variable": "stream_function_calling"
                      },
                      {
                          "default": "no_support",
                          "label": {
                              "en_US": "Vision Support",
                              "zh_Hans": "Vision 支持"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  },
                                  "value": "support"
                              },
                              {
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  },
                                  "value": "no_support"
                              }
                          ],
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "select",
                          "variable": "vision_support"
                      },
                      {
                          "variable": "structured_output_support",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "en_US": "Structured Output"
                          },
                          "type": "select",
                          "required": false,
                          "default": "not_supported",
                          "options": [
                              {
                                  "value": "supported",
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  }
                              },
                              {
                                  "value": "not_supported",
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "stream_mode_delimiter",
                          "label": {
                              "zh_Hans": "流模式返回结果的分隔符",
                              "en_US": "Delimiter for streaming results"
                          },
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "default": "\\n\\n",
                          "type": "text-input"
                      },
                      {
                          "variable": "voices",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "tts"
                              }
                          ],
                          "label": {
                              "en_US": "Available Voices (comma-separated)",
                              "zh_Hans": "可用声音（用英文逗号分隔）"
                          },
                          "type": "text-input",
                          "required": false,
                          "default": "Chinese Female",
                          "placeholder": {
                              "en_US": "Chinese Female,Chinese Male, Japanese Male, Cantonese Female, English Female, English Male, Korean Female",
                              "zh_Hans": "Chinese Female,Chinese Male, Japanese Male, Cantonese Female, English Female, English Male, Korean Female"
                          },
                          "help": {
                              "en_US": "List voice names separated by commas. First voice will be used as default.",
                              "zh_Hans": "用英文逗号分隔的声音列表。第一个声音将作为默认值。"
                          }
                      },
                      {
                          "variable": "timeout",
                          "label": {
                              "en_US": "Timeout(s)",
                              "zh_Hans": "超时时间(秒)"
                          },
                          "type": "text-input",
                          "required": false,
                          "default": "600",
                          "placeholder": {
                              "en_US": "600",
                              "zh_Hans": "600"
                          },
                          "help": {
                              "en_US": "The maximum time to wait for the model to complete the task(seconds).",
                              "zh_Hans": "等待模型完成任务的最大时间(秒)。"
                          },
                          "show_on": [
                              {
                                  "value": "rerank",
                                  "variable": "__model_type"
                              }
                          ]
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  }
              },
              "provider": "gpustack",
              "supported_model_types": [
                  "llm",
                  "text-embedding",
                  "rerank",
                  "speech2text",
                  "tts"
              ],
              "models": []
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "Vertex AI in Google Cloud Platform."
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "Vertex AI | Google Cloud Platform"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "vertex_ai",
          "plugins": {
              "models": [
                  "provider/vertex_ai.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.22",
          "model": {
              "background": "#FCFDFF",
              "configurate_methods": [
                  "predefined-model"
              ],
              "description": {
                  "en_US": "Vertex AI in Google Cloud Platform."
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/text_embedding/text_embedding.py"
                      ],
                      "provider_source": "provider/vertex_ai.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your Access Details from Google"
                  },
                  "url": {
                      "en_US": "https://cloud.google.com/vertex-ai/"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.png"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "Vertex AI | Google Cloud Platform"
              },
              "models": [
                  {
                      "model": "claude-3-haiku@20240307",
                      "label": {
                          "en_US": "Claude 3 Haiku"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "type": "int",
                              "default": 4096,
                              "min": 1,
                              "max": 4096,
                              "help": {
                                  "zh_Hans": "停止前生成的最大令牌数。请注意，Anthropic Claude 模型可能会在达到 max_tokens 的值之前停止生成令牌。不同的 Anthropic Claude 模型对此参数具有不同的最大值。",
                                  "en_US": "The maximum number of tokens to generate before stopping. Note that Anthropic Claude models might stop generating tokens before reaching the value of max_tokens. Different Anthropic Claude models have different maximum values for this parameter."
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "required": false,
                              "type": "float",
                              "default": 1,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "生成内容的随机性。",
                                  "en_US": "The amount of randomness injected into the response."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "required": false,
                              "type": "float",
                              "default": 0.999,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "在核采样中，Anthropic Claude 按概率递减顺序计算每个后续标记的所有选项的累积分布，并在达到 top_p 指定的特定概率时将其切断。您应该更改温度或top_p，但不能同时更改两者。",
                                  "en_US": "In nucleus sampling, Anthropic Claude computes the cumulative distribution over all the options for each subsequent token in decreasing probability order and cuts it off once it reaches a particular probability specified by top_p. You should alter either temperature or top_p, but not both."
                              }
                          },
                          {
                              "name": "top_k",
                              "use_template": "top_k",
                              "required": false,
                              "type": "int",
                              "default": 0,
                              "min": 0,
                              "max": 500,
                              "help": {
                                  "zh_Hans": "对于每个后续标记，仅从前 K 个选项中进行采样。使用 top_k 删除长尾低概率响应。",
                                  "en_US": "Only sample from the top K options for each subsequent token. Use top_k to remove long tail low probability responses."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.00025",
                          "output": "0.00125",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "claude-3-opus@20240229",
                      "label": {
                          "en_US": "Claude 3 Opus"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "type": "int",
                              "default": 4096,
                              "min": 1,
                              "max": 4096,
                              "help": {
                                  "zh_Hans": "停止前生成的最大令牌数。请注意，Anthropic Claude 模型可能会在达到 max_tokens 的值之前停止生成令牌。不同的 Anthropic Claude 模型对此参数具有不同的最大值。",
                                  "en_US": "The maximum number of tokens to generate before stopping. Note that Anthropic Claude models might stop generating tokens before reaching the value of max_tokens. Different Anthropic Claude models have different maximum values for this parameter."
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "required": false,
                              "type": "float",
                              "default": 1,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "生成内容的随机性。",
                                  "en_US": "The amount of randomness injected into the response."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "required": false,
                              "type": "float",
                              "default": 0.999,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "在核采样中，Anthropic Claude 按概率递减顺序计算每个后续标记的所有选项的累积分布，并在达到 top_p 指定的特定概率时将其切断。您应该更改温度或top_p，但不能同时更改两者。",
                                  "en_US": "In nucleus sampling, Anthropic Claude computes the cumulative distribution over all the options for each subsequent token in decreasing probability order and cuts it off once it reaches a particular probability specified by top_p. You should alter either temperature or top_p, but not both."
                              }
                          },
                          {
                              "name": "top_k",
                              "use_template": "top_k",
                              "required": false,
                              "type": "int",
                              "default": 0,
                              "min": 0,
                              "max": 500,
                              "help": {
                                  "zh_Hans": "对于每个后续标记，仅从前 K 个选项中进行采样。使用 top_k 删除长尾低概率响应。",
                                  "en_US": "Only sample from the top K options for each subsequent token. Use top_k to remove long tail low probability responses."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.015",
                          "output": "0.075",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "claude-3-sonnet@20240229",
                      "label": {
                          "en_US": "Claude 3 Sonnet"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "type": "int",
                              "default": 4096,
                              "min": 1,
                              "max": 4096,
                              "help": {
                                  "zh_Hans": "停止前生成的最大令牌数。请注意，Anthropic Claude 模型可能会在达到 max_tokens 的值之前停止生成令牌。不同的 Anthropic Claude 模型对此参数具有不同的最大值。",
                                  "en_US": "The maximum number of tokens to generate before stopping. Note that Anthropic Claude models might stop generating tokens before reaching the value of max_tokens. Different Anthropic Claude models have different maximum values for this parameter."
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "required": false,
                              "type": "float",
                              "default": 1,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "生成内容的随机性。",
                                  "en_US": "The amount of randomness injected into the response."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "required": false,
                              "type": "float",
                              "default": 0.999,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "在核采样中，Anthropic Claude 按概率递减顺序计算每个后续标记的所有选项的累积分布，并在达到 top_p 指定的特定概率时将其切断。您应该更改温度或top_p，但不能同时更改两者。",
                                  "en_US": "In nucleus sampling, Anthropic Claude computes the cumulative distribution over all the options for each subsequent token in decreasing probability order and cuts it off once it reaches a particular probability specified by top_p. You should alter either temperature or top_p, but not both."
                              }
                          },
                          {
                              "name": "top_k",
                              "use_template": "top_k",
                              "required": false,
                              "type": "int",
                              "default": 0,
                              "min": 0,
                              "max": 500,
                              "help": {
                                  "zh_Hans": "对于每个后续标记，仅从前 K 个选项中进行采样。使用 top_k 删除长尾低概率响应。",
                                  "en_US": "Only sample from the top K options for each subsequent token. Use top_k to remove long tail low probability responses."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.003",
                          "output": "0.015",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "claude-3-5-sonnet-v2@20241022",
                      "label": {
                          "en_US": "Claude 3.5 Sonnet v2"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "停止前生成的最大令牌数。请注意，Anthropic Claude 模型可能会在达到 max_tokens 的值之前停止生成令牌。不同的 Anthropic Claude 模型对此参数具有不同的最大值。",
                                  "en_US": "The maximum number of tokens to generate before stopping. Note that Anthropic Claude models might stop generating tokens before reaching the value of max_tokens. Different Anthropic Claude models have different maximum values for this parameter."
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "required": false,
                              "type": "float",
                              "default": 1,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "生成内容的随机性。",
                                  "en_US": "The amount of randomness injected into the response."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "required": false,
                              "type": "float",
                              "default": 0.999,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "在核采样中，Anthropic Claude 按概率递减顺序计算每个后续标记的所有选项的累积分布，并在达到 top_p 指定的特定概率时将其切断。您应该更改温度或top_p，但不能同时更改两者。",
                                  "en_US": "In nucleus sampling, Anthropic Claude computes the cumulative distribution over all the options for each subsequent token in decreasing probability order and cuts it off once it reaches a particular probability specified by top_p. You should alter either temperature or top_p, but not both."
                              }
                          },
                          {
                              "name": "top_k",
                              "use_template": "top_k",
                              "required": false,
                              "type": "int",
                              "default": 0,
                              "min": 0,
                              "max": 500,
                              "help": {
                                  "zh_Hans": "对于每个后续标记，仅从前 K 个选项中进行采样。使用 top_k 删除长尾低概率响应。",
                                  "en_US": "Only sample from the top K options for each subsequent token. Use top_k to remove long tail low probability responses."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.003",
                          "output": "0.015",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "claude-3-5-sonnet@20240620",
                      "label": {
                          "en_US": "Claude 3.5 Sonnet"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "type": "int",
                              "default": 4096,
                              "min": 1,
                              "max": 4096,
                              "help": {
                                  "zh_Hans": "停止前生成的最大令牌数。请注意，Anthropic Claude 模型可能会在达到 max_tokens 的值之前停止生成令牌。不同的 Anthropic Claude 模型对此参数具有不同的最大值。",
                                  "en_US": "The maximum number of tokens to generate before stopping. Note that Anthropic Claude models might stop generating tokens before reaching the value of max_tokens. Different Anthropic Claude models have different maximum values for this parameter."
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "required": false,
                              "type": "float",
                              "default": 1,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "生成内容的随机性。",
                                  "en_US": "The amount of randomness injected into the response."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "required": false,
                              "type": "float",
                              "default": 0.999,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "在核采样中，Anthropic Claude 按概率递减顺序计算每个后续标记的所有选项的累积分布，并在达到 top_p 指定的特定概率时将其切断。您应该更改温度或top_p，但不能同时更改两者。",
                                  "en_US": "In nucleus sampling, Anthropic Claude computes the cumulative distribution over all the options for each subsequent token in decreasing probability order and cuts it off once it reaches a particular probability specified by top_p. You should alter either temperature or top_p, but not both."
                              }
                          },
                          {
                              "name": "top_k",
                              "use_template": "top_k",
                              "required": false,
                              "type": "int",
                              "default": 0,
                              "min": 0,
                              "max": 500,
                              "help": {
                                  "zh_Hans": "对于每个后续标记，仅从前 K 个选项中进行采样。使用 top_k 删除长尾低概率响应。",
                                  "en_US": "Only sample from the top K options for each subsequent token. Use top_k to remove long tail low probability responses."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.003",
                          "output": "0.015",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "claude-3-7-sonnet@20250219",
                      "label": {
                          "en_US": "Claude 3.7 Sonnet"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "type": "int",
                              "default": 64000,
                              "min": 1,
                              "max": 128000,
                              "help": {
                                  "zh_Hans": "停止前生成的最大令牌数。请注意，Anthropic Claude 模型可能会在达到 max_tokens 的值之前停止生成令牌。不同的 Anthropic Claude 模型对此参数具有不同的最大值。",
                                  "en_US": "The maximum number of tokens to generate before stopping. Note that Anthropic Claude models might stop generating tokens before reaching the value of max_tokens. Different Anthropic Claude models have different maximum values for this parameter."
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "required": false,
                              "type": "float",
                              "default": 1,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "生成内容的随机性。",
                                  "en_US": "The amount of randomness injected into the response."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "required": false,
                              "type": "float",
                              "default": 0.999,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "在核采样中，Anthropic Claude 按概率递减顺序计算每个后续标记的所有选项的累积分布，并在达到 top_p 指定的特定概率时将其切断。您应该更改温度或top_p，但不能同时更改两者。",
                                  "en_US": "In nucleus sampling, Anthropic Claude computes the cumulative distribution over all the options for each subsequent token in decreasing probability order and cuts it off once it reaches a particular probability specified by top_p. You should alter either temperature or top_p, but not both."
                              }
                          },
                          {
                              "name": "top_k",
                              "use_template": "top_k",
                              "required": false,
                              "type": "int",
                              "default": 0,
                              "min": 0,
                              "max": 500,
                              "help": {
                                  "zh_Hans": "对于每个后续标记，仅从前 K 个选项中进行采样。使用 top_k 删除长尾低概率响应。",
                                  "en_US": "Only sample from the top K options for each subsequent token. Use top_k to remove long tail low probability responses."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.003",
                          "output": "0.015",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "claude-opus-4@20250514",
                      "label": {
                          "en_US": "Claude Opus 4"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "type": "int",
                              "default": 32000,
                              "min": 1,
                              "max": 32000,
                              "help": {
                                  "zh_Hans": "停止前生成的最大令牌数。请注意，Anthropic Claude 模型可能会在达到 max_tokens 的值之前停止生成令牌。不同的 Anthropic Claude 模型对此参数具有不同的最大值。",
                                  "en_US": "The maximum number of tokens to generate before stopping. Note that Anthropic Claude models might stop generating tokens before reaching the value of max_tokens. Different Anthropic Claude models have different maximum values for this parameter."
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "required": false,
                              "type": "float",
                              "default": 1,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "生成内容的随机性。",
                                  "en_US": "The amount of randomness injected into the response."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "required": false,
                              "type": "float",
                              "default": 0.999,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "在核采样中，Anthropic Claude 按概率递减顺序计算每个后续标记的所有选项的累积分布，并在达到 top_p 指定的特定概率时将其切断。您应该更改温度或top_p，但不能同时更改两者。",
                                  "en_US": "In nucleus sampling, Anthropic Claude computes the cumulative distribution over all the options for each subsequent token in decreasing probability order and cuts it off once it reaches a particular probability specified by top_p. You should alter either temperature or top_p, but not both."
                              }
                          },
                          {
                              "name": "top_k",
                              "use_template": "top_k",
                              "required": false,
                              "type": "int",
                              "default": 0,
                              "min": 0,
                              "max": 500,
                              "help": {
                                  "zh_Hans": "对于每个后续标记，仅从前 K 个选项中进行采样。使用 top_k 删除长尾低概率响应。",
                                  "en_US": "Only sample from the top K options for each subsequent token. Use top_k to remove long tail low probability responses."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.015",
                          "output": "0.075",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "claude-sonnet-4@20250514",
                      "label": {
                          "en_US": "Claude Sonnet 4"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "type": "int",
                              "default": 64000,
                              "min": 1,
                              "max": 64000,
                              "help": {
                                  "zh_Hans": "停止前生成的最大令牌数。请注意，Anthropic Claude 模型可能会在达到 max_tokens 的值之前停止生成令牌。不同的 Anthropic Claude 模型对此参数具有不同的最大值。",
                                  "en_US": "The maximum number of tokens to generate before stopping. Note that Anthropic Claude models might stop generating tokens before reaching the value of max_tokens. Different Anthropic Claude models have different maximum values for this parameter."
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "required": false,
                              "type": "float",
                              "default": 1,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "生成内容的随机性。",
                                  "en_US": "The amount of randomness injected into the response."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "required": false,
                              "type": "float",
                              "default": 0.999,
                              "min": 0.0,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "在核采样中，Anthropic Claude 按概率递减顺序计算每个后续标记的所有选项的累积分布，并在达到 top_p 指定的特定概率时将其切断。您应该更改温度或top_p，但不能同时更改两者。",
                                  "en_US": "In nucleus sampling, Anthropic Claude computes the cumulative distribution over all the options for each subsequent token in decreasing probability order and cuts it off once it reaches a particular probability specified by top_p. You should alter either temperature or top_p, but not both."
                              }
                          },
                          {
                              "name": "top_k",
                              "use_template": "top_k",
                              "required": false,
                              "type": "int",
                              "default": 0,
                              "min": 0,
                              "max": 500,
                              "help": {
                                  "zh_Hans": "对于每个后续标记，仅从前 K 个选项中进行采样。使用 top_k 删除长尾低概率响应。",
                                  "en_US": "Only sample from the top K options for each subsequent token. Use top_k to remove long tail low probability responses."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.003",
                          "output": "0.015",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-1.0-pro-vision-001",
                      "label": {
                          "en_US": "Gemini 1.0 Pro Vision"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16384
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 2048,
                              "min": 1,
                              "max": 2048
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-1.0-pro-002",
                      "label": {
                          "en_US": "Gemini 1.0 Pro"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32760
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-1.5-flash-001",
                      "label": {
                          "en_US": "Gemini 1.5 Flash 001"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-1.5-flash-002",
                      "label": {
                          "en_US": "Gemini 1.5 Flash 002"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "grounding",
                              "label": {
                                  "en_US": "Grounding"
                              },
                              "type": "float",
                              "help": {
                                  "en_US": "ensures responses are based on reliable sources."
                              },
                              "required": false,
                              "min": 0,
                              "max": 1
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-1.5-pro-001",
                      "label": {
                          "en_US": "Gemini 1.5 Pro 001"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-1.5-pro-002",
                      "label": {
                          "en_US": "Gemini 1.5 Pro 002"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "grounding",
                              "label": {
                                  "en_US": "Grounding"
                              },
                              "type": "float",
                              "help": {
                                  "en_US": "ensures responses are based on reliable sources."
                              },
                              "required": false,
                              "min": 0,
                              "max": 1
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.0-flash-001",
                      "label": {
                          "en_US": "Gemini 2.0 Flash 001"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          },
                          {
                              "name": "grounding",
                              "label": {
                                  "en_US": "Grounding"
                              },
                              "type": "float",
                              "help": {
                                  "en_US": "ensures responses are based on reliable sources."
                              },
                              "required": false,
                              "min": 0,
                              "max": 1
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.0-flash-exp",
                      "label": {
                          "en_US": "Gemini 2.0 Flash Exp"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.0-flash-lite-001",
                      "label": {
                          "en_US": "Gemini 2.0 Flash Lite 001"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          },
                          {
                              "name": "grounding",
                              "label": {
                                  "en_US": "Grounding"
                              },
                              "type": "float",
                              "help": {
                                  "en_US": "ensures responses are based on reliable sources."
                              },
                              "required": false,
                              "min": 0,
                              "max": 1
                          }
                      ],
                      "pricing": {
                          "input": "0.075",
                          "output": "0.30",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.0-flash-lite-preview-02-05",
                      "label": {
                          "en_US": "Gemini 2.0 Flash Lite Preview 0205"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.0-flash-thinking-exp-01-21",
                      "label": {
                          "en_US": "Gemini 2.0 Flash Thinking Exp 01-21"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32767
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.0-pro-exp-02-05",
                      "label": {
                          "en_US": "Gemini 2.0 pro exp 02-05"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.5-flash-lite-preview-06-17",
                      "label": {
                          "en_US": "Gemini 2.5 Flash Lite Preview 06-17"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 65535,
                              "min": 1,
                              "max": 65535
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          },
                          {
                              "name": "grounding",
                              "label": {
                                  "en_US": "Grounding"
                              },
                              "type": "float",
                              "help": {
                                  "en_US": "ensures responses are based on reliable sources."
                              },
                              "required": false,
                              "min": 0,
                              "max": 1
                          }
                      ],
                      "pricing": {
                          "input": "0.10",
                          "output": "0.40",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.5-flash-preview-04-17",
                      "label": {
                          "en_US": "gemini-2.5-flash-preview-04-17"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2097152
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 65535,
                              "min": 1,
                              "max": 65535
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          },
                          {
                              "name": "grounding",
                              "label": {
                                  "en_US": "Grounding"
                              },
                              "type": "float",
                              "help": {
                                  "en_US": "ensures responses are based on reliable sources."
                              },
                              "required": false,
                              "min": 0,
                              "max": 1
                          }
                      ],
                      "pricing": {
                          "input": "1.00",
                          "output": "3.50",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.5-flash-preview-05-20",
                      "label": {
                          "en_US": "Gemini 2.5 Flash Preview 0520"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2097152
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 65535,
                              "min": 1,
                              "max": 65535
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          },
                          {
                              "name": "grounding",
                              "label": {
                                  "en_US": "Grounding"
                              },
                              "type": "float",
                              "help": {
                                  "en_US": "ensures responses are based on reliable sources."
                              },
                              "required": false,
                              "min": 0,
                              "max": 1
                          }
                      ],
                      "pricing": {
                          "input": "0.15",
                          "output": "0.60",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.5-flash",
                      "label": {
                          "en_US": "Gemini 2.5 Flash"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 65535,
                              "min": 1,
                              "max": 65535
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          },
                          {
                              "name": "grounding",
                              "label": {
                                  "en_US": "Grounding"
                              },
                              "type": "float",
                              "help": {
                                  "en_US": "ensures responses are based on reliable sources."
                              },
                              "required": false,
                              "min": 0,
                              "max": 1
                          }
                      ],
                      "pricing": {
                          "input": "0.30",
                          "output": "2.50",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.5-pro-exp-03-25",
                      "label": {
                          "en_US": "Gemini 2.5 pro exp 03-25"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2097152
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 65535,
                              "min": 1,
                              "max": 65535
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.5-pro-preview-03-25",
                      "label": {
                          "en_US": "gemini-2.5-pro-preview-03-25"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2097152
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 65535,
                              "min": 1,
                              "max": 65535
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          },
                          {
                              "name": "grounding",
                              "label": {
                                  "en_US": "Grounding"
                              },
                              "type": "float",
                              "help": {
                                  "en_US": "ensures responses are based on reliable sources."
                              },
                              "required": false,
                              "min": 0,
                              "max": 1
                          }
                      ],
                      "pricing": {
                          "input": "1.25",
                          "output": "10.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.5-pro-preview-05-06",
                      "label": {
                          "en_US": "gemini-2.5-pro-preview-05-06"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2097152
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 65535,
                              "min": 1,
                              "max": 65535
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          },
                          {
                              "name": "grounding",
                              "label": {
                                  "en_US": "Grounding"
                              },
                              "type": "float",
                              "help": {
                                  "en_US": "ensures responses are based on reliable sources."
                              },
                              "required": false,
                              "min": 0,
                              "max": 1
                          }
                      ],
                      "pricing": {
                          "input": "1.25",
                          "output": "10.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.5-pro-preview-06-05",
                      "label": {
                          "en_US": "Gemini 2.5 Pro Preview 06-05"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 65535,
                              "min": 1,
                              "max": 65535
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          },
                          {
                              "name": "grounding",
                              "label": {
                                  "en_US": "Grounding"
                              },
                              "type": "float",
                              "help": {
                                  "en_US": "ensures responses are based on reliable sources."
                              },
                              "required": false,
                              "min": 0,
                              "max": 1
                          }
                      ],
                      "pricing": {
                          "input": "1.25",
                          "output": "10.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.5-pro",
                      "label": {
                          "en_US": "Gemini 2.5 Pro"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 65535,
                              "min": 1,
                              "max": 65535
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          },
                          {
                              "name": "grounding",
                              "label": {
                                  "en_US": "Grounding"
                              },
                              "type": "float",
                              "help": {
                                  "en_US": "ensures responses are based on reliable sources."
                              },
                              "required": false,
                              "min": 0,
                              "max": 1
                          }
                      ],
                      "pricing": {
                          "input": "1.25",
                          "output": "10.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-flash-experimental",
                      "label": {
                          "en_US": "Gemini Flash Experimental"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-pro-experimental",
                      "label": {
                          "en_US": "Gemini Pro Experimental"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "text-embedding-004",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 2048
                      },
                      "pricing": {
                          "input": "0.00013",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "text-embedding-005",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 2048
                      },
                      "pricing": {
                          "input": "0.00013",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "text-multilingual-embedding-002",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 2048
                      },
                      "pricing": {
                          "input": "0.00013",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  }
              ],
              "provider": "vertex_ai",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "Project ID"
                          },
                          "placeholder": {
                              "en_US": "Enter your Google Cloud Project ID"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "vertex_project_id"
                      },
                      {
                          "label": {
                              "en_US": "Location"
                          },
                          "placeholder": {
                              "en_US": "Enter your Google Cloud Location"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "vertex_location"
                      },
                      {
                          "label": {
                              "en_US": "Service Account Key (Leave blank if you use Application Default Credentials)"
                          },
                          "placeholder": {
                              "en_US": "Enter your Google Cloud Service Account Key in base64 format"
                          },
                          "required": false,
                          "type": "secret-input",
                          "variable": "vertex_service_account_key"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding"
              ]
          }
      },
      {
          "version": "0.0.4",
          "type": "plugin",
          "author": "ssrag",
          "name": "modelscope",
          "label": {
              "en_US": "modelscope",
              "zh_Hans": "魔搭社区"
          },
          "description": {
              "en_US": "Models provided by ModelScope",
              "zh_Hans": "ModelScope 提供的模型"
          },
          "icon": "icon.svg",
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "text_embedding": false,
                      "rerank": false,
                      "tts": false,
                      "speech2text": false,
                      "moderation": false
                  }
              }
          },
          "plugins": {
              "models": [
                  "provider/modelscope.yaml"
              ]
          },
          "meta": {
              "version": "0.0.1",
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "language": "python",
                  "version": "3.12",
                  "entrypoint": "main"
              }
          },
          "created_at": "2025-04-10T14:55:40.722241+08:00",
          "privacy": "PRIVACY.md",
          "verified": false,
          "model": {
              "background": "#FFFFFF",
              "configurate_methods": [
                  "predefined-model",
                  "customizable-model"
              ],
              "description": {
                  "en_US": "Models provided by ModelScope",
                  "zh_Hans": "ModelScope 提供的模型"
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py"
                      ],
                      "provider_source": "provider/modelscope.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API Key from ModelScope",
                      "zh_Hans": "从 ModelScope 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://modelscope.cn/docs/model-service/API-Inference/intro"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.png"
              },
              "icon_small": {
                  "en_US": "icon.svg"
              },
              "label": {
                  "en_US": "ModelScope",
                  "zh_Hans": "魔搭社区"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Model context size",
                              "zh_Hans": "模型上下文长度"
                          },
                          "placeholder": {
                              "en_US": "Enter your Model context size",
                              "zh_Hans": "在此输入您的模型上下文长度"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "context_size"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Upper bound for max tokens",
                              "zh_Hans": "最大 token 上限"
                          },
                          "type": "text-input",
                          "variable": "max_tokens"
                      },
                      {
                          "default": "no_call",
                          "label": {
                              "en_US": "Function calling"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Not supported",
                                      "zh_Hans": "不支持"
                                  },
                                  "value": "no_call"
                              },
                              {
                                  "label": {
                                      "en_US": "Tool Call",
                                      "zh_Hans": "Tool Call"
                                  },
                                  "value": "tool_call"
                              }
                          ],
                          "required": false,
                          "type": "select",
                          "variable": "function_calling_type"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  }
              },
              "models": [
                  {
                      "model": "LLM-Research/Llama-3.3-70B-Instruct",
                      "label": {
                          "en_US": "LLM-Research/Llama-3.3-70B-Instruct"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 100000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-14B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-14B-Instruct"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 16384,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-32B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-32B-Instruct"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 16384,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-72B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-72B-Instruct"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 16384,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-7B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-7B-Instruct"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 16384,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-Coder-14B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-Coder-14B-Instruct"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 16384,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-Coder-32B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-Coder-32B-Instruct"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 16384,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-Coder-7B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-Coder-7B-Instruct"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 16384,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/QwQ-32B-Preview",
                      "label": {
                          "en_US": "Qwen/QwQ-32B-Preview"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 16384,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen/QwQ-32B",
                      "label": {
                          "en_US": "Qwen/QwQ-32B"
                      },
                      "model_type": "llm",
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 16384,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      }
                  }
              ],
              "provider": "modelscope",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "label": {
                              "en_US": "API Base"
                          },
                          "placeholder": {
                              "en_US": "Base URL, e.g. https://api-inference.modelscope.cn/v1",
                              "zh_Hans": "Base URL, 如：https://api-inference.modelscope.cn/v1"
                          },
                          "required": false,
                          "type": "text-input",
                          "variable": "endpoint_url"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm"
              ]
          }
      },
      {
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "azure_ai_studio",
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "Azure AI Studio"
          },
          "icon": "icon_s_en.png",
          "label": {
              "en_US": "Azure AI Studio"
          },
          "plugins": {
              "models": [
                  "provider/azure_ai_studio.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": false
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.3",
          "model": {
              "background": "#93c5fd",
              "configurate_methods": [
                  "customizable-model"
              ],
              "description": {
                  "en_US": "Azure AI Studio",
                  "zh_Hans": "Azure AI Studio"
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/rerank/rerank.py"
                      ],
                      "provider_source": "provider/azure_ai_studio.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "How to deploy customized model on Azure AI Studio",
                      "zh_Hans": "如何在Azure AI Studio上的私有化部署的模型"
                  },
                  "url": {
                      "en_US": "https://learn.microsoft.com/en-us/azure/ai-studio/how-to/deploy-models",
                      "zh_Hans": "https://learn.microsoft.com/zh-cn/azure/ai-studio/how-to/deploy-models"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.png"
              },
              "icon_small": {
                  "en_US": "icon_s_en.png"
              },
              "label": {
                  "en_US": "Azure AI Studio",
                  "zh_Hans": "Azure AI Studio"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "Azure AI Studio Endpoint"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Endpoint, eg: https://example.com",
                              "zh_Hans": "请输入你的Azure AI Studio推理端点"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "endpoint"
                      },
                      {
                          "label": {
                              "en_US": "API Key",
                              "zh_Hans": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your Azure AI Studio API Key",
                              "zh_Hans": "在此输入您的 Azure AI Studio API Key"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "label": {
                              "en_US": "Select completion mode",
                              "zh_Hans": "选择对话类型"
                          },
                          "placeholder": {
                              "en_US": "Select completion model",
                              "zh_Hans": "选择对话类型"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "select",
                          "variable": "mode",
                          "options": [
                              {
                                  "value": "chat",
                                  "label": {
                                      "en_US": "Chat",
                                      "zh_Hans": "对话"
                                  }
                              },
                              {
                                  "value": "completion",
                                  "label": {
                                      "en_US": "Completion",
                                      "zh_Hans": "补全"
                                  }
                              }
                          ]
                      },
                      {
                          "label": {
                              "en_US": "Model context size",
                              "zh_Hans": "模型上下文长度"
                          },
                          "placeholder": {
                              "en_US": "Enter your Model context size",
                              "zh_Hans": "在此输入您的模型上下文长度"
                          },
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "required": true,
                          "type": "text-input",
                          "variable": "context_size"
                      },
                      {
                          "label": {
                              "en_US": "JWT Token",
                              "zh_Hans": "JWT令牌"
                          },
                          "placeholder": {
                              "en_US": "Enter your Azure AI Studio JWT Token",
                              "zh_Hans": "在此输入您的 Azure AI Studio 推理 API Key"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "value": "rerank",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "secret-input",
                          "variable": "jwt_token"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  }
              },
              "models": [],
              "provider": "azure_ai_studio",
              "supported_model_types": [
                  "llm",
                  "rerank"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "GroqCloud provides access to the Groq Cloud API, which hosts models like LLama2 and Mixtral.",
              "zh_Hans": "GroqCloud 提供对 Groq Cloud API 的访问，其中托管了 LLama2 和 Mixtral 等模型。"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "GroqCloud",
              "zh_Hans": "GroqCloud"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "groq",
          "plugins": {
              "models": [
                  "provider/groq.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.7",
          "model": {
              "background": "#F5F5F4",
              "configurate_methods": [
                  "predefined-model"
              ],
              "description": {
                  "en_US": "GroqCloud provides access to the Groq Cloud API, which hosts models like LLama2 and Mixtral.",
                  "zh_Hans": "GroqCloud 提供对 Groq Cloud API 的访问，其中托管了 LLama2 和 Mixtral 等模型。"
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/speech2text/speech2text.py"
                      ],
                      "provider_source": "provider/groq.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API Key from GroqCloud",
                      "zh_Hans": "从 GroqCloud 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://console.groq.com/keys"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "GroqCloud",
                  "zh_Hans": "GroqCloud"
              },
              "models": [
                  {
                      "model": "deepseek-r1-distill-llama-70b-specdec",
                      "label": {
                          "zh_Hans": "DeepSeek R1 Distill Llama 70B SpecDec",
                          "en_US": "DeepSeek R1 Distill Llama 70B SpecDec"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 1,
                              "max": 16000
                          }
                      ],
                      "pricing": {
                          "input": "0.0",
                          "output": "0.0",
                          "unit": "0.000001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "deepseek-r1-distill-llama-70b",
                      "label": {
                          "en_US": "DeepSeek R1 Distill Llama 70B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 16000
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.75",
                          "output": "0.99",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "deepseek-r1-distill-qwen-32b",
                      "label": {
                          "zh_Hans": "DeepSeek R1 Distill Qwen 32B 128k",
                          "en_US": "DeepSeek R1 Distill Qwen 32B 128k"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 16000
                          }
                      ],
                      "pricing": {
                          "input": "0.69",
                          "output": "0.69",
                          "unit": "0.000001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "gemma-7b-it",
                      "label": {
                          "zh_Hans": "Gemma 7B Instruction Tuned",
                          "en_US": "Gemma 7B Instruction Tuned"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.05",
                          "output": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "gemma2-9b-it",
                      "label": {
                          "zh_Hans": "Gemma 2 9B Instruction Tuned",
                          "en_US": "Gemma 2 9B Instruction Tuned"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.05",
                          "output": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "llama-3.1-405b-reasoning",
                      "label": {
                          "zh_Hans": "Llama-3.1-405b-reasoning",
                          "en_US": "Llama-3.1-405b-reasoning"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.05",
                          "output": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "llama-3.1-70b-versatile",
                      "label": {
                          "zh_Hans": "Llama-3.1-70b-versatile",
                          "en_US": "Llama-3.1-70b-versatile"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.05",
                          "output": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "llama-3.1-8b-instant",
                      "label": {
                          "zh_Hans": "Llama-3.1-8b-instant",
                          "en_US": "Llama-3.1-8b-instant"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.05",
                          "output": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "llama-3.2-11b-text-preview",
                      "label": {
                          "zh_Hans": "Llama 3.2 11B Text (Preview)",
                          "en_US": "Llama 3.2 11B Text (Preview)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.05",
                          "output": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "llama-3.2-11b-vision-preview",
                      "label": {
                          "zh_Hans": "Llama 3.2 11B Vision (Preview)",
                          "en_US": "Llama 3.2 11B Vision (Preview)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.05",
                          "output": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "llama-3.2-1b-preview",
                      "label": {
                          "zh_Hans": "Llama 3.2 1B Text (Preview)",
                          "en_US": "Llama 3.2 1B Text (Preview)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.05",
                          "output": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "llama-3.2-3b-preview",
                      "label": {
                          "zh_Hans": "Llama 3.2 3B Text (Preview)",
                          "en_US": "Llama 3.2 3B Text (Preview)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.05",
                          "output": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "llama-3.2-90b-text-preview",
                      "label": {
                          "zh_Hans": "Llama 3.2 90B Text (Preview)",
                          "en_US": "Llama 3.2 90B Text (Preview)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.05",
                          "output": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "llama-3.2-90b-vision-preview",
                      "label": {
                          "zh_Hans": "Llama 3.2 90B Vision (Preview)",
                          "en_US": "Llama 3.2 90B Vision (Preview)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.05",
                          "output": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "llama-3.3-70b-specdec",
                      "label": {
                          "zh_Hans": "Llama 3.3 70b Speculative Decoding  (PREVIEW)",
                          "en_US": "Llama 3.3 70b Speculative Decoding (PREVIEW)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.05",
                          "output": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "meta-llama/llama-4-maverick-17b-128e-instruct",
                      "label": {
                          "zh_Hans": "Llama 4 Maverick 17B 128E Instruct Preview",
                          "en_US": "Llama 4 Maverick 17B 128E Instruct Preview"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.05",
                          "output": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta-llama/llama-4-scout-17b-16e-instruct",
                      "label": {
                          "zh_Hans": "Llama 4 Scout 17B 16E Instruct Preview",
                          "en_US": "Llama 4 Scout 17B 16E Instruct Preview"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.05",
                          "output": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "llama-guard-3-8b",
                      "label": {
                          "zh_Hans": "Llama-Guard-3-8B",
                          "en_US": "Llama-Guard-3-8B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.20",
                          "output": "0.20",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "llama2-70b-4096",
                      "label": {
                          "zh_Hans": "Llama-2-70B-4096",
                          "en_US": "Llama-2-70B-4096"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.7",
                          "output": "0.8",
                          "unit": "0.000001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "llama3-70b-8192",
                      "label": {
                          "zh_Hans": "Llama-3-70B-8192",
                          "en_US": "Llama-3-70B-8192"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.59",
                          "output": "0.79",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "llama3-8b-8192",
                      "label": {
                          "zh_Hans": "Llama-3-8B-8192",
                          "en_US": "Llama-3-8B-8192"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.05",
                          "output": "0.08",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "llama3-groq-70b-8192-tool-use-preview",
                      "label": {
                          "zh_Hans": "Llama3-groq-70b-8192-tool-use (PREVIEW)",
                          "en_US": "Llama3-groq-70b-8192-tool-use (PREVIEW)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.05",
                          "output": "0.08",
                          "unit": "0.000001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "mixtral-8x7b-32768",
                      "label": {
                          "zh_Hans": "Mixtral-8x7b-Instruct-v0.1",
                          "en_US": "Mixtral-8x7b-Instruct-v0.1"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 20480
                          }
                      ],
                      "pricing": {
                          "input": "0.27",
                          "output": "0.27",
                          "unit": "0.000001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "qwen-2.5-32b",
                      "label": {
                          "zh_Hans": "Qwen 2.5 32B Instruct 128k",
                          "en_US": "Qwen 2.5 32B Instruct 128k"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.79",
                          "output": "0.79",
                          "unit": "0.000001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "qwen-2.5-coder-32b",
                      "label": {
                          "zh_Hans": "Qwen 2.5 Coder 32B Instruct 128k",
                          "en_US": "Qwen 2.5 Coder 32B Instruct 128k"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.79",
                          "output": "0.79",
                          "unit": "0.000001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "qwen-qwq-32b",
                      "label": {
                          "zh_Hans": "Qwen QwQ 32B (Preview) 128k",
                          "en_US": "Qwen QwQ 32B (Preview) 128k"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.29",
                          "output": "0.39",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "distil-whisper-large-v3-en",
                      "model_type": "speech2text",
                      "model_properties": {
                          "file_upload_limit": 1,
                          "supported_file_extensions": "flac,mp3,mp4,mpeg,mpga,m4a,ogg,wav,webm"
                      }
                  },
                  {
                      "model": "whisper-large-v3-turbo",
                      "model_type": "speech2text",
                      "model_properties": {
                          "file_upload_limit": 1,
                          "supported_file_extensions": "flac,mp3,mp4,mpeg,mpga,m4a,ogg,wav,webm"
                      }
                  },
                  {
                      "model": "whisper-large-v3",
                      "model_type": "speech2text",
                      "model_properties": {
                          "file_upload_limit": 1,
                          "supported_file_extensions": "flac,mp3,mp4,mpeg,mpga,m4a,ogg,wav,webm"
                      }
                  }
              ],
              "provider": "groq",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm",
                  "speech2text"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "OpenLLM"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "OpenLLM"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "openllm",
          "plugins": {
              "models": [
                  "provider/openllm.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.3",
          "model": {
              "background": "#F9FAFB",
              "configurate_methods": [
                  "customizable-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/text_embedding/text_embedding.py"
                      ],
                      "provider_source": "provider/openllm.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "How to deploy OpenLLM",
                      "zh_Hans": "如何部署 OpenLLM"
                  },
                  "url": {
                      "en_US": "https://github.com/bentoml/OpenLLM"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "OpenLLM"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "Server url",
                              "zh_Hans": "服务器URL"
                          },
                          "placeholder": {
                              "en_US": "Enter the url of your OpenLLM, e.g. http://192.168.1.100:3000",
                              "zh_Hans": "在此输入OpenLLM的服务器地址，如 http://192.168.1.100:3000"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "server_url"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  }
              },
              "models": [],
              "provider": "openllm",
              "supported_model_types": [
                  "llm",
                  "text-embedding"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "ChatGLM"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "ChatGLM"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "chatglm",
          "plugins": {
              "models": [
                  "provider/chatglm.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.2",
          "model": {
              "background": "#F4F7FF",
              "configurate_methods": [
                  "predefined-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py"
                      ],
                      "provider_source": "provider/chatglm.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Deploy ChatGLM to your local",
                      "zh_Hans": "部署您的本地 ChatGLM"
                  },
                  "url": {
                      "en_US": "https://github.com/THUDM/ChatGLM3"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "ChatGLM"
              },
              "models": [
                  {
                      "model": "chatglm2-6b-32k",
                      "label": {
                          "en_US": "ChatGLM2-6B-32K"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 2000,
                              "min": 1,
                              "max": 32000
                          }
                      ]
                  },
                  {
                      "model": "chatglm2-6b",
                      "label": {
                          "en_US": "ChatGLM2-6B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 256,
                              "min": 1,
                              "max": 2000
                          }
                      ]
                  },
                  {
                      "model": "chatglm3-6b-32k",
                      "label": {
                          "en_US": "ChatGLM3-6B-32K"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 8000,
                              "min": 1,
                              "max": 32000
                          }
                      ]
                  },
                  {
                      "model": "chatglm3-6b",
                      "label": {
                          "en_US": "ChatGLM3-6B"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 256,
                              "min": 1,
                              "max": 8000
                          }
                      ]
                  }
              ],
              "provider": "chatglm",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API URL"
                          },
                          "placeholder": {
                              "en_US": "Enter your API URL",
                              "zh_Hans": "在此输入您的 API URL"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "api_base"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-10-10T17:22:41.561951-04:00",
          "icon": "icon_s_en.svg",
          "description": {
              "en_US": "Tencent"
          },
          "label": {
              "en_US": "tencent"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.10"
              },
              "version": "0.0.1"
          },
          "name": "tencent",
          "plugins": {
              "models": [
                  "provider/tencent.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": false,
                      "moderation": false,
                      "rerank": false,
                      "speech2text": true,
                      "text_embedding": false,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.2",
          "model": {
              "background": "#E5E7EB",
              "configurate_methods": [
                  "predefined-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/speech2text/speech2text.py"
                      ],
                      "provider_source": "provider/tencent.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API key from Tencent AI",
                      "zh_Hans": "从腾讯云获取 API Key"
                  },
                  "url": {
                      "en_US": "https://cloud.tencent.com/product/asr"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg",
                  "zh_Hans": "icon_l_zh.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "Tencent",
                  "zh_Hans": "腾讯云"
              },
              "models": [
                  {
                      "model": "tencent",
                      "model_type": "speech2text",
                      "model_properties": {
                          "file_upload_limit": 25,
                          "supported_file_extensions": "flac,mp3,mp4,mpeg,mpga,m4a,ogg,wav,webm"
                      }
                  }
              ],
              "provider": "tencent",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "APPID",
                              "zh_Hans": "APPID"
                          },
                          "placeholder": {
                              "en_US": "Enter the APPID of your Tencent Cloud ASR service",
                              "zh_Hans": "在此输入您的腾讯语音识别服务的 APPID"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "app_id"
                      },
                      {
                          "label": {
                              "en_US": "SecretId",
                              "zh_Hans": "SecretId"
                          },
                          "placeholder": {
                              "en_US": "Enter the SecretId of your Tencent Cloud ASR service",
                              "zh_Hans": "在此输入您的腾讯语音识别服务的 SecretId"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "secret_id"
                      },
                      {
                          "label": {
                              "en_US": "SecretKey",
                              "zh_Hans": "SecretKey"
                          },
                          "placeholder": {
                              "en_US": "Enter the SecretKey of your Tencent Cloud ASR service",
                              "zh_Hans": "在此输入您的腾讯语音识别服务的 SecretKey"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "secret_key"
                      }
                  ]
              },
              "supported_model_types": [
                  "speech2text"
              ]
          }
      },
      {
          "version": "0.0.4",
          "type": "plugin",
          "author": "langgenius",
          "name": "fishaudio",
          "description": {
              "en_US": "Models provided by Fish Audio, currently support TTS and ASR.",
              "zh_Hans": "Fish Audio 提供的模型，目前支持 TTS 和 ASR。"
          },
          "icon": "fishaudio.jpeg",
          "label": {
              "en_US": "Fish Audio"
          },
          "created_at": "2024-09-29T15:24:33.625407551-04:00",
          "resource": {
              "memory": 268435456,
              "permission": {
                  "tool": {
                      "enabled": true
                  },
                  "model": {
                      "enabled": true,
                      "llm": false,
                      "text_embedding": false,
                      "rerank": false,
                      "tts": true,
                      "speech2text": true,
                      "moderation": false
                  }
              }
          },
          "plugins": {
              "models": [
                  "provider/fishaudio.yaml"
              ]
          },
          "meta": {
              "version": "0.0.1",
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "language": "python",
                  "version": "3.12",
                  "entrypoint": "main"
              }
          },
          "model": {
              "provider": "fishaudio",
              "label": {
                  "en_US": "Fish Audio"
              },
              "description": {
                  "en_US": "Models provided by Fish Audio, currently only support TTS and ASR.",
                  "zh_Hans": "Fish Audio 提供的模型，目前支持 TTS 和 ASR。"
              },
              "icon_small": {
                  "en_US": "fishaudio.jpeg"
              },
              "icon_large": {
                  "en_US": "fishaudio.jpeg"
              },
              "background": "#E5E7EB",
              "help": {
                  "title": {
                      "en_US": "Get your API key from Fish Audio",
                      "zh_Hans": "从 Fish Audio 获取你的 API Key"
                  },
                  "url": {
                      "en_US": "https://fish.audio/zh-CN/go-api/api-keys/"
                  }
              },
              "supported_model_types": [
                  "tts",
                  "speech2text"
              ],
              "configurate_methods": [
                  "predefined-model"
              ],
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "variable": "api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "type": "secret-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Key",
                              "en_US": "Enter your API Key"
                          }
                      },
                      {
                          "variable": "api_base",
                          "label": {
                              "en_US": "API URL"
                          },
                          "type": "text-input",
                          "required": false,
                          "default": "https://api.fish.audio",
                          "placeholder": {
                              "en_US": "Enter your API URL",
                              "zh_Hans": "在此输入您的 API URL"
                          }
                      },
                      {
                          "variable": "use_public_models",
                          "label": {
                              "en_US": "Use Public Models"
                          },
                          "type": "select",
                          "required": false,
                          "default": "false",
                          "placeholder": {
                              "en_US": "Toggle to use public models",
                              "zh_Hans": "切换以使用公共模型"
                          },
                          "options": [
                              {
                                  "value": "true",
                                  "label": {
                                      "en_US": "Allow Public Models",
                                      "zh_Hans": "使用公共模型"
                                  }
                              },
                              {
                                  "value": "false",
                                  "label": {
                                      "en_US": "Private Models Only",
                                      "zh_Hans": "仅使用私有模型"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "latency",
                          "label": {
                              "en_US": "Latency"
                          },
                          "type": "select",
                          "required": false,
                          "default": "normal",
                          "placeholder": {
                              "en_US": "Toggle to choice latency",
                              "zh_Hans": "切换以调整延迟"
                          },
                          "options": [
                              {
                                  "value": "balanced",
                                  "label": {
                                      "en_US": "Low (may affect quality)",
                                      "zh_Hans": "低延迟 (可能降低质量)"
                                  }
                              },
                              {
                                  "value": "normal",
                                  "label": {
                                      "en_US": "Normal",
                                      "zh_Hans": "标准"
                                  }
                              }
                          ]
                      }
                  ]
              },
              "models": [
                  {
                      "model": "s1",
                      "model_type": "tts",
                      "model_properties": {
                          "audio_type": "mp3",
                          "max_workers": 5,
                          "word_limit": 1000
                      },
                      "pricing": {
                          "input": "15",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "speech-1.5",
                      "model_type": "tts",
                      "model_properties": {
                          "audio_type": "mp3",
                          "max_workers": 5,
                          "word_limit": 1000
                      },
                      "pricing": {
                          "input": "15",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "speech-1.6",
                      "model_type": "tts",
                      "model_properties": {
                          "audio_type": "mp3",
                          "max_workers": 5,
                          "word_limit": 1000
                      },
                      "pricing": {
                          "input": "15",
                          "output": "0",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "fishaudio",
                      "model_type": "speech2text",
                      "model_properties": {
                          "file_upload_limit": 25,
                          "supported_file_extensions": "flac,mp3,mp4,mpeg,mpga,m4a,ogg,wav,webm"
                      }
                  }
              ],
              "extra": {
                  "python": {
                      "provider_source": "provider/fishaudio.py",
                      "model_sources": [
                          "models/tts/tts.py",
                          "models/speech2text/speech2text.py"
                      ]
                  }
              }
          }
      },
      {
          "version": "0.0.3",
          "type": "plugin",
          "author": "higgs-projects",
          "name": "lkeap",
          "label": {
              "en_US": "LKEAP",
              "zh_Hans": "腾讯知识引擎"
          },
          "description": {
              "en_US": "Models provide by Tencent LKEAP, such as deepseek-v3-0324, deepseek-r1-0528.",
              "zh_Hans": "腾讯知识引擎大模型相关原子能力，如deepseek-v3-0324, deepseek-r1-0528."
          },
          "icon": "icon_s_en.svg",
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "text_embedding": true,
                      "rerank": true,
                      "tts": false,
                      "speech2text": false,
                      "moderation": false
                  }
              }
          },
          "plugins": {
              "models": [
                  "provider/lkeap.yaml"
              ]
          },
          "meta": {
              "version": "0.0.3",
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "language": "python",
                  "version": "3.12",
                  "entrypoint": "main"
              }
          },
          "created_at": "2025-03-15T19:34:58.986286+08:00",
          "privacy": "PRIVACY.md",
          "verified": false,
          "model": {
              "provider": "lkeap",
              "author": "higgs-projects",
              "label": {
                  "en_US": "LKEAP",
                  "zh_Hans": "腾讯知识引擎"
              },
              "description": {
                  "en_US": "Models provided by Tencent LKEAP.",
                  "zh_Hans": "腾讯知识引擎原子能力 提供的模型。"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "background": "#E5E7EB",
              "help": {
                  "title": {
                      "en_US": "Get your API Key from LKEAP",
                      "zh_Hans": "从 腾讯知识引擎 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://console.cloud.tencent.com/cam/capi"
                  }
              },
              "supported_model_types": [
                  "llm",
                  "rerank",
                  "text-embedding"
              ],
              "configurate_methods": [
                  "predefined-model"
              ],
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "Secret ID"
                          },
                          "placeholder": {
                              "en_US": "Enter your Secret ID",
                              "zh_Hans": "在此输入您的 Secret ID"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "secret_id"
                      },
                      {
                          "label": {
                              "en_US": "Secret Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your Secret Key",
                              "zh_Hans": "在此输入您的 Secret Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "secret_key"
                      }
                  ]
              },
              "models": [
                  {
                      "model": "deepseek-prover-v2",
                      "label": {
                          "zh_Hans": "deepseek-prover-v2",
                          "en_US": "deepseek-prover-v2"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.6,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的多样性和随机性。数值越小，越严谨；数值越大，越发散。",
                                  "en_US": "Control the diversity and randomness of generated results. The smaller the value, the more rigorous it is; the larger the value, the more divergent it is."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 4096,
                              "min": 1,
                              "max": 16384,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "是否启用联网搜索。",
                                  "en_US": "Specifies whether to enable internet search capability."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "8",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "deepseek-r1-0528",
                      "label": {
                          "zh_Hans": "deepseek-r1-0528",
                          "en_US": "deepseek-r1-0528"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.6,
                              "min": 0.5,
                              "max": 0.7,
                              "help": {
                                  "zh_Hans": "控制生成结果的多样性和随机性。数值越小，越严谨；数值越大，越发散。",
                                  "en_US": "Control the diversity and randomness of generated results. The smaller the value, the more rigorous it is; the larger the value, the more divergent it is."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 4096,
                              "min": 1,
                              "max": 16384,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "是否启用联网搜索。",
                                  "en_US": "Specifies whether to enable internet search capability."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "4",
                          "output": "16",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "deepseek-r1",
                      "label": {
                          "zh_Hans": "deepseek-r1",
                          "en_US": "deepseek-r1"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 96000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.6,
                              "min": 0.5,
                              "max": 0.7,
                              "help": {
                                  "zh_Hans": "控制生成结果的多样性和随机性。数值越小，越严谨；数值越大，越发散。",
                                  "en_US": "Control the diversity and randomness of generated results. The smaller the value, the more rigorous it is; the larger the value, the more divergent it is."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 4096,
                              "min": 1,
                              "max": 16384,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "是否启用联网搜索。",
                                  "en_US": "Specifies whether to enable internet search capability."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "4",
                          "output": "16",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "deepseek-v3-0324",
                      "label": {
                          "zh_Hans": "deepseek-v3-0324",
                          "en_US": "deepseek-v3-0324"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.6,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的多样性和随机性。数值越小，越严谨；数值越大，越发散。",
                                  "en_US": "Control the diversity and randomness of generated results. The smaller the value, the more rigorous it is; the larger the value, the more divergent it is."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 4096,
                              "min": 1,
                              "max": 16384,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "是否启用联网搜索。",
                                  "en_US": "Specifies whether to enable internet search capability."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "8",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "deepseek-v3",
                      "label": {
                          "zh_Hans": "deepseek-v3",
                          "en_US": "deepseek-v3"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.6,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的多样性和随机性。数值越小，越严谨；数值越大，越发散。",
                                  "en_US": "Control the diversity and randomness of generated results. The smaller the value, the more rigorous it is; the larger the value, the more divergent it is."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 4096,
                              "min": 1,
                              "max": 16384,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "enable_search",
                              "type": "boolean",
                              "default": false,
                              "label": {
                                  "zh_Hans": "联网搜索",
                                  "en_US": "Web Search"
                              },
                              "help": {
                                  "zh_Hans": "是否启用联网搜索。",
                                  "en_US": "Specifies whether to enable internet search capability."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "8",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "lke-reranker-base",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 4000
                      }
                  },
                  {
                      "model": "lke-text-embedding-v1",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 500,
                          "max_chunks": 7
                      }
                  }
              ],
              "extra": {
                  "python": {
                      "provider_source": "provider/lkeap.py",
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/rerank/rerank.py",
                          "models/text_embedding/text_embedding.py"
                      ]
                  }
              }
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "Models provided by stepfun, such as step-1-8k, step-1-32k、step-1v-8k、step-1v-32k, step-1-128k and step-1-256k",
              "zh_Hans": "阶跃星辰提供的模型，例如 step-1-8k、step-1-32k、step-1v-8k、step-1v-32k、step-1-128k 和 step-1-256k。"
          },
          "icon": "icon_s_en.png",
          "label": {
              "en_US": "Stepfun",
              "zh_Hans": "阶跃星辰"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "stepfun",
          "plugins": {
              "models": [
                  "provider/stepfun.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.2",
          "model": {
              "background": "#FFFFFF",
              "configurate_methods": [
                  "predefined-model",
                  "customizable-model"
              ],
              "description": {
                  "en_US": "Models provided by stepfun, such as step-1-8k, step-1-32k、step-1v-8k、step-1v-32k, step-1-128k and step-1-256k",
                  "zh_Hans": "阶跃星辰提供的模型，例如 step-1-8k、step-1-32k、step-1v-8k、step-1v-32k、step-1-128k 和 step-1-256k。"
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py"
                      ],
                      "provider_source": "provider/stepfun.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API Key from stepfun",
                      "zh_Hans": "从 stepfun 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://platform.stepfun.com/interface-key"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.png"
              },
              "icon_small": {
                  "en_US": "icon_s_en.png"
              },
              "label": {
                  "en_US": "Stepfun",
                  "zh_Hans": "阶跃星辰"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "default": "8192",
                          "label": {
                              "en_US": "Model context size",
                              "zh_Hans": "模型上下文长度"
                          },
                          "placeholder": {
                              "en_US": "Enter your Model context size",
                              "zh_Hans": "在此输入您的模型上下文长度"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "context_size"
                      },
                      {
                          "default": "8192",
                          "label": {
                              "en_US": "Upper bound for max tokens",
                              "zh_Hans": "最大 token 上限"
                          },
                          "type": "text-input",
                          "variable": "max_tokens"
                      },
                      {
                          "default": "no_call",
                          "label": {
                              "en_US": "Function calling"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Not supported",
                                      "zh_Hans": "不支持"
                                  },
                                  "value": "no_call"
                              },
                              {
                                  "label": {
                                      "en_US": "Tool Call",
                                      "zh_Hans": "Tool Call"
                                  },
                                  "value": "tool_call"
                              }
                          ],
                          "required": false,
                          "type": "select",
                          "variable": "function_calling_type"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  }
              },
              "models": [
                  {
                      "model": "step-1-128k",
                      "label": {
                          "zh_Hans": "step-1-128k",
                          "en_US": "step-1-128k"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 128000
                          }
                      ],
                      "pricing": {
                          "input": "0.04",
                          "output": "0.20",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "step-1-256k",
                      "label": {
                          "zh_Hans": "step-1-256k",
                          "en_US": "step-1-256k"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 256000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 256000
                          }
                      ],
                      "pricing": {
                          "input": "0.095",
                          "output": "0.300",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "step-1-32k",
                      "label": {
                          "zh_Hans": "step-1-32k",
                          "en_US": "step-1-32k"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 32000
                          }
                      ],
                      "pricing": {
                          "input": "0.015",
                          "output": "0.070",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "step-1-8k",
                      "label": {
                          "zh_Hans": "step-1-8k",
                          "en_US": "step-1-8k"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8000
                          }
                      ],
                      "pricing": {
                          "input": "0.005",
                          "output": "0.020",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "step-1-flash",
                      "label": {
                          "zh_Hans": "step-1-flash",
                          "en_US": "step-1-flash"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8000
                          }
                      ],
                      "pricing": {
                          "input": "0.001",
                          "output": "0.004",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "step-1v-32k",
                      "label": {
                          "zh_Hans": "step-1v-32k",
                          "en_US": "step-1v-32k"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 32000
                          }
                      ],
                      "pricing": {
                          "input": "0.015",
                          "output": "0.070",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "step-1v-8k",
                      "label": {
                          "zh_Hans": "step-1v-8k",
                          "en_US": "step-1v-8k"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.005",
                          "output": "0.020",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "step-2-16k",
                      "label": {
                          "zh_Hans": "step-2-16k",
                          "en_US": "step-2-16k"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 16000
                          }
                      ],
                      "pricing": {
                          "input": "0.038",
                          "output": "0.120",
                          "unit": "0.001",
                          "currency": "RMB"
                      }
                  }
              ],
              "provider": "stepfun",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "快速体验大模型，领先探索 AI 开源世界",
              "zh_Hans": "快速体验大模型，领先探索 AI 开源世界"
          },
          "icon": "Gitee-AI-Logo.svg",
          "label": {
              "en_US": "Gitee AI",
              "zh_Hans": "模力方舟"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "gitee_ai",
          "plugins": {
              "models": [
                  "provider/gitee_ai.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.1.3",
          "model": {
              "configurate_methods": [
                  "customizable-model",
                  "predefined-model"
              ],
              "description": {
                  "en_US": "快速体验大模型，领先探索 AI 开源世界",
                  "zh_Hans": "快速体验大模型，领先探索 AI 开源世界"
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/rerank/rerank.py",
                          "models/text_embedding/text_embedding.py",
                          "models/tts/tts.py",
                          "models/speech2text/speech2text.py"
                      ],
                      "provider_source": "provider/gitee_ai.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your token from Gitee AI",
                      "zh_Hans": "从 Gitee AI 获取 token"
                  },
                  "url": {
                      "en_US": "https://ai.gitee.com/dashboard/settings/tokens"
                  }
              },
              "icon_large": {
                  "en_US": "Gitee-AI-Logo-full.svg"
              },
              "icon_small": {
                  "en_US": "Gitee-AI-Logo.svg"
              },
              "label": {
                  "en_US": "Gitee AI",
                  "zh_Hans": "模力方舟"
              },
              "models": [
                  {
                      "model": "Align-DS-V",
                      "label": {
                          "zh_Hans": "Align-DS-V",
                          "en_US": "Align-DS-V"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "codegeex4-all-9b",
                      "label": {
                          "zh_Hans": "codegeex4-all-9b",
                          "en_US": "codegeex4-all-9b"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "stream",
                              "label": {
                                  "en_US": "Stream",
                                  "zh_Hans": "流式"
                              },
                              "type": "boolean",
                              "default": true,
                              "required": true,
                              "help": {
                                  "en_US": "Whether to return the results in batches through streaming. If set to true, the generated text will be pushed to the user in real time during the generation process.",
                                  "zh_Hans": "是否通过流式分批返回结果。如果设置为 true，生成过程中实时地向用户推送每一部分生成的文本。"
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "deepseek-coder-33B-instruct",
                      "label": {
                          "zh_Hans": "deepseek-coder-33B-instruct",
                          "en_US": "deepseek-coder-33B-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "stream",
                              "label": {
                                  "en_US": "Stream",
                                  "zh_Hans": "流式"
                              },
                              "type": "boolean",
                              "default": true,
                              "required": true,
                              "help": {
                                  "en_US": "Whether to return the results in batches through streaming. If set to true, the generated text will be pushed to the user in real time during the generation process.",
                                  "zh_Hans": "是否通过流式分批返回结果。如果设置为 true，生成过程中实时地向用户推送每一部分生成的文本。"
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "DeepSeek-R1-Distill-Qwen-1.5B",
                      "label": {
                          "zh_Hans": "DeepSeek-R1-Distill-Qwen-1.5B",
                          "en_US": "DeepSeek-R1-Distill-Qwen-1.5B"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "stream",
                              "label": {
                                  "en_US": "Stream",
                                  "zh_Hans": "流式"
                              },
                              "type": "boolean",
                              "default": true,
                              "required": true,
                              "help": {
                                  "en_US": "Whether to return the results in batches through streaming. If set to true, the generated text will be pushed to the user in real time during the generation process.",
                                  "zh_Hans": "是否通过流式分批返回结果。如果设置为 true，生成过程中实时地向用户推送每一部分生成的文本。"
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "DeepSeek-R1-Distill-Qwen-14B",
                      "label": {
                          "zh_Hans": "DeepSeek-R1-Distill-Qwen-14B",
                          "en_US": "DeepSeek-R1-Distill-Qwen-14B"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "stream",
                              "label": {
                                  "en_US": "Stream",
                                  "zh_Hans": "流式"
                              },
                              "type": "boolean",
                              "default": true,
                              "required": true,
                              "help": {
                                  "en_US": "Whether to return the results in batches through streaming. If set to true, the generated text will be pushed to the user in real time during the generation process.",
                                  "zh_Hans": "是否通过流式分批返回结果。如果设置为 true，生成过程中实时地向用户推送每一部分生成的文本。"
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "DeepSeek-R1-Distill-Qwen-32B",
                      "label": {
                          "zh_Hans": "DeepSeek-R1-Distill-Qwen-32B",
                          "en_US": "DeepSeek-R1-Distill-Qwen-32B"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "stream",
                              "label": {
                                  "en_US": "Stream",
                                  "zh_Hans": "流式"
                              },
                              "type": "boolean",
                              "default": true,
                              "required": true,
                              "help": {
                                  "en_US": "Whether to return the results in batches through streaming. If set to true, the generated text will be pushed to the user in real time during the generation process.",
                                  "zh_Hans": "是否通过流式分批返回结果。如果设置为 true，生成过程中实时地向用户推送每一部分生成的文本。"
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "DeepSeek-R1-Distill-Qwen-7B",
                      "label": {
                          "zh_Hans": "DeepSeek-R1-Distill-Qwen-7B",
                          "en_US": "DeepSeek-R1-Distill-Qwen-7B"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "stream",
                              "label": {
                                  "en_US": "Stream",
                                  "zh_Hans": "流式"
                              },
                              "type": "boolean",
                              "default": true,
                              "required": true,
                              "help": {
                                  "en_US": "Whether to return the results in batches through streaming. If set to true, the generated text will be pushed to the user in real time during the generation process.",
                                  "zh_Hans": "是否通过流式分批返回结果。如果设置为 true，生成过程中实时地向用户推送每一部分生成的文本。"
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "DeepSeek-R1",
                      "label": {
                          "zh_Hans": "DeepSeek-R1",
                          "en_US": "DeepSeek-R1"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "stream",
                              "label": {
                                  "en_US": "Stream",
                                  "zh_Hans": "流式"
                              },
                              "type": "boolean",
                              "default": true,
                              "required": true,
                              "help": {
                                  "en_US": "Whether to return the results in batches through streaming. If set to true, the generated text will be pushed to the user in real time during the generation process.",
                                  "zh_Hans": "是否通过流式分批返回结果。如果设置为 true，生成过程中实时地向用户推送每一部分生成的文本。"
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "DeepSeek-V3",
                      "label": {
                          "zh_Hans": "DeepSeek-V3",
                          "en_US": "DeepSeek-V3"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "stream",
                              "label": {
                                  "en_US": "Stream",
                                  "zh_Hans": "流式"
                              },
                              "type": "boolean",
                              "default": true,
                              "required": true,
                              "help": {
                                  "en_US": "Whether to return the results in batches through streaming. If set to true, the generated text will be pushed to the user in real time during the generation process.",
                                  "zh_Hans": "是否通过流式分批返回结果。如果设置为 true，生成过程中实时地向用户推送每一部分生成的文本。"
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "gemma-3-27b-it",
                      "label": {
                          "zh_Hans": "gemma-3-27b-it",
                          "en_US": "gemma-3-27b-it"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "stream",
                              "label": {
                                  "en_US": "Stream",
                                  "zh_Hans": "流式"
                              },
                              "type": "boolean",
                              "default": true,
                              "required": true,
                              "help": {
                                  "en_US": "Whether to return the results in batches through streaming. If set to true, the generated text will be pushed to the user in real time during the generation process.",
                                  "zh_Hans": "是否通过流式分批返回结果。如果设置为 true，生成过程中实时地向用户推送每一部分生成的文本。"
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "glm-4-9b-chat",
                      "label": {
                          "zh_Hans": "glm-4-9b-chat",
                          "en_US": "glm-4-9b-chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "stream",
                              "label": {
                                  "en_US": "Stream",
                                  "zh_Hans": "流式"
                              },
                              "type": "boolean",
                              "default": true,
                              "required": true,
                              "help": {
                                  "en_US": "Whether to return the results in batches through streaming. If set to true, the generated text will be pushed to the user in real time during the generation process.",
                                  "zh_Hans": "是否通过流式分批返回结果。如果设置为 true，生成过程中实时地向用户推送每一部分生成的文本。"
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "InternVL2-8B",
                      "label": {
                          "zh_Hans": "InternVL2-8B",
                          "en_US": "InternVL2-8B"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "InternVL2.5-26B",
                      "label": {
                          "zh_Hans": "InternVL2.5-26B",
                          "en_US": "InternVL2.5-26B"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "InternVL2.5-78B",
                      "label": {
                          "zh_Hans": "InternVL2.5-78B",
                          "en_US": "InternVL2.5-78B"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "Qwen2-72B-Instruct",
                      "label": {
                          "zh_Hans": "Qwen2-72B-Instruct",
                          "en_US": "Qwen2-72B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "stream",
                              "label": {
                                  "en_US": "Stream",
                                  "zh_Hans": "流式"
                              },
                              "type": "boolean",
                              "default": true,
                              "required": true,
                              "help": {
                                  "en_US": "Whether to return the results in batches through streaming. If set to true, the generated text will be pushed to the user in real time during the generation process.",
                                  "zh_Hans": "是否通过流式分批返回结果。如果设置为 true，生成过程中实时地向用户推送每一部分生成的文本。"
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "Qwen2-7B-Instruct",
                      "label": {
                          "zh_Hans": "Qwen2-7B-Instruct",
                          "en_US": "Qwen2-7B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 24576
                      },
                      "parameter_rules": [
                          {
                              "name": "stream",
                              "label": {
                                  "en_US": "Stream",
                                  "zh_Hans": "流式"
                              },
                              "type": "boolean",
                              "default": true,
                              "required": true,
                              "help": {
                                  "en_US": "Whether to return the results in batches through streaming. If set to true, the generated text will be pushed to the user in real time during the generation process.",
                                  "zh_Hans": "是否通过流式分批返回结果。如果设置为 true，生成过程中实时地向用户推送每一部分生成的文本。"
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 24576,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "Qwen2-VL-72B",
                      "label": {
                          "zh_Hans": "Qwen2-VL-72B",
                          "en_US": "Qwen2-VL-72B"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "Qwen2.5-14B-Instruct",
                      "label": {
                          "zh_Hans": "Qwen2.5-14B-Instruct",
                          "en_US": "Qwen2.5-14B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 24576
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 24576,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "Qwen2.5-32B-Instruct",
                      "label": {
                          "zh_Hans": "Qwen2.5-32B-Instruct",
                          "en_US": "Qwen2.5-32B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "Qwen2.5-72B-Instruct",
                      "label": {
                          "zh_Hans": "Qwen2.5-72B-Instruct",
                          "en_US": "Qwen2.5-72B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16384
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 16384,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "Qwen2.5-VL-32B-Instruct",
                      "label": {
                          "zh_Hans": "Qwen2.5-VL-32B-Instruct",
                          "en_US": "Qwen2.5-VL-32B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 24576
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "Qwen3-0.6B",
                      "label": {
                          "zh_Hans": "Qwen3-0.6B",
                          "en_US": "Qwen3-0.6B"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "Qwen3-235B-A22B",
                      "label": {
                          "zh_Hans": "Qwen3-235B-A22B",
                          "en_US": "Qwen3-235B-A22B"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "Qwen3-30B-A3B",
                      "label": {
                          "zh_Hans": "Qwen3-30B-A3B",
                          "en_US": "Qwen3-30B-A3B"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "Qwen3-32B",
                      "label": {
                          "zh_Hans": "Qwen3-32B",
                          "en_US": "Qwen3-32B"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "Qwen3-4B",
                      "label": {
                          "zh_Hans": "Qwen3-4B",
                          "en_US": "Qwen3-4B"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "Qwen3-8B",
                      "label": {
                          "zh_Hans": "Qwen3-8B",
                          "en_US": "Qwen3-8B"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "QwQ-32B",
                      "label": {
                          "zh_Hans": "QwQ-32B",
                          "en_US": "QwQ-32B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 32768,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "Yi-34B-Chat",
                      "label": {
                          "zh_Hans": "Yi-34B-Chat",
                          "en_US": "Yi-34B-Chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "stream",
                              "label": {
                                  "en_US": "Stream",
                                  "zh_Hans": "流式"
                              },
                              "type": "boolean",
                              "default": true,
                              "required": true,
                              "help": {
                                  "en_US": "Whether to return the results in batches through streaming. If set to true, the generated text will be pushed to the user in real time during the generation process.",
                                  "zh_Hans": "是否通过流式分批返回结果。如果设置为 true，生成过程中实时地向用户推送每一部分生成的文本。"
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "label": {
                                  "en_US": "Max Tokens",
                                  "zh_Hans": "最大Token数"
                              },
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 4096,
                              "required": true,
                              "help": {
                                  "en_US": "The maximum number of tokens that can be generated by the model varies depending on the model.",
                                  "zh_Hans": "模型可生成的最大 token 个数，不同模型上限不同。"
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "label": {
                                  "en_US": "Temperature",
                                  "zh_Hans": "采样温度"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "required": true,
                              "help": {
                                  "en_US": "The randomness of the sampling temperature control output. The temperature value is within the range of [0.0, 1.0]. The higher the value, the more random and creative the output; the lower the value, the more stable it is. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样温度控制输出的随机性。温度值在 [0.0, 1.0] 范围内，值越高，输出越随机和创造性；值越低，输出越稳定。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "label": {
                                  "en_US": "Top P",
                                  "zh_Hans": "Top P"
                              },
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": true,
                              "help": {
                                  "en_US": "The value range of the sampling method is [0.0, 1.0]. The top_p value determines that the model selects tokens from the top p% of candidate words with the highest probability; when top_p is 0, this parameter is invalid. It is recommended to adjust either top_p or temperature parameters according to your needs to avoid adjusting both at the same time.",
                                  "zh_Hans": "采样方法的取值范围为 [0.0,1.0]。top_p 值确定模型从概率最高的前p%的候选词中选取 tokens；当 top_p 为 0 时，此参数无效。建议根据需求调整 top_p 或 temperature 参数，避免同时调整两者。"
                              }
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "en_US": "Top K",
                                  "zh_Hans": "Top K"
                              },
                              "type": "int",
                              "default": 50,
                              "min": 0,
                              "max": 100,
                              "required": true,
                              "help": {
                                  "en_US": "The value range is [0,100], which limits the model to only select from the top k words with the highest probability when choosing the next word at each step. The larger the value, the more diverse text generation will be.",
                                  "zh_Hans": "取值范围为 [0,100]，限制模型在每一步选择下一个词时，只从概率最高的前 k 个词中选取。数值越大，文本生成越多样。"
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "type": "float",
                              "default": 0,
                              "min": -1.0,
                              "max": 1.0,
                              "precision": 1,
                              "required": false,
                              "help": {
                                  "en_US": "Used to adjust the frequency of repeated content in automatically generated text. Positive numbers reduce repetition, while negative numbers increase repetition. After setting this parameter, if a word has already appeared in the text, the model will decrease the probability of choosing that word for subsequent generation.",
                                  "zh_Hans": "用于调整自动生成文本中重复内容的频率。正数减少重复，负数增加重复。设置此参数后，如果一个词在文本中已经出现过，模型在后续生成中选择该词的概率会降低。"
                              }
                          },
                          {
                              "name": "user",
                              "label": {
                                  "en_US": "User",
                                  "zh_Hans": "用户"
                              },
                              "type": "string",
                              "required": false,
                              "help": {
                                  "en_US": "Used to track and differentiate conversation requests from different users.",
                                  "zh_Hans": "用于追踪和区分不同用户的对话请求。"
                              }
                          }
                      ]
                  },
                  {
                      "model": "bce-reranker-base_v1",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 512
                      }
                  },
                  {
                      "model": "bge-reranker-v2-m3",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 8192
                      }
                  },
                  {
                      "model": "jina-reranker-m0",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 10240
                      }
                  },
                  {
                      "model": "Qwen3-Reranker-0.6B",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 32000
                      }
                  },
                  {
                      "model": "Qwen3-Reranker-4B",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 32000
                      }
                  },
                  {
                      "model": "Qwen3-Reranker-8B",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 512
                      }
                  },
                  {
                      "model": "SenseVoiceSmall",
                      "model_type": "speech2text",
                      "model_properties": {
                          "file_upload_limit": 1,
                          "supported_file_extensions": "flac,mp3,mp4,mpeg,mpga,m4a,ogg,wav,webm"
                      }
                  },
                  {
                      "model": "whisper-base",
                      "model_type": "speech2text",
                      "model_properties": {
                          "file_upload_limit": 1,
                          "supported_file_extensions": "flac,mp3,mp4,mpeg,mpga,m4a,ogg,wav,webm"
                      }
                  },
                  {
                      "model": "whisper-large-v3-turbo",
                      "model_type": "speech2text",
                      "model_properties": {
                          "file_upload_limit": 1,
                          "supported_file_extensions": "flac,mp3,mp4,mpeg,mpga,m4a,ogg,wav,webm"
                      }
                  },
                  {
                      "model": "whisper-large",
                      "model_type": "speech2text",
                      "model_properties": {
                          "file_upload_limit": 1,
                          "supported_file_extensions": "flac,mp3,mp4,mpeg,mpga,m4a,ogg,wav,webm"
                      }
                  },
                  {
                      "model": "bce-embedding-base_v1",
                      "label": {
                          "zh_Hans": "bce-embedding-base_v1",
                          "en_US": "bce-embedding-base_v1"
                      },
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 512,
                          "max_chunks": 20
                      }
                  },
                  {
                      "model": "bge-large-zh-v1.5",
                      "label": {
                          "zh_Hans": "bge-large-zh-v1.5",
                          "en_US": "bge-large-zh-v1.5"
                      },
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 512,
                          "max_chunks": 20
                      }
                  },
                  {
                      "model": "bge-m3",
                      "label": {
                          "zh_Hans": "bge-m3",
                          "en_US": "bge-m3"
                      },
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 20
                      }
                  },
                  {
                      "model": "bge-small-zh-v1.5",
                      "label": {
                          "zh_Hans": "bge-small-zh-v1.5",
                          "en_US": "bge-small-zh-v1.5"
                      },
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 512,
                          "max_chunks": 20
                      }
                  },
                  {
                      "model": "Qwen3-Embedding-0.6B",
                      "label": {
                          "zh_Hans": "Qwen3-Embedding-0.6B",
                          "en_US": "Qwen3-Embedding-0.6B"
                      },
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 32000,
                          "max_chunks": 20
                      },
                      "name": "Qwen3-Embedding-0.6B",
                      "provider": "gitee_ai",
                      "visible": true,
                      "description": "Qwen3-Embedding-0.6B 是一个高效的中文文本嵌入模型，适用于多种文本向量化场景。"
                  },
                  {
                      "model": "Qwen3-Embedding-4B",
                      "label": {
                          "zh_Hans": "Qwen3-Embedding-4B",
                          "en_US": "Qwen3-Embedding-4B"
                      },
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 32000,
                          "max_chunks": 20
                      },
                      "name": "Qwen3-Embedding-4B",
                      "provider": "gitee_ai",
                      "visible": true,
                      "description": "Qwen3-Embedding-4B 是一个高效的中文文本嵌入模型，适用于多种文本向量化场景。"
                  },
                  {
                      "model": "Qwen3-Embedding-8B",
                      "label": {
                          "zh_Hans": "Qwen3-Embedding-8B",
                          "en_US": "Qwen3-Embedding-8B"
                      },
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 32000,
                          "max_chunks": 20
                      },
                      "name": "Qwen3-Embedding-8B",
                      "provider": "gitee_ai",
                      "visible": true,
                      "description": "Qwen3-Embedding-8B 是一个高效的中文文本嵌入模型，适用于多种文本向量化场景。"
                  },
                  {
                      "model": "ChatTTS",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "default",
                          "voices": [
                              {
                                  "mode": "default",
                                  "name": "Default",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              }
                          ],
                          "word_limit": 3500,
                          "audio_type": "mp3",
                          "max_workers": 5
                      }
                  },
                  {
                      "model": "CosyVoice2",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "default",
                          "voices": [
                              {
                                  "mode": "default",
                                  "name": "Default",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              }
                          ],
                          "word_limit": 3500,
                          "audio_type": "mp3",
                          "max_workers": 5
                      }
                  },
                  {
                      "model": "fish-speech-1.2-sft",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "default",
                          "voices": [
                              {
                                  "mode": "default",
                                  "name": "Default",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              }
                          ],
                          "word_limit": 3500,
                          "audio_type": "mp3",
                          "max_workers": 5
                      }
                  },
                  {
                      "model": "fish-speech-1.5",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "default",
                          "voices": [
                              {
                                  "mode": "default",
                                  "name": "Default",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              }
                          ],
                          "word_limit": 3500,
                          "audio_type": "mp3",
                          "max_workers": 5
                      }
                  },
                  {
                      "model": "FunAudioLLM-CosyVoice-300M",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "default",
                          "voices": [
                              {
                                  "mode": "default",
                                  "name": "Default",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              }
                          ],
                          "word_limit": 3500,
                          "audio_type": "mp3",
                          "max_workers": 5
                      }
                  },
                  {
                      "model": "MegaTTS3",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "default",
                          "voices": [
                              {
                                  "mode": "default",
                                  "name": "Default",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              }
                          ],
                          "word_limit": 3500,
                          "audio_type": "mp3",
                          "max_workers": 5
                      }
                  },
                  {
                      "model": "Step-Audio-TTS-3B",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "default",
                          "voices": [
                              {
                                  "mode": "default",
                                  "name": "Default",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              }
                          ],
                          "word_limit": 3500,
                          "audio_type": "mp3",
                          "max_workers": 5
                      }
                  }
              ],
              "provider": "gitee_ai",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      }
                  ]
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Model context size",
                              "zh_Hans": "模型上下文长度"
                          },
                          "placeholder": {
                              "en_US": "Enter your Model context size",
                              "zh_Hans": "在此输入您的模型上下文长度"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "context_size"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Upper bound for max tokens",
                              "zh_Hans": "最大 token 上限"
                          },
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "text-input",
                          "variable": "max_tokens"
                      },
                      {
                          "default": "no_call",
                          "label": {
                              "en_US": "Function calling"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  },
                                  "value": "no_call"
                              },
                              {
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  },
                                  "value": "function_call"
                              }
                          ],
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "select",
                          "variable": "function_calling_type"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  }
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding",
                  "rerank",
                  "speech2text",
                  "tts"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "Models provided by MistralAI, including Magistral models with prompt_mode support, Mistral Large/Medium/Small, Pixtral vision models, Codestral for coding, specialized embedding models, and content moderation services.",
              "zh_Hans": "MistralAI 提供的模型，包括支持 prompt_mode 的 Magistral 模型、Mistral Large/Medium/Small、Pixtral 视觉模型、Codestral 编程模型、专用嵌入模型和内容审核服务。"
          },
          "icon": "icon_s_en.png",
          "label": {
              "en_US": "MistralAI"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "mistralai",
          "plugins": {
              "models": [
                  "provider/mistralai.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": true,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.4",
          "model": {
              "background": "#FFFFFF",
              "configurate_methods": [
                  "predefined-model"
              ],
              "description": {
                  "en_US": "Models provided by MistralAI, including Magistral models with prompt_mode support, Mistral Large/Medium/Small, Pixtral vision models, Codestral for coding, specialized embedding models, and content moderation services.",
                  "zh_Hans": "MistralAI 提供的模型，包括支持 prompt_mode 的 Magistral 模型、Mistral Large/Medium/Small、Pixtral 视觉模型、Codestral 编程模型、专用嵌入模型和内容审核服务。"
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/text_embedding/text_embedding.py",
                          "models/moderation/moderation.py"
                      ],
                      "provider_source": "provider/mistralai.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API Key from MistralAI",
                      "zh_Hans": "从 MistralAI 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://console.mistral.ai/api-keys/"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.png"
              },
              "icon_small": {
                  "en_US": "icon_s_en.png"
              },
              "label": {
                  "en_US": "MistralAI"
              },
              "models": [
                  {
                      "model": "codestral-2501",
                      "label": {
                          "zh_Hans": "Codestral (25.01)",
                          "en_US": "Codestral (25.01)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 256000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 256000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ],
                      "pricing": {
                          "input": "0.3",
                          "output": "0.9",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "codestral-latest",
                      "label": {
                          "zh_Hans": "Codestral (Latest)",
                          "en_US": "Codestral (Latest)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 256000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 256000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ],
                      "pricing": {
                          "input": "0.3",
                          "output": "0.9",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "devstral-small-2505",
                      "label": {
                          "zh_Hans": "Devstral Small (25.05)",
                          "en_US": "Devstral Small (25.05)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ],
                      "pricing": {
                          "input": "0.1",
                          "output": "0.3",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "devstral-small-latest",
                      "label": {
                          "zh_Hans": "Devstral Small (Latest)",
                          "en_US": "Devstral Small (Latest)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ],
                      "pricing": {
                          "input": "0.1",
                          "output": "0.3",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "magistral-medium-2506",
                      "label": {
                          "zh_Hans": "Magistral Medium (25.06)",
                          "en_US": "Magistral Medium (25.06)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 40960,
                              "min": 1,
                              "max": 128000,
                              "help": {
                                  "en_US": "Maximum tokens to generate. 40960 recommended for complex tasks. Context window is 128k but performance may degrade past 40k.",
                                  "zh_Hans": "生成的最大令牌数。复杂任务建议使用40960。上下文窗口为128k，但超过40k后性能可能下降。"
                              }
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "reasoning_mode",
                              "type": "boolean",
                              "default": true,
                              "help": {
                                  "en_US": "Enable reasoning mode with system prompt for step-by-step problem solving. When disabled, uses standard chat behavior without system prompt.",
                                  "zh_Hans": "启用带系统提示的推理模式进行逐步问题解决。禁用时，使用标准聊天行为而无系统提示。"
                              },
                              "label": {
                                  "en_US": "Reasoning Mode",
                                  "zh_Hans": "推理模式"
                              }
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "5",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "magistral-medium-latest",
                      "label": {
                          "zh_Hans": "Magistral Medium (Latest)",
                          "en_US": "Magistral Medium (Latest)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 40960,
                              "min": 1,
                              "max": 128000,
                              "help": {
                                  "en_US": "Maximum tokens to generate. 40960 recommended for complex tasks. Context window is 128k but performance may degrade past 40k.",
                                  "zh_Hans": "生成的最大令牌数。复杂任务建议使用40960。上下文窗口为128k，但超过40k后性能可能下降。"
                              }
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "reasoning_mode",
                              "type": "boolean",
                              "default": true,
                              "help": {
                                  "en_US": "Enable reasoning mode with system prompt for step-by-step problem solving. When disabled, uses standard chat behavior without system prompt.",
                                  "zh_Hans": "启用带系统提示的推理模式进行逐步问题解决。禁用时，使用标准聊天行为而无系统提示。"
                              },
                              "label": {
                                  "en_US": "Reasoning Mode",
                                  "zh_Hans": "推理模式"
                              }
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "5",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "magistral-small-2506",
                      "label": {
                          "zh_Hans": "Magistral Small (25.06)",
                          "en_US": "Magistral Small (25.06)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 40960,
                              "min": 1,
                              "max": 128000,
                              "help": {
                                  "en_US": "Maximum tokens to generate. 40960 recommended for complex tasks. Context window is 128k but performance may degrade past 40k.",
                                  "zh_Hans": "生成的最大令牌数。复杂任务建议使用40960。上下文窗口为128k，但超过40k后性能可能下降。"
                              }
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "reasoning_mode",
                              "type": "boolean",
                              "default": true,
                              "help": {
                                  "en_US": "Enable reasoning mode with system prompt for step-by-step problem solving. When disabled, uses standard chat behavior without system prompt.",
                                  "zh_Hans": "启用带系统提示的推理模式进行逐步问题解决。禁用时，使用标准聊天行为而无系统提示。"
                              },
                              "label": {
                                  "en_US": "Reasoning Mode",
                                  "zh_Hans": "推理模式"
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.5",
                          "output": "1.5",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "magistral-small-latest",
                      "label": {
                          "zh_Hans": "Magistral Small (Latest)",
                          "en_US": "Magistral Small (Latest)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 40960,
                              "min": 1,
                              "max": 128000,
                              "help": {
                                  "en_US": "Maximum tokens to generate. 40960 recommended for complex tasks. Context window is 128k but performance may degrade past 40k.",
                                  "zh_Hans": "生成的最大令牌数。复杂任务建议使用40960。上下文窗口为128k，但超过40k后性能可能下降。"
                              }
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "reasoning_mode",
                              "type": "boolean",
                              "default": true,
                              "help": {
                                  "en_US": "Enable reasoning mode with system prompt for step-by-step problem solving. When disabled, uses standard chat behavior without system prompt.",
                                  "zh_Hans": "启用带系统提示的推理模式进行逐步问题解决。禁用时，使用标准聊天行为而无系统提示。"
                              },
                              "label": {
                                  "en_US": "Reasoning Mode",
                                  "zh_Hans": "推理模式"
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.5",
                          "output": "1.5",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "mathstral",
                      "label": {
                          "zh_Hans": "Mathstral",
                          "en_US": "Mathstral"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 32000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ]
                  },
                  {
                      "model": "ministral-3b-2410",
                      "label": {
                          "zh_Hans": "Ministral 3B (24.10)",
                          "en_US": "Ministral 3B (24.10)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ],
                      "pricing": {
                          "input": "0.04",
                          "output": "0.04",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "ministral-3b-latest",
                      "label": {
                          "zh_Hans": "Ministral 3B (Latest)",
                          "en_US": "Ministral 3B (Latest)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ],
                      "pricing": {
                          "input": "0.04",
                          "output": "0.04",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "ministral-8b-2410",
                      "label": {
                          "zh_Hans": "Ministral 8B (24.10)",
                          "en_US": "Ministral 8B (24.10)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ],
                      "pricing": {
                          "input": "0.1",
                          "output": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "ministral-8b-latest",
                      "label": {
                          "zh_Hans": "Ministral 8B (Latest)",
                          "en_US": "Ministral 8B (Latest)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ],
                      "pricing": {
                          "input": "0.1",
                          "output": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "mistral-large-2411",
                      "label": {
                          "zh_Hans": "Mistral Large (24.11)",
                          "en_US": "Mistral Large (24.11)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "6",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "mistral-large-latest",
                      "label": {
                          "zh_Hans": "Mistral Large (Latest)",
                          "en_US": "Mistral Large (Latest)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "6",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "mistral-medium-2505",
                      "label": {
                          "zh_Hans": "Mistral Medium (25.05)",
                          "en_US": "Mistral Medium (25.05)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ],
                      "pricing": {
                          "input": "0.4",
                          "output": "2",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "mistral-medium-latest",
                      "label": {
                          "zh_Hans": "Mistral Medium (Latest)",
                          "en_US": "Mistral Medium (Latest)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ],
                      "pricing": {
                          "input": "0.4",
                          "output": "2",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "mistral-saba-2502",
                      "label": {
                          "zh_Hans": "Mistral Saba (25.02)",
                          "en_US": "Mistral Saba (25.02)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 32000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ],
                      "pricing": {
                          "input": "0.2",
                          "output": "0.6",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "mistral-saba-latest",
                      "label": {
                          "zh_Hans": "Mistral Saba (Latest)",
                          "en_US": "Mistral Saba (Latest)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 32000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ],
                      "pricing": {
                          "input": "0.2",
                          "output": "0.6",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "mistral-small-2503",
                      "label": {
                          "zh_Hans": "Mistral Small (25.03)",
                          "en_US": "Mistral Small (25.03)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ],
                      "pricing": {
                          "input": "0.1",
                          "output": "0.3",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "mistral-small-latest",
                      "label": {
                          "zh_Hans": "Mistral Small (Latest)",
                          "en_US": "Mistral Small (Latest)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ],
                      "pricing": {
                          "input": "0.1",
                          "output": "0.3",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "open-codestral-mamba",
                      "label": {
                          "zh_Hans": "Codestral Mamba (Latest)",
                          "en_US": "Codestral Mamba (Latest)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 256000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 256000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ],
                      "pricing": {
                          "input": "0.008",
                          "output": "0.024",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "open-mistral-nemo-2407",
                      "label": {
                          "zh_Hans": "Mistral Nemo (24.07)",
                          "en_US": "Mistral Nemo (24.07)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ],
                      "pricing": {
                          "input": "0.15",
                          "output": "0.15",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "open-mistral-nemo",
                      "label": {
                          "zh_Hans": "Mistral Nemo (Latest)",
                          "en_US": "Mistral Nemo (Latest)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ],
                      "pricing": {
                          "input": "0.15",
                          "output": "0.15",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "pixtral-12b-2409",
                      "label": {
                          "zh_Hans": "Pixtral 12B (24.09)",
                          "en_US": "Pixtral 12B (24.09)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ],
                      "pricing": {
                          "input": "0.15",
                          "output": "0.15",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "pixtral-large-2411",
                      "label": {
                          "zh_Hans": "Pixtral Large (24.11)",
                          "en_US": "Pixtral Large (24.11)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "6",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "pixtral-large-latest",
                      "label": {
                          "zh_Hans": "Pixtral Large (Latest)",
                          "en_US": "Pixtral Large (Latest)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.7,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 1,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "safe_prompt",
                              "default": false,
                              "type": "boolean",
                              "help": {
                                  "en_US": "Whether to inject a safety prompt before all conversations.",
                                  "zh_Hans": "是否开启提示词审查"
                              },
                              "label": {
                                  "en_US": "SafePrompt",
                                  "zh_Hans": "提示词审查"
                              }
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "RandomSeed",
                                  "zh_Hans": "随机数种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          },
                          {
                              "name": "frequency_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Frequency penalty penalizes the repetition of words based on their frequency in the generated text.",
                                  "zh_Hans": "频率惩罚根据生成文本中单词的频率来惩罚单词的重复"
                              },
                              "label": {
                                  "en_US": "Frequency Penalty",
                                  "zh_Hans": "频率惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          },
                          {
                              "name": "presence_penalty",
                              "type": "float",
                              "help": {
                                  "en_US": "Presence penalty determines how much the model penalizes the repetition of words or phrases.",
                                  "zh_Hans": "存在惩罚决定模型对单词或短语重复的惩罚程度"
                              },
                              "label": {
                                  "en_US": "Presence Penalty",
                                  "zh_Hans": "存在惩罚"
                              },
                              "default": 0,
                              "min": -2,
                              "max": 2
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "6",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "codestral-embed",
                      "label": {
                          "zh_Hans": "Codestral Embed",
                          "en_US": "Codestral Embed"
                      },
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 1
                      },
                      "pricing": {
                          "input": "0.15",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "mistral-embed",
                      "label": {
                          "zh_Hans": "Mistral Embed",
                          "en_US": "Mistral Embed"
                      },
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 1
                      },
                      "pricing": {
                          "input": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "mistral-moderation-2411",
                      "label": {
                          "zh_Hans": "Mistral Moderation (24.11)",
                          "en_US": "Mistral Moderation (24.11)"
                      },
                      "model_type": "moderation",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 1
                      },
                      "pricing": {
                          "input": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "mistral-moderation-latest",
                      "label": {
                          "zh_Hans": "Mistral Moderation (Latest)",
                          "en_US": "Mistral Moderation (Latest)"
                      },
                      "model_type": "moderation",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 1
                      },
                      "pricing": {
                          "input": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  }
              ],
              "provider": "mistralai",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding",
                  "moderation"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "Models provided by 01.AI, such as yi-34b-chat and yi-vl-plus.",
              "zh_Hans": "零一万物提供的模型，例如 yi-34b-chat 和 yi-vl-plus。"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "01.AI",
              "zh_Hans": "零一万物"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "yi",
          "plugins": {
              "models": [
                  "provider/yi.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.2",
          "model": {
              "background": "#E9F1EC",
              "configurate_methods": [
                  "predefined-model",
                  "customizable-model"
              ],
              "description": {
                  "en_US": "Models provided by 01.AI, such as yi-34b-chat and yi-vl-plus.",
                  "zh_Hans": "零一万物提供的模型，例如 yi-34b-chat 和 yi-vl-plus。"
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py"
                      ],
                      "provider_source": "provider/yi.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API Key from 01.ai",
                      "zh_Hans": "从零一万物获取 API Key"
                  },
                  "url": {
                      "en_US": "https://platform.lingyiwanwu.com/apikeys"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "01.AI",
                  "zh_Hans": "零一万物"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Model context size",
                              "zh_Hans": "模型上下文长度"
                          },
                          "placeholder": {
                              "en_US": "Enter your Model context size",
                              "zh_Hans": "在此输入您的模型上下文长度"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "context_size"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Upper bound for max tokens",
                              "zh_Hans": "最大 token 上限"
                          },
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "text-input",
                          "variable": "max_tokens"
                      },
                      {
                          "default": "no_call",
                          "label": {
                              "en_US": "Function calling"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  },
                                  "value": "no_call"
                              },
                              {
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  },
                                  "value": "function_call"
                              }
                          ],
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "select",
                          "variable": "function_calling_type"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  }
              },
              "models": [
                  {
                      "model": "yi-34b-chat-0205",
                      "label": {
                          "zh_Hans": "yi-34b-chat-0205",
                          "en_US": "yi-34b-chat-0205"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的多样性和随机性。数值越小，越严谨；数值越大，越发散。",
                                  "en_US": "Control the diversity and randomness of generated results. The smaller the value, the more rigorous it is; the larger the value, the more divergent it is."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 4000,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.01,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的随机性。数值越小，随机性越弱；数值越大，随机性越强。一般而言，top_p 和 temperature 两个参数选择一个进行调整即可。",
                                  "en_US": "Control the randomness of generated results. The smaller the value, the weaker the randomness; the larger the value, the stronger the randomness. Generally speaking, you can adjust one of the two parameters top_p and temperature."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "2.5",
                          "output": "2.5",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "yi-34b-chat-200k",
                      "label": {
                          "zh_Hans": "yi-34b-chat-200k",
                          "en_US": "yi-34b-chat-200k"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.6,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的多样性和随机性。数值越小，越严谨；数值越大，越发散。",
                                  "en_US": "Control the diversity and randomness of generated results. The smaller the value, the more rigorous it is; the larger the value, the more divergent it is."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 4096,
                              "min": 1,
                              "max": 199950,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.9,
                              "min": 0.01,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的随机性。数值越小，随机性越弱；数值越大，随机性越强。一般而言，top_p 和 temperature 两个参数选择一个进行调整即可。",
                                  "en_US": "Control the randomness of generated results. The smaller the value, the weaker the randomness; the larger the value, the stronger the randomness. Generally speaking, you can adjust one of the two parameters top_p and temperature."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "12",
                          "output": "12",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "yi-large-turbo",
                      "label": {
                          "zh_Hans": "yi-large-turbo",
                          "en_US": "yi-large-turbo"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16384
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的多样性和随机性。数值越小，越严谨；数值越大，越发散。",
                                  "en_US": "Control the diversity and randomness of generated results. The smaller the value, the more rigorous it is; the larger the value, the more divergent it is."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 1024,
                              "min": 1,
                              "max": 16384,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.9,
                              "min": 0.01,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的随机性。数值越小，随机性越弱；数值越大，随机性越强。一般而言，top_p 和 temperature 两个参数选择一个进行调整即可。",
                                  "en_US": "Control the randomness of generated results. The smaller the value, the weaker the randomness; the larger the value, the stronger the randomness. Generally speaking, you can adjust one of the two parameters top_p and temperature."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "12",
                          "output": "12",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "yi-large",
                      "label": {
                          "zh_Hans": "yi-large",
                          "en_US": "yi-large"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16384
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的多样性和随机性。数值越小，越严谨；数值越大，越发散。",
                                  "en_US": "Control the diversity and randomness of generated results. The smaller the value, the more rigorous it is; the larger the value, the more divergent it is."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 1024,
                              "min": 1,
                              "max": 16384,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.9,
                              "min": 0.01,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的随机性。数值越小，随机性越弱；数值越大，随机性越强。一般而言，top_p 和 temperature 两个参数选择一个进行调整即可。",
                                  "en_US": "Control the randomness of generated results. The smaller the value, the weaker the randomness; the larger the value, the stronger the randomness. Generally speaking, you can adjust one of the two parameters top_p and temperature."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "20",
                          "output": "20",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "yi-lightning",
                      "label": {
                          "zh_Hans": "yi-lightning",
                          "en_US": "yi-lightning"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16384
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的多样性和随机性。数值越小，越严谨；数值越大，越发散。",
                                  "en_US": "Control the diversity and randomness of generated results. The smaller the value, the more rigorous it is; the larger the value, the more divergent it is."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 1024,
                              "min": 1,
                              "max": 4000,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.9,
                              "min": 0.01,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的随机性。数值越小，随机性越弱；数值越大，随机性越强。一般而言，top_p 和 temperature 两个参数选择一个进行调整即可。",
                                  "en_US": "Control the randomness of generated results. The smaller the value, the weaker the randomness; the larger the value, the stronger the randomness. Generally speaking, you can adjust one of the two parameters top_p and temperature."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.99",
                          "output": "0.99",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "yi-medium-200k",
                      "label": {
                          "zh_Hans": "yi-medium-200k",
                          "en_US": "yi-medium-200k"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 204800
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的多样性和随机性。数值越小，越严谨；数值越大，越发散。",
                                  "en_US": "Control the diversity and randomness of generated results. The smaller the value, the more rigorous it is; the larger the value, the more divergent it is."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 1024,
                              "min": 1,
                              "max": 204800,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.9,
                              "min": 0.01,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的随机性。数值越小，随机性越弱；数值越大，随机性越强。一般而言，top_p 和 temperature 两个参数选择一个进行调整即可。",
                                  "en_US": "Control the randomness of generated results. The smaller the value, the weaker the randomness; the larger the value, the stronger the randomness. Generally speaking, you can adjust one of the two parameters top_p and temperature."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "12",
                          "output": "12",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "yi-medium",
                      "label": {
                          "zh_Hans": "yi-medium",
                          "en_US": "yi-medium"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16384
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的多样性和随机性。数值越小，越严谨；数值越大，越发散。",
                                  "en_US": "Control the diversity and randomness of generated results. The smaller the value, the more rigorous it is; the larger the value, the more divergent it is."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 1024,
                              "min": 1,
                              "max": 16384,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.9,
                              "min": 0.01,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的随机性。数值越小，随机性越弱；数值越大，随机性越强。一般而言，top_p 和 temperature 两个参数选择一个进行调整即可。",
                                  "en_US": "Control the randomness of generated results. The smaller the value, the weaker the randomness; the larger the value, the stronger the randomness. Generally speaking, you can adjust one of the two parameters top_p and temperature."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "2.5",
                          "output": "2.5",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "yi-spark",
                      "label": {
                          "zh_Hans": "yi-spark",
                          "en_US": "yi-spark"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16384
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的多样性和随机性。数值越小，越严谨；数值越大，越发散。",
                                  "en_US": "Control the diversity and randomness of generated results. The smaller the value, the more rigorous it is; the larger the value, the more divergent it is."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 1024,
                              "min": 1,
                              "max": 16384,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.9,
                              "min": 0.01,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的随机性。数值越小，随机性越弱；数值越大，随机性越强。一般而言，top_p 和 temperature 两个参数选择一个进行调整即可。",
                                  "en_US": "Control the randomness of generated results. The smaller the value, the weaker the randomness; the larger the value, the stronger the randomness. Generally speaking, you can adjust one of the two parameters top_p and temperature."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "1",
                          "output": "1",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "yi-vision",
                      "label": {
                          "zh_Hans": "yi-vision",
                          "en_US": "yi-vision"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的多样性和随机性。数值越小，越严谨；数值越大，越发散。",
                                  "en_US": "Control the diversity and randomness of generated results. The smaller the value, the more rigorous it is; the larger the value, the more divergent it is."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 1024,
                              "min": 1,
                              "max": 4096,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.9,
                              "min": 0.01,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的随机性。数值越小，随机性越弱；数值越大，随机性越强。一般而言，top_p 和 temperature 两个参数选择一个进行调整即可。",
                                  "en_US": "Control the randomness of generated results. The smaller the value, the weaker the randomness; the larger the value, the stronger the randomness. Generally speaking, you can adjust one of the two parameters top_p and temperature."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "6",
                          "output": "6",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "yi-vl-plus",
                      "label": {
                          "zh_Hans": "yi-vl-plus",
                          "en_US": "yi-vl-plus"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的多样性和随机性。数值越小，越严谨；数值越大，越发散。",
                                  "en_US": "Control the diversity and randomness of generated results. The smaller the value, the more rigorous it is; the larger the value, the more divergent it is."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 4000,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.01,
                              "max": 1.0,
                              "help": {
                                  "zh_Hans": "控制生成结果的随机性。数值越小，随机性越弱；数值越大，随机性越强。一般而言，top_p 和 temperature 两个参数选择一个进行调整即可。",
                                  "en_US": "Control the randomness of generated results. The smaller the value, the weaker the randomness; the larger the value, the stronger the randomness. Generally speaking, you can adjust one of the two parameters top_p and temperature."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "6",
                          "output": "6",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  }
              ],
              "provider": "yi",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "label": {
                              "en_US": "Custom API endpoint URL",
                              "zh_Hans": "自定义 API endpoint 地址"
                          },
                          "placeholder": {
                              "en_US": "Base URL, e.g. https://api.lingyiwanwu.com/v1",
                              "zh_Hans": "Base URL, e.g. https://api.lingyiwanwu.com/v1"
                          },
                          "required": false,
                          "type": "text-input",
                          "variable": "endpoint_url"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "Baichuan"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "Baichuan",
              "zh_Hans": "百川智能"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "baichuan",
          "plugins": {
              "models": [
                  "provider/baichuan.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {}
          },
          "type": "plugin",
          "version": "0.0.3",
          "model": {
              "background": "#FFF6F2",
              "configurate_methods": [
                  "predefined-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/text_embedding/text_embedding.py"
                      ],
                      "provider_source": "provider/baichuan.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API Key from BAICHUAN AI",
                      "zh_Hans": "从百川智能获取您的 API Key"
                  },
                  "url": {
                      "en_US": "https://www.baichuan-ai.com"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "Baichuan"
              },
              "models": [
                  {
                      "model": "baichuan2-53b",
                      "label": {
                          "en_US": "Baichuan2-53B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 1000,
                              "min": 1,
                              "max": 4000
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "default": 1,
                              "min": 1,
                              "max": 2
                          },
                          {
                              "name": "with_search_enhance",
                              "label": {
                                  "zh_Hans": "搜索增强",
                                  "en_US": "Search Enhance"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "允许模型自行进行外部搜索，以增强生成结果。",
                                  "en_US": "Allow the model to perform external search to enhance the generation results."
                              },
                              "required": false
                          }
                      ],
                      "deprecated": true
                  },
                  {
                      "model": "baichuan2-turbo-192k",
                      "label": {
                          "en_US": "Baichuan2-Turbo-192K"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 192000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 8000,
                              "min": 1,
                              "max": 192000
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "default": 1,
                              "min": 1,
                              "max": 2
                          },
                          {
                              "name": "with_search_enhance",
                              "label": {
                                  "zh_Hans": "搜索增强",
                                  "en_US": "Search Enhance"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "允许模型自行进行外部搜索，以增强生成结果。",
                                  "en_US": "Allow the model to perform external search to enhance the generation results."
                              },
                              "required": false
                          }
                      ],
                      "deprecated": true
                  },
                  {
                      "model": "baichuan2-turbo",
                      "label": {
                          "en_US": "Baichuan2-Turbo"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.3
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.85
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "min": 0,
                              "max": 20,
                              "default": 5,
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 2048
                          },
                          {
                              "name": "with_search_enhance",
                              "label": {
                                  "zh_Hans": "搜索增强",
                                  "en_US": "Search Enhance"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "允许模型自行进行外部搜索，以增强生成结果。",
                                  "en_US": "Allow the model to perform external search to enhance the generation results."
                              },
                              "required": false
                          }
                      ]
                  },
                  {
                      "model": "baichuan3-turbo-128k",
                      "label": {
                          "en_US": "Baichuan3-Turbo-128k"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.3
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.85
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "min": 0,
                              "max": 20,
                              "default": 5,
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 2048
                          },
                          {
                              "name": "res_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          },
                          {
                              "name": "with_search_enhance",
                              "label": {
                                  "zh_Hans": "搜索增强",
                                  "en_US": "Search Enhance"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "允许模型自行进行外部搜索，以增强生成结果。",
                                  "en_US": "Allow the model to perform external search to enhance the generation results."
                              },
                              "required": false
                          }
                      ]
                  },
                  {
                      "model": "baichuan3-turbo",
                      "label": {
                          "en_US": "Baichuan3-Turbo"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.3
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.85
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "min": 0,
                              "max": 20,
                              "default": 5,
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 2048
                          },
                          {
                              "name": "res_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          },
                          {
                              "name": "with_search_enhance",
                              "label": {
                                  "zh_Hans": "搜索增强",
                                  "en_US": "Search Enhance"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "允许模型自行进行外部搜索，以增强生成结果。",
                                  "en_US": "Allow the model to perform external search to enhance the generation results."
                              },
                              "required": false
                          }
                      ]
                  },
                  {
                      "model": "baichuan4-air",
                      "label": {
                          "en_US": "Baichuan4-Air"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.3
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.85
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "min": 0,
                              "max": 20,
                              "default": 5,
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 2048
                          },
                          {
                              "name": "res_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          },
                          {
                              "name": "with_search_enhance",
                              "label": {
                                  "zh_Hans": "搜索增强",
                                  "en_US": "Search Enhance"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "允许模型自行进行外部搜索，以增强生成结果。",
                                  "en_US": "Allow the model to perform external search to enhance the generation results."
                              },
                              "required": false
                          }
                      ]
                  },
                  {
                      "model": "baichuan4-turbo",
                      "label": {
                          "en_US": "Baichuan4-Turbo"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.3
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.85
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "min": 0,
                              "max": 20,
                              "default": 5,
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 2048
                          },
                          {
                              "name": "res_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          },
                          {
                              "name": "with_search_enhance",
                              "label": {
                                  "zh_Hans": "搜索增强",
                                  "en_US": "Search Enhance"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "允许模型自行进行外部搜索，以增强生成结果。",
                                  "en_US": "Allow the model to perform external search to enhance the generation results."
                              },
                              "required": false
                          }
                      ]
                  },
                  {
                      "model": "baichuan4",
                      "label": {
                          "en_US": "Baichuan4"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "multi-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.3
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.85
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "min": 0,
                              "max": 20,
                              "default": 5,
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 2048
                          },
                          {
                              "name": "res_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          },
                          {
                              "name": "with_search_enhance",
                              "label": {
                                  "zh_Hans": "搜索增强",
                                  "en_US": "Search Enhance"
                              },
                              "type": "boolean",
                              "help": {
                                  "zh_Hans": "允许模型自行进行外部搜索，以增强生成结果。",
                                  "en_US": "Allow the model to perform external search to enhance the generation results."
                              },
                              "required": false
                          }
                      ]
                  },
                  {
                      "model": "baichuan-text-embedding",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 512,
                          "max_chunks": 16
                      }
                  }
              ],
              "provider": "baichuan",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "API Catalog",
              "zh_Hans": "API Catalog"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "API Catalog"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "nvidia",
          "plugins": {
              "models": [
                  "provider/nvidia.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.2",
          "model": {
              "background": "#FFFFFF",
              "configurate_methods": [
                  "predefined-model"
              ],
              "description": {
                  "en_US": "API Catalog",
                  "zh_Hans": "API Catalog"
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/rerank/rerank.py",
                          "models/text_embedding/text_embedding.py"
                      ],
                      "provider_source": "provider/nvidia.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API Key from NVIDIA",
                      "zh_Hans": "从 NVIDIA 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://build.nvidia.com/explore/discover"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.png"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "API Catalog"
              },
              "models": [
                  {
                      "model": "snowflake/arctic",
                      "label": {
                          "zh_Hans": "snowflake/arctic",
                          "en_US": "snowflake/arctic"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 1,
                              "default": 0.5
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 1024,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ]
                  },
                  {
                      "model": "google/codegemma-7b",
                      "label": {
                          "zh_Hans": "google/codegemma-7b",
                          "en_US": "google/codegemma-7b"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 1,
                              "default": 0.5
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 1024,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ]
                  },
                  {
                      "model": "deepseek-ai/deepseek-r1",
                      "label": {
                          "en_US": "deepseek-ai/deepseek-r1"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 1,
                              "default": 0.5
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 1024,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ]
                  },
                  {
                      "model": "fuyu-8b",
                      "label": {
                          "zh_Hans": "fuyu-8b",
                          "en_US": "fuyu-8b"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.2,
                              "min": 0.1,
                              "max": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.7,
                              "min": 0.1,
                              "max": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 1024,
                              "min": 1,
                              "max": 1024
                          }
                      ]
                  },
                  {
                      "model": "google/gemma-7b",
                      "label": {
                          "zh_Hans": "google/gemma-7b",
                          "en_US": "google/gemma-7b"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 1,
                              "default": 0.5
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 1024,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ]
                  },
                  {
                      "model": "meta/llama-3.1-405b-instruct",
                      "label": {
                          "zh_Hans": "meta/llama-3.1-405b-instruct",
                          "en_US": "meta/llama-3.1-405b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 1,
                              "default": 0.5
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 4096,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalt",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ]
                  },
                  {
                      "model": "meta/llama-3.1-70b-instruct",
                      "label": {
                          "zh_Hans": "meta/llama-3.1-70b-instruct",
                          "en_US": "meta/llama-3.1-70b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 1,
                              "default": 0.5
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 4096,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ]
                  },
                  {
                      "model": "meta/llama-3.1-8b-instruct",
                      "label": {
                          "zh_Hans": "meta/llama-3.1-8b-instruct",
                          "en_US": "meta/llama-3.1-8b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 1,
                              "default": 0.5
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 4096,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ]
                  },
                  {
                      "model": "meta/llama2-70b",
                      "label": {
                          "zh_Hans": "meta/llama2-70b",
                          "en_US": "meta/llama2-70b"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 1,
                              "default": 0.5
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 1024,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ]
                  },
                  {
                      "model": "meta/llama3-70b-instruct",
                      "label": {
                          "zh_Hans": "meta/llama3-70b-instruct",
                          "en_US": "meta/llama3-70b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 1,
                              "default": 0.5
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 1024,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ]
                  },
                  {
                      "model": "meta/llama3-8b-instruct",
                      "label": {
                          "zh_Hans": "meta/llama3-8b-instruct",
                          "en_US": "meta/llama3-8b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 1,
                              "default": 0.5
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 1024,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ]
                  },
                  {
                      "model": "mistralai/mistral-large",
                      "label": {
                          "zh_Hans": "mistralai/mistral-large",
                          "en_US": "mistralai/mistral-large"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 1,
                              "default": 0.5
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 1024,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ]
                  },
                  {
                      "model": "mistralai/mixtral-8x7b-instruct-v0.1",
                      "label": {
                          "zh_Hans": "mistralai/mixtral-8x7b-instruct-v0.1",
                          "en_US": "mistralai/mixtral-8x7b-instruct-v0.1"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 1,
                              "default": 0.5
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 1024,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ]
                  },
                  {
                      "model": "mistralai/mixtral-8x22b-instruct-v0.1",
                      "label": {
                          "zh_Hans": "mistralai/mixtral-8x22b-instruct-v0.1",
                          "en_US": "mistralai/mixtral-8x22b-instruct-v0.1"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 1,
                              "default": 0.5
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 1024,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ]
                  },
                  {
                      "model": "nvidia/nemotron-4-340b-instruct",
                      "label": {
                          "zh_Hans": "nvidia/nemotron-4-340b-instruct",
                          "en_US": "nvidia/nemotron-4-340b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 1,
                              "default": 0.5
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 4096,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ]
                  },
                  {
                      "model": "microsoft/phi-3-medium-128k-instruct",
                      "label": {
                          "zh_Hans": "microsoft/phi-3-medium-128k-instruct",
                          "en_US": "microsoft/phi-3-medium-128k-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 1,
                              "default": 0.5
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 4096,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ]
                  },
                  {
                      "model": "microsoft/phi-3-mini-128k-instruct",
                      "label": {
                          "zh_Hans": "microsoft/phi-3-mini-128k-instruct",
                          "en_US": "microsoft/phi-3-mini-128k-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 1,
                              "default": 0.5
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 4096,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ]
                  },
                  {
                      "model": "google/recurrentgemma-2b",
                      "label": {
                          "zh_Hans": "google/recurrentgemma-2b",
                          "en_US": "google/recurrentgemma-2b"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2048
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 1,
                              "default": 0.2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 0.7
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 1024,
                              "default": 1024
                          },
                          {
                              "name": "random_seed",
                              "type": "int",
                              "help": {
                                  "en_US": "The seed to use for random sampling. If set, different calls will generate deterministic results.",
                                  "zh_Hans": "当开启随机数种子以后，你可以通过指定一个固定的种子来使得回答结果更加稳定"
                              },
                              "label": {
                                  "en_US": "Seed",
                                  "zh_Hans": "种子"
                              },
                              "default": 0,
                              "min": 0,
                              "max": 2147483647
                          }
                      ]
                  },
                  {
                      "model": "nv-rerank-qa-mistral-4b:1",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 512
                      }
                  },
                  {
                      "model": "NV-Embed-QA",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 512,
                          "max_chunks": 1
                      }
                  }
              ],
              "provider": "nvidia",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding",
                  "rerank"
              ]
          }
      },
      {
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "replicate",
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "Replicate"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "Replicate"
          },
          "plugins": {
              "models": [
                  "provider/replicate.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": false
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.3",
          "model": {
              "background": "#E5E7EB",
              "configurate_methods": [
                  "customizable-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/text_embedding/text_embedding.py"
                      ],
                      "provider_source": "provider/replicate.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API Key from Replicate",
                      "zh_Hans": "从 Replicate 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://replicate.com/account/api-tokens"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "Replicate"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your Replicate API Key",
                              "zh_Hans": "在此输入您的 Replicate API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "replicate_api_token"
                      },
                      {
                          "label": {
                              "en_US": "Model Version"
                          },
                          "placeholder": {
                              "en_US": "Enter your model version, default to the latest version",
                              "zh_Hans": "在此输入您的模型版本，默认为最新版本"
                          },
                          "required": false,
                          "type": "text-input",
                          "variable": "model_version"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      }
                  }
              },
              "provider": "replicate",
              "supported_model_types": [
                  "llm",
                  "text-embedding"
              ],
              "models": []
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "NVIDIA NIM, a set of easy-to-use inference microservices.",
              "zh_Hans": "NVIDIA NIM，一组易于使用的模型推理微服务。"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "NVIDIA NIM"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "nvidia_nim",
          "plugins": {
              "models": [
                  "provider/nvidia_nim.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.2",
          "model": {
              "background": "#EFFDFD",
              "configurate_methods": [
                  "customizable-model"
              ],
              "description": {
                  "en_US": "NVIDIA NIM, a set of easy-to-use inference microservices.",
                  "zh_Hans": "NVIDIA NIM，一组易于使用的模型推理微服务。"
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py"
                      ],
                      "provider_source": "provider/nvidia_nim.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Learn more about NVIDIA NIM",
                      "zh_Hans": "了解 NVIDIA NIM 更多信息"
                  },
                  "url": {
                      "en_US": "https://www.nvidia.com/en-us/ai/"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.png"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "NVIDIA NIM"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API endpoint URL",
                              "zh_Hans": "API endpoint URL"
                          },
                          "placeholder": {
                              "en_US": "Base URL, e.g. http://192.168.1.100:8000/v1",
                              "zh_Hans": "Base URL, e.g. http://192.168.1.100:8000/v1"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "endpoint_url"
                      },
                      {
                          "default": "chat",
                          "label": {
                              "en_US": "Completion mode"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Completion",
                                      "zh_Hans": "补全"
                                  },
                                  "value": "completion"
                              },
                              {
                                  "label": {
                                      "en_US": "Chat",
                                      "zh_Hans": "对话"
                                  },
                                  "value": "chat"
                              }
                          ],
                          "placeholder": {
                              "en_US": "Select completion mode",
                              "zh_Hans": "选择对话类型"
                          },
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "select",
                          "variable": "mode"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Model context size",
                              "zh_Hans": "模型上下文长度"
                          },
                          "placeholder": {
                              "en_US": "Enter your Model context size",
                              "zh_Hans": "在此输入您的模型上下文长度"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "context_size"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Upper bound for max tokens",
                              "zh_Hans": "最大 token 上限"
                          },
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "text-input",
                          "variable": "max_tokens_to_sample"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter full model name",
                          "zh_Hans": "输入模型全称"
                      }
                  }
              },
              "models": [],
              "provider": "nvidia_nim",
              "supported_model_types": [
                  "llm"
              ]
          }
      },
      {
          "version": "0.0.3",
          "type": "plugin",
          "author": "infiniai",
          "name": "infiniai",
          "label": {
              "en_US": "无问芯穹",
              "ja_JP": "无问芯穹",
              "zh_Hans": "无问芯穹",
              "pt_BR": "无问芯穹"
          },
          "description": {
              "en_US": "InfiniAI provides high-performance APIs for accelerating large model inference, covering multiple modalities such as text, images, and videos. It supports the latest open-source LLM models like DeepSeek, as well as SOTA embedding and reranking models such as Jina/bge. Configuration can be done via model names, API keys, and other parameters.",
              "ja_JP": "InfiniAIは、テキスト、画像、動画などの多様なモダリティをカバーする大規模モデル推論高速化のための高性能APIを提供します。DeepSeekなどの最新オープンソースLLMモデルや、Jina/bgeなどのSOTA埋め込み・再ランキングモデルをサポートし、モデル名、APIキー、その他のパラメータで設定できます。",
              "zh_Hans": "无问芯穹提供大模型推理加速高性能API，涵盖文本、图像、视频等多种模态，支持最新开源DeepSeek等系列LLM模型，以及Jina/bge等sota嵌入重排模型，可通过模型名称、API密钥和其他参数进行配置。",
              "pt_BR": "InfiniAI fornece APIs de alto desempenho para acelerar a inferência de modelos grandes, abrangendo várias modalidades, como texto, imagens e vídeos. Ele suporta os mais recentes modelos LLM de código aberto, como DeepSeek, bem como modelos SOTA de incorporação e reclassificação, como Jina/bge. A configuração pode ser feita por meio de nomes de modelos, chaves de API e outros parâmetros."
          },
          "icon": "icon.svg",
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "text_embedding": true,
                      "rerank": true,
                      "tts": true,
                      "speech2text": true,
                      "moderation": true
                  }
              }
          },
          "plugins": {
              "models": [
                  "provider/infiniai.yaml"
              ]
          },
          "meta": {
              "version": "0.0.1",
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "language": "python",
                  "version": "3.12",
                  "entrypoint": "main"
              }
          },
          "created_at": "2025-03-12T17:15:12.677072+08:00",
          "privacy": "PRIVACY.md",
          "verified": false,
          "model": {
              "provider": "infiniai",
              "label": {
                  "en_US": "InfiniAI"
              },
              "description": {
                  "en_US": "Models provided by InfiniAI.",
                  "zh_Hans": "InfiniAI 提供的模型。"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "background": "#E5E7EB",
              "help": {
                  "title": {
                      "en_US": "Get your API Key from InfiniAI",
                      "zh_Hans": "从 InfiniAI 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://cloud.infini-ai.com/genstudio/model?deepsearch"
                  }
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding",
                  "rerank",
                  "tts",
                  "speech2text",
                  "moderation"
              ],
              "configurate_methods": [
                  "predefined-model",
                  "customizable-model"
              ],
              "model_credential_schema": {
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  },
                  "credential_form_schemas": [
                      {
                          "variable": "infiniai_api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "type": "secret-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Key",
                              "en_US": "Enter your API Key"
                          }
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Model context size",
                              "zh_Hans": "模型上下文长度"
                          },
                          "placeholder": {
                              "en_US": "Enter your Model context size",
                              "zh_Hans": "在此输入您的模型上下文长度"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "context_size"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Upper bound for max tokens",
                              "zh_Hans": "最大 token 上限"
                          },
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "text-input",
                          "variable": "max_tokens"
                      },
                      {
                          "default": "no_call",
                          "label": {
                              "en_US": "Function calling"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  },
                                  "value": "no_call"
                              },
                              {
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  },
                                  "value": "function_call"
                              }
                          ],
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "select",
                          "variable": "function_calling_type"
                      }
                  ]
              },
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "variable": "infiniai_api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "type": "secret-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Key",
                              "en_US": "Enter your API Key"
                          }
                      }
                  ]
              },
              "models": [
                  {
                      "model": "deepseek-r1",
                      "label": {
                          "zh_Hans": "deepseek-r1",
                          "en_US": "deepseek-r1"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 2048,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0",
                          "output": "0.0",
                          "unit": "0.0",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "deepseek-v3",
                      "label": {
                          "zh_Hans": "deepseek-v3",
                          "en_US": "deepseek-v3"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 2048,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0",
                          "output": "0.0",
                          "unit": "0.0",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2.5-14b-instruct",
                      "label": {
                          "zh_Hans": "qwen2.5-14b-instruct",
                          "en_US": "qwen2.5-14b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 2048,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0",
                          "output": "0.0",
                          "unit": "0.0",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2.5-32b-instruct",
                      "label": {
                          "zh_Hans": "qwen2.5-32b-instruct",
                          "en_US": "qwen2.5-32b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 2048,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0",
                          "output": "0.0",
                          "unit": "0.0",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2.5-72b-instruct",
                      "label": {
                          "zh_Hans": "qwen2.5-72b-instruct",
                          "en_US": "qwen2.5-72b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 2048,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0",
                          "output": "0.0",
                          "unit": "0.0",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2.5-7b-instruct",
                      "label": {
                          "zh_Hans": "qwen2.5-7b-instruct",
                          "en_US": "qwen2.5-7b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 2048,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0",
                          "output": "0.0",
                          "unit": "0.0",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2.5-vl-32b-instruct",
                      "label": {
                          "zh_Hans": "qwen2.5-vl-32b-instruct",
                          "en_US": "qwen2.5-vl-32b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 2048,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0",
                          "output": "0.0",
                          "unit": "0.0",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2.5-vl-72b-instruct",
                      "label": {
                          "zh_Hans": "qwen2.5-vl-72b-instruct",
                          "en_US": "qwen2.5-vl-72b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 2048,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0",
                          "output": "0.0",
                          "unit": "0.0",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen2.5-vl-7b-instruct",
                      "label": {
                          "zh_Hans": "qwen2.5-vl-7b-instruct",
                          "en_US": "qwen2.5-vl-7b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 2048,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0",
                          "output": "0.0",
                          "unit": "0.0",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen3-14b",
                      "label": {
                          "zh_Hans": "qwen3-14b",
                          "en_US": "qwen3-14b"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.0",
                          "output": "0.0",
                          "unit": "0.0",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen3-235b-a22b",
                      "label": {
                          "zh_Hans": "qwen3-235b-a22b",
                          "en_US": "qwen3-235b-a22b"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.0",
                          "output": "0.0",
                          "unit": "0.0",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen3-30b-a3b",
                      "label": {
                          "zh_Hans": "qwen3-30b-a3b",
                          "en_US": "qwen3-30b-a3b"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.0",
                          "output": "0.0",
                          "unit": "0.0",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen3-32b",
                      "label": {
                          "zh_Hans": "qwen3-32b",
                          "en_US": "qwen3-32b"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.0",
                          "output": "0.0",
                          "unit": "0.0",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen3-8b",
                      "label": {
                          "zh_Hans": "qwen3-8b",
                          "en_US": "qwen3-8b"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.0",
                          "output": "0.0",
                          "unit": "0.0",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwq-32b",
                      "label": {
                          "zh_Hans": "qwq-32b",
                          "en_US": "qwq-32b"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 2048,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0",
                          "output": "0.0",
                          "unit": "0.0",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "bge-reranker-v2-m3",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 8192
                      }
                  },
                  {
                      "model": "bge-m3",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 1
                      }
                  },
                  {
                      "model": "jina-embeddings-v2-base-code",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 1
                      }
                  },
                  {
                      "model": "jina-embeddings-v2-base-zh",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 1
                      }
                  }
              ],
              "extra": {
                  "python": {
                      "provider_source": "provider/infiniai.py",
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/text_embedding/text_embedding.py",
                          "models/rerank/rerank.py"
                      ]
                  }
              }
          }
      },
      {
          "author": "cnjasonz",
          "created_at": "2024-02-13T14:45:00-04:00",
          "description": {
              "en_US": "PPIO is a cloud infrastructure provider offering a wide range of AI model services and cost-effective GPU computing services.",
              "zh_Hans": "PPIO 派欧云一站式 AIGC 云服务平台，提供高性能、高性价比的大模型 API 和 GPU 算力服务，无缝集成最前沿的 AI 推理技术，全面覆盖不同业务阶段的 AI 需求，加速 AI 业务发展。"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "PPIO",
              "zh_Hans": "PPIO 派欧云"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.10"
              },
              "version": "0.0.2"
          },
          "name": "ppio",
          "plugins": {
              "models": [
                  "provider/ppio.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": false,
                      "speech2text": false,
                      "text_embedding": false,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.2",
          "privacy": "https://ppio.cn/legal/privacy-policy",
          "model": {
              "provider": "ppio",
              "label": {
                  "en_US": "PPIO",
                  "zh_Hans": "PPIO 派欧云"
              },
              "description": {
                  "en_US": "PPIO is a cloud infrastructure provider offering a wide range of AI model services.",
                  "zh_Hans": "PPIO 提供满血版 DeepSeek R1/V3 模型，以及 Qwen、Llama、Yi 等一系列模型。"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg",
                  "zh_Hans": "icon_l_zh.svg"
              },
              "background": "#b5cefc",
              "help": {
                  "title": {
                      "en_US": "Get your API key from PPIO",
                      "zh_Hans": "从 PPIO 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://ppio.cn/settings/key-management"
                  }
              },
              "supported_model_types": [
                  "llm"
              ],
              "configurate_methods": [
                  "predefined-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py"
                      ],
                      "provider_source": "provider/ppio.py"
                  }
              },
              "models": [
                  {
                      "model": "baichuan/baichuan2-13b-chat",
                      "label": {
                          "zh_Hans": "Baichuan2 13B Chat",
                          "en_US": "Baichuan2 13B Chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 14336
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0175",
                          "output": "0.0175",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "deepseek/deepseek-prover-v2-671b",
                      "label": {
                          "zh_Hans": "Deepseek Prover V2 671B",
                          "en_US": "Deepseek Prover V2 671B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 160000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.04",
                          "output": "0.16",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "deepseek/deepseek-r1-0528-qwen3-8b",
                      "label": {
                          "zh_Hans": "DeepSeek R1 0528 Qwen3 8B",
                          "en_US": "DeepSeek R1 0528 Qwen3 8B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.0065",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "deepseek/deepseek-r1-0528",
                      "label": {
                          "zh_Hans": "DeepSeek R1 0528",
                          "en_US": "DeepSeek R1 0528"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.04",
                          "output": "0.16",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "deepseek/deepseek-r1/community",
                      "label": {
                          "zh_Hans": "DeepSeek R1 (Community)",
                          "en_US": "DeepSeek R1 (Community)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.04",
                          "output": "0.16",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "deepseek/deepseek-r1-distill-llama-70b",
                      "label": {
                          "zh_Hans": "DeepSeek R1 Distill Llama 70B",
                          "en_US": "DeepSeek R1 Distill Llama 70B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.058",
                          "output": "0.058",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "deepseek/deepseek-r1-distill-llama-8b",
                      "label": {
                          "zh_Hans": "DeepSeek: DeepSeek R1 Distill Llama 8B",
                          "en_US": "DeepSeek: DeepSeek R1 Distill Llama 8B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.003",
                          "output": "0.003",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "deepseek/deepseek-r1-distill-qwen-14b",
                      "label": {
                          "zh_Hans": "DeepSeek: DeepSeek R1 Distill Qwen 14B",
                          "en_US": "DeepSeek: DeepSeek R1 Distill Qwen 14B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.01",
                          "output": "0.01",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "deepseek/deepseek-r1-distill-qwen-32b",
                      "label": {
                          "zh_Hans": "DeepSeek: DeepSeek R1 Distill Qwen 32B",
                          "en_US": "DeepSeek: DeepSeek R1 Distill Qwen 32B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0218",
                          "output": "0.0218",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "deepseek/deepseek-r1-turbo",
                      "label": {
                          "zh_Hans": "DeepSeek R1 (Turbo)",
                          "en_US": "DeepSeek R1 (Turbo)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.04",
                          "output": "0.16",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "deepseek/deepseek-v3-0324",
                      "label": {
                          "zh_Hans": "DeepSeek V3 0324",
                          "en_US": "DeepSeek V3 0324"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.02",
                          "output": "0.08",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "deepseek/deepseek-v3/community",
                      "label": {
                          "zh_Hans": "DeepSeek V3 (Community)",
                          "en_US": "DeepSeek V3 (Community)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.02",
                          "output": "0.08",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "deepseek/deepseek-v3-turbo",
                      "label": {
                          "zh_Hans": "DeepSeek V3 (Turbo)",
                          "en_US": "DeepSeek V3 (Turbo)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.02",
                          "output": "0.08",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "google/gemma-3-27b-it",
                      "label": {
                          "zh_Hans": "Gemma 3 27B",
                          "en_US": "Gemma 3 27B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0146",
                          "output": "0.0146",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "thudm/glm-4-32b-0414",
                      "label": {
                          "zh_Hans": "THUDM/GLM-4-32B-0414",
                          "en_US": "THUDM/GLM-4-32B-0414"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0175",
                          "output": "0.0175",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "thudm/glm-4-9b-0414",
                      "label": {
                          "zh_Hans": "THUDM/GLM-4-9B-0414",
                          "en_US": "THUDM/GLM-4-9B-0414"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "thudm/glm-4-9b-chat",
                      "label": {
                          "zh_Hans": "GLM4 9B Chat",
                          "en_US": "GLM4 9B Chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "thudm/glm-z1-32b-0414",
                      "label": {
                          "zh_Hans": "THUDM/GLM-Z1-32B-0414",
                          "en_US": "THUDM/GLM-Z1-32B-0414"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0175",
                          "output": "0.0175",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "thudm/glm-z1-9b-0414",
                      "label": {
                          "zh_Hans": "THUDM/GLM-Z1-9B-0414",
                          "en_US": "THUDM/GLM-Z1-9B-0414"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "thudm/glm-z1-rumination-32b-0414",
                      "label": {
                          "zh_Hans": "THUDM/GLM-Z1-Rumination-32B-0414",
                          "en_US": "THUDM/GLM-Z1-Rumination-32B-0414"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0175",
                          "output": "0.0175",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "meta-llama/llama-3.1-8b-instruct",
                      "label": {
                          "zh_Hans": "Llama3.1 8B Instruct",
                          "en_US": "Llama3.1 8B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.004",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "meta-llama/llama-3.2-3b-instruct",
                      "label": {
                          "zh_Hans": "Llama3.2 3B Instruct",
                          "en_US": "Llama3.2 3B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "meta-llama/llama-3.3-70b-instruct",
                      "label": {
                          "zh_Hans": "Llama 3.3 70B Instruct",
                          "en_US": "Llama 3.3 70B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.028",
                          "output": "0.028",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "meta-llama/llama-4-maverick-17b-128e-instruct-fp8",
                      "label": {
                          "zh_Hans": "Llama 4 Maverick Instruct",
                          "en_US": "Llama 4 Maverick Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0145",
                          "output": "0.062",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "meta-llama/llama-4-scout-17b-16e-instruct",
                      "label": {
                          "zh_Hans": "Llama 4 Scout Instruct",
                          "en_US": "Llama 4 Scout Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.00725",
                          "output": "0.036",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "qwen/qwen-2.5-72b-instruct",
                      "label": {
                          "zh_Hans": "Qwen2.5 72B Instruct",
                          "en_US": "Qwen2.5 72B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0275",
                          "output": "0.0288",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "qwen/qwen2.5-32b-instruct",
                      "label": {
                          "zh_Hans": "Qwen2.5 32B Instruct",
                          "en_US": "Qwen2.5 32B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0126",
                          "output": "0.0126",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "qwen/qwen2.5-7b-instruct",
                      "label": {
                          "zh_Hans": "Qwen 2.5 7B Instruct",
                          "en_US": "Qwen 2.5 7B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "qwen/qwen2.5-vl-72b-instruct",
                      "label": {
                          "zh_Hans": "Qwen2.5 VL 72B Instruct",
                          "en_US": "Qwen2.5 VL 72B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 96000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.042",
                          "output": "0.042",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "qwen/qwen3-235b-a22b-fp8",
                      "label": {
                          "zh_Hans": "Qwen3-235B-A22B",
                          "en_US": "Qwen3-235B-A22B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 40960
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0145",
                          "output": "0.058",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "qwen/qwen3-30b-a3b-fp8",
                      "label": {
                          "zh_Hans": "Qwen3-30B-A3B",
                          "en_US": "Qwen3-30B-A3B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0072",
                          "output": "0.0326",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "qwen/qwen3-32b-fp8",
                      "label": {
                          "zh_Hans": "Qwen3 32B",
                          "en_US": "Qwen3 32B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0072",
                          "output": "0.0326",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "qwen/qwen3-4b-fp8",
                      "label": {
                          "zh_Hans": "Qwen3 4B",
                          "en_US": "Qwen3 4B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0",
                          "output": "0",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "qwen/qwen3-8b-fp8",
                      "label": {
                          "zh_Hans": "Qwen3 8B",
                          "en_US": "Qwen3 8B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0025",
                          "output": "0.01",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "01-ai/yi-1.5-34b-chat",
                      "label": {
                          "zh_Hans": "YI 1.5 34B Chat",
                          "en_US": "YI 1.5 34B Chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16384
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.011",
                          "output": "0.011",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "01-ai/yi-1.5-9b-chat",
                      "label": {
                          "zh_Hans": "YI 1.5 9B Chat",
                          "en_US": "YI 1.5 9B Chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16384
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.004",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  }
              ],
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "variable": "api_key",
                          "label": {
                              "en_US": "API Key",
                              "zh_Hans": "API Key"
                          },
                          "type": "secret-input",
                          "required": true,
                          "placeholder": {
                              "en_US": "Please input your  API Key",
                              "zh_Hans": "请输入您的 API Key"
                          }
                      }
                  ]
              }
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "together.ai"
          },
          "icon": "togetherai_square.svg",
          "label": {
              "en_US": "Together.AI"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "togetherai",
          "plugins": {
              "models": [
                  "provider/togetherai.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.2",
          "model": {
              "background": "#F1EFED",
              "configurate_methods": [
                  "customizable-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py"
                      ],
                      "provider_source": "provider/togetherai.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API key from together.ai",
                      "zh_Hans": "从 together.ai 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://api.together.xyz/"
                  }
              },
              "icon_large": {
                  "en_US": "togetherai.svg"
              },
              "icon_small": {
                  "en_US": "togetherai_square.svg"
              },
              "label": {
                  "en_US": "together.ai"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "default": "chat",
                          "label": {
                              "en_US": "Completion mode"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Completion",
                                      "zh_Hans": "补全"
                                  },
                                  "value": "completion"
                              },
                              {
                                  "label": {
                                      "en_US": "Chat",
                                      "zh_Hans": "对话"
                                  },
                                  "value": "chat"
                              }
                          ],
                          "placeholder": {
                              "en_US": "Select completion mode",
                              "zh_Hans": "选择对话类型"
                          },
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "select",
                          "variable": "mode"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Model context size",
                              "zh_Hans": "模型上下文长度"
                          },
                          "placeholder": {
                              "en_US": "Enter your Model context size",
                              "zh_Hans": "在此输入您的模型上下文长度"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "context_size"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Upper bound for max tokens",
                              "zh_Hans": "最大 token 上限"
                          },
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "text-input",
                          "variable": "max_tokens_to_sample"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter full model name",
                          "zh_Hans": "输入模型全称"
                      }
                  }
              },
              "provider": "togetherai",
              "supported_model_types": [
                  "llm"
              ],
              "models": []
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "Models provided by 360 AI.",
              "zh_Hans": "360 智脑提供的模型。"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "360 AI",
              "zh_Hans": "360 智脑"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "zhinao",
          "plugins": {
              "models": [
                  "provider/zhinao.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.2",
          "model": {
              "background": "#e3f0ff",
              "configurate_methods": [
                  "predefined-model"
              ],
              "description": {
                  "en_US": "Models provided by 360 AI.",
                  "zh_Hans": "360 智脑提供的模型。"
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py"
                      ],
                      "provider_source": "provider/zhinao.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API Key from 360 AI.",
                      "zh_Hans": "从360 智脑获取 API Key"
                  },
                  "url": {
                      "en_US": "https://ai.360.com/platform/keys"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "360 AI",
                  "zh_Hans": "360 智脑"
              },
              "models": [
                  {
                      "model": "360gpt-turbo-responsibility-8k",
                      "label": {
                          "zh_Hans": "360gpt-turbo-responsibility-8k",
                          "en_US": "360gpt-turbo-responsibility-8k"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 1,
                              "default": 0.5
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ]
                  },
                  {
                      "model": "360gpt-turbo",
                      "label": {
                          "zh_Hans": "360gpt-turbo",
                          "en_US": "360gpt-turbo"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2048
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 1,
                              "default": 0.5
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ]
                  },
                  {
                      "model": "360gpt2-pro",
                      "label": {
                          "zh_Hans": "360gpt2-pro",
                          "en_US": "360gpt2-pro"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2048
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 1,
                              "default": 0.5
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ]
                  }
              ],
              "provider": "zhinao",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-10-08T16:51:54.385000-04:00",
          "icon": "icon_s_en.png",
          "label": {
              "en_US": "nomic"
          },
          "description": {
              "en_US": "Nomic"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.10"
              },
              "version": "0.0.1"
          },
          "name": "nomic",
          "plugins": {
              "models": [
                  "provider/nomic.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": false,
                      "moderation": false,
                      "rerank": false,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.3",
          "model": {
              "background": "#EFF1FE",
              "configurate_methods": [
                  "predefined-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/text_embedding/text_embedding.py"
                      ],
                      "provider_source": "provider/nomic.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API key from Nomic Atlas",
                      "zh_Hans": "从Nomic Atlas获取 API Key"
                  },
                  "url": {
                      "en_US": "https://atlas.nomic.ai/data"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.png"
              },
              "label": {
                  "en_US": "Nomic Atlas",
                  "zh_Hans": "Nomic Atlas"
              },
              "models": [
                  {
                      "model": "nomic-embed-text-v1.5",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192
                      },
                      "pricing": {
                          "input": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "nomic-embed-text-v1",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192
                      },
                      "pricing": {
                          "input": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  }
              ],
              "provider": "nomic",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "nomic_api_key"
                      }
                  ]
              },
              "supported_model_types": [
                  "text-embedding"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-10-10T18:09:58.213005-04:00",
          "description": {
              "en_US": "Voyage"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "Voyage"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.10"
              },
              "version": "0.0.1"
          },
          "name": "voyage",
          "plugins": {
              "models": [
                  "provider/voyage.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": false,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.5",
          "model": {
              "background": "#EFFDFD",
              "configurate_methods": [
                  "predefined-model"
              ],
              "description": {
                  "en_US": "Embedding and Rerank Model Supported"
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/text_embedding/text_embedding.py",
                          "models/rerank/rerank.py"
                      ],
                      "provider_source": "provider/voyage.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API key from Voyage AI",
                      "zh_Hans": "从 Voyage 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://dash.voyageai.com/"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "Voyage"
              },
              "models": [
                  {
                      "model": "rerank-1",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 8000
                      }
                  },
                  {
                      "model": "rerank-2",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 16000
                      }
                  },
                  {
                      "model": "rerank-lite-1",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 4000
                      }
                  },
                  {
                      "model": "rerank-lite-2",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 8000
                      }
                  },
                  {
                      "model": "voyage-3",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 32000
                      },
                      "pricing": {
                          "input": "0.00018",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "voyage-3-lite",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 32000
                      },
                      "pricing": {
                          "input": "0.00002",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "voyage-3-lite",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 32000
                      },
                      "pricing": {
                          "input": "0.00002",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "voyage-3.5",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 32000
                      },
                      "pricing": {
                          "input": "0.00006",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "voyage-3",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 32000
                      },
                      "pricing": {
                          "input": "0.00006",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "voyage-code-2",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 16000
                      },
                      "pricing": {
                          "input": "0.00012",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "voyage-finance-2",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 32000
                      },
                      "pricing": {
                          "input": "0.00012",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "voyage-law-2",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 16000
                      },
                      "pricing": {
                          "input": "0.00012",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "voyage-multilingual-2",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 32000
                      },
                      "pricing": {
                          "input": "0.00012",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  }
              ],
              "provider": "voyage",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      }
                  ]
              },
              "supported_model_types": [
                  "text-embedding",
                  "rerank"
              ]
          }
      },
      {
          "version": "0.0.3",
          "type": "plugin",
          "author": "ssrag",
          "name": "llama-api",
          "label": {
              "en_US": "Llama API",
              "ja_JP": "Llama API",
              "zh_Hans": "Llama API",
              "pt_BR": "Llama API"
          },
          "description": {
              "en_US": "Llama API",
              "ja_JP": "Llama API",
              "zh_Hans": "Llama API",
              "pt_BR": "Llama API"
          },
          "icon": "icon.svg",
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "text_embedding": false,
                      "rerank": false,
                      "tts": false,
                      "speech2text": false,
                      "moderation": false
                  }
              }
          },
          "plugins": {
              "models": [
                  "provider/llama-api.yaml"
              ]
          },
          "meta": {
              "version": "0.0.3",
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "language": "python",
                  "version": "3.12",
                  "entrypoint": "main"
              }
          },
          "created_at": "2025-04-21T10:19:15.396651-07:00",
          "privacy": "PRIVACY.md",
          "verified": false,
          "model": {
              "provider": "llama-api",
              "label": {
                  "en_US": "Llama API"
              },
              "description": {
                  "en_US": "Models provided by Llama API.",
                  "zh_Hans": "LlamaApi 提供的模型。"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "background": "#E5E7EB",
              "help": {
                  "title": {
                      "en_US": "Get your API Key from Llama API",
                      "zh_Hans": "从 Llama API 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://llama.developer.meta.com"
                  }
              },
              "supported_model_types": [
                  "llm"
              ],
              "configurate_methods": [
                  "predefined-model",
                  "customizable-model"
              ],
              "model_credential_schema": {
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  },
                  "credential_form_schemas": [
                      {
                          "variable": "llama_api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "type": "secret-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Key",
                              "en_US": "Enter your API Key"
                          }
                      }
                  ]
              },
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "variable": "llama_api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "type": "secret-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Key",
                              "en_US": "Enter your API Key"
                          }
                      }
                  ]
              },
              "models": [
                  {
                      "model": "Llama-3.3-70B-Instruct",
                      "label": {
                          "en_US": "Llama-3.3-70B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": null,
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": null,
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 4028,
                              "min": 1,
                              "max": 4028
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "Llama-4-Maverick-17B-128E-Instruct-FP8",
                      "label": {
                          "en_US": "Llama-4-Maverick-17B-128E-Instruct-FP8"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": null,
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": null,
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 4028,
                              "min": 1,
                              "max": 4028
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "Llama-4-Scout-17B-16E-Instruct-FP8",
                      "label": {
                          "en_US": "Llama-4-Scout-17B-16E-Instruct-FP8"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": null,
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": null,
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 4028,
                              "min": 1,
                              "max": 4028
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.00",
                          "output": "0.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  }
              ],
              "extra": {
                  "python": {
                      "provider_source": "provider/llama-api.py",
                      "model_sources": [
                          "models/llm/llm.py"
                      ]
                  }
              }
          }
      },
      {
          "version": "0.0.7",
          "type": "plugin",
          "author": "ssrag",
          "name": "sagemaker",
          "label": {
              "en_US": "Amazon SageMaker",
              "ja_JP": "Amazon SageMaker",
              "zh_Hans": "Amazon SageMaker",
              "pt_BR": "Amazon SageMaker"
          },
          "description": {
              "en_US": "Self deployed model provider - Amazon SageMaker",
              "ja_JP": "Self deployed model provider - Amazon SageMaker",
              "zh_Hans": "Self deployed model provider - Amazon SageMaker",
              "pt_BR": "Self deployed model provider - Amazon SageMaker"
          },
          "icon": "icon_s_en.png",
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "text_embedding": false,
                      "rerank": false,
                      "tts": false,
                      "speech2text": false,
                      "moderation": false
                  }
              }
          },
          "plugins": {
              "models": [
                  "provider/sagemaker.yaml"
              ]
          },
          "meta": {
              "version": "0.0.1",
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "language": "python",
                  "version": "3.12",
                  "entrypoint": "main"
              }
          },
          "created_at": "2025-02-26T11:40:49.732667+08:00",
          "privacy": "PRIVACY.md",
          "verified": false,
          "model": {
              "provider": "sagemaker",
              "label": {
                  "en_US": "Amazon SageMaker"
              },
              "icon_small": {
                  "en_US": "icon_s_en.png"
              },
              "icon_large": {
                  "en_US": "icon_l_en.png"
              },
              "description": {
                  "en_US": "Customized model on SageMaker",
                  "zh_Hans": "SageMaker上的私有化部署的模型"
              },
              "background": "#ECE9E3",
              "help": {
                  "title": {
                      "en_US": "How to deploy customized model on SageMaker",
                      "zh_Hans": "如何在Sagemaker上的私有化部署的模型"
                  },
                  "url": {
                      "en_US": "https://github.com/aws-samples/",
                      "zh_Hans": "https://github.com/aws-samples/"
                  }
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding",
                  "rerank",
                  "speech2text",
                  "tts"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/rerank/rerank.py",
                          "models/text_embedding/text_embedding.py",
                          "models/tts/tts.py",
                          "models/speech2text/speech2text.py"
                      ],
                      "provider_source": "provider/sagemaker.py"
                  }
              },
              "configurate_methods": [
                  "customizable-model"
              ],
              "model_credential_schema": {
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  },
                  "credential_form_schemas": [
                      {
                          "variable": "mode",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "en_US": "Completion mode"
                          },
                          "type": "select",
                          "required": false,
                          "default": "chat",
                          "placeholder": {
                              "zh_Hans": "选择对话类型",
                              "en_US": "Select completion mode"
                          },
                          "options": [
                              {
                                  "value": "chat",
                                  "label": {
                                      "en_US": "Chat",
                                      "zh_Hans": "Chat"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "sagemaker_endpoint",
                          "label": {
                              "en_US": "sagemaker endpoint"
                          },
                          "type": "text-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "请输出你的Sagemaker推理端点",
                              "en_US": "Enter your Sagemaker Inference endpoint"
                          }
                      },
                      {
                          "variable": "context_length",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "zh_Hans": "模型上下文长度",
                              "en_US": "Model context size"
                          },
                          "type": "text-input",
                          "default": "4096",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的模型上下文长度",
                              "en_US": "Enter your Model context size"
                          }
                      },
                      {
                          "variable": "audio_s3_cache_bucket",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "speech2text"
                              }
                          ],
                          "label": {
                              "zh_Hans": "音频缓存桶(s3 bucket, Whisper模型不填,FunASR模型需要填)",
                              "en_US": "audio cache bucket(s3 bucket, Whisper模型不填,FunASR模型需要填)"
                          },
                          "type": "text-input",
                          "required": false,
                          "placeholder": {
                              "zh_Hans": "sagemaker-us-east-1-******207838",
                              "en_US": "sagemaker-us-east-1-*******7838"
                          }
                      },
                      {
                          "variable": "audio_model_type",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "tts"
                              }
                          ],
                          "label": {
                              "en_US": "Audio model type"
                          },
                          "type": "select",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "语音模型类型",
                              "en_US": "Audio model type"
                          },
                          "options": [
                              {
                                  "value": "PresetVoice",
                                  "label": {
                                      "en_US": "preset voice",
                                      "zh_Hans": "内置音色"
                                  }
                              },
                              {
                                  "value": "CloneVoice",
                                  "label": {
                                      "en_US": "clone voice",
                                      "zh_Hans": "克隆音色"
                                  }
                              },
                              {
                                  "value": "CloneVoice_CrossLingual",
                                  "label": {
                                      "en_US": "crosslingual clone voice",
                                      "zh_Hans": "跨语种克隆音色"
                                  }
                              },
                              {
                                  "value": "InstructVoice",
                                  "label": {
                                      "en_US": "Instruct voice",
                                      "zh_Hans": "文字指令音色"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "prompt_audio",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "tts"
                              }
                          ],
                          "label": {
                              "en_US": "Mock Audio Source"
                          },
                          "type": "text-input",
                          "required": false,
                          "placeholder": {
                              "zh_Hans": "被模仿的音色音频",
                              "en_US": "source audio to be mocked"
                          }
                      },
                      {
                          "variable": "prompt_text",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "tts"
                              }
                          ],
                          "label": {
                              "en_US": "Prompt Audio Text"
                          },
                          "type": "text-input",
                          "required": false,
                          "placeholder": {
                              "zh_Hans": "模仿音色的对应文本",
                              "en_US": "text for the mocked source audio"
                          }
                      },
                      {
                          "variable": "instruct_text",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "tts"
                              }
                          ],
                          "label": {
                              "en_US": "instruct text for speaker"
                          },
                          "type": "text-input",
                          "required": false
                      },
                      {
                          "variable": "aws_access_key_id",
                          "required": false,
                          "label": {
                              "en_US": "Access Key (If not provided, credentials are obtained from the running environment.)",
                              "zh_Hans": "Access Key (如果未提供，凭证将从运行环境中获取。)"
                          },
                          "type": "secret-input",
                          "placeholder": {
                              "en_US": "Enter your Access Key",
                              "zh_Hans": "在此输入您的 Access Key"
                          }
                      },
                      {
                          "variable": "aws_secret_access_key",
                          "required": false,
                          "label": {
                              "en_US": "Secret Access Key",
                              "zh_Hans": "Secret Access Key"
                          },
                          "type": "secret-input",
                          "placeholder": {
                              "en_US": "Enter your Secret Access Key",
                              "zh_Hans": "在此输入您的 Secret Access Key"
                          }
                      },
                      {
                          "variable": "aws_region",
                          "required": false,
                          "label": {
                              "en_US": "AWS Region",
                              "zh_Hans": "AWS 地区"
                          },
                          "type": "select",
                          "default": "us-east-1",
                          "options": [
                              {
                                  "value": "us-east-1",
                                  "label": {
                                      "en_US": "US East (N. Virginia)",
                                      "zh_Hans": "美国东部 (弗吉尼亚北部)"
                                  }
                              },
                              {
                                  "value": "us-west-2",
                                  "label": {
                                      "en_US": "US West (Oregon)",
                                      "zh_Hans": "美国西部 (俄勒冈州)"
                                  }
                              },
                              {
                                  "value": "ap-southeast-1",
                                  "label": {
                                      "en_US": "Asia Pacific (Singapore)",
                                      "zh_Hans": "亚太地区 (新加坡)"
                                  }
                              },
                              {
                                  "value": "ap-northeast-1",
                                  "label": {
                                      "en_US": "Asia Pacific (Tokyo)",
                                      "zh_Hans": "亚太地区 (东京)"
                                  }
                              },
                              {
                                  "value": "eu-central-1",
                                  "label": {
                                      "en_US": "Europe (Frankfurt)",
                                      "zh_Hans": "欧洲 (法兰克福)"
                                  }
                              },
                              {
                                  "value": "us-gov-west-1",
                                  "label": {
                                      "en_US": "AWS GovCloud (US-West)",
                                      "zh_Hans": "AWS GovCloud (US-West)"
                                  }
                              },
                              {
                                  "value": "ap-southeast-2",
                                  "label": {
                                      "en_US": "Asia Pacific (Sydney)",
                                      "zh_Hans": "亚太地区 (悉尼)"
                                  }
                              },
                              {
                                  "value": "cn-north-1",
                                  "label": {
                                      "en_US": "AWS Beijing (cn-north-1)",
                                      "zh_Hans": "中国北京 (cn-north-1)"
                                  }
                              },
                              {
                                  "value": "cn-northwest-1",
                                  "label": {
                                      "en_US": "AWS Ningxia (cn-northwest-1)",
                                      "zh_Hans": "中国宁夏 (cn-northwest-1)"
                                  }
                              }
                          ]
                      }
                  ]
              },
              "models": []
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "Fireworks AI",
              "zh_Hans": "Fireworks AI"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "Fireworks AI",
              "zh_Hans": "Fireworks AI"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "fireworks",
          "plugins": {
              "models": [
                  "provider/fireworks.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.3",
          "model": {
              "background": "#FCFDFF",
              "configurate_methods": [
                  "predefined-model",
                  "customizable-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/text_embedding/text_embedding.py"
                      ],
                      "provider_source": "provider/fireworks.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API Key from Fireworks AI",
                      "zh_Hans": "从 Fireworks AI 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://fireworks.ai/account/api-keys"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "Fireworks AI",
                  "zh_Hans": "Fireworks AI"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "The zh_Hans of Model",
                              "zh_Hans": "模型中文名称"
                          },
                          "placeholder": {
                              "en_US": "Enter your zh_Hans of Model",
                              "zh_Hans": "在此输入您的模型中文名称"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "model_label_zh_Hanns"
                      },
                      {
                          "label": {
                              "en_US": "The en_US of Model",
                              "zh_Hans": "模型英文名称"
                          },
                          "placeholder": {
                              "en_US": "Enter your en_US of Model",
                              "zh_Hans": "在此输入您的模型英文名称"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "model_label_en_US"
                      },
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "fireworks_api_key"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Model context size",
                              "zh_Hans": "模型上下文长度"
                          },
                          "placeholder": {
                              "en_US": "Enter your Model context size",
                              "zh_Hans": "在此输入您的模型上下文长度"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "context_size"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Upper bound for max tokens",
                              "zh_Hans": "最大 token 上限"
                          },
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "text-input",
                          "variable": "max_tokens"
                      },
                      {
                          "default": "no_call",
                          "label": {
                              "en_US": "Function calling"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  },
                                  "value": "no_call"
                              },
                              {
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  },
                                  "value": "function_call"
                              }
                          ],
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "select",
                          "variable": "function_calling_type"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model URL",
                          "zh_Hans": "模型URL"
                      },
                      "placeholder": {
                          "en_US": "Enter your Model URL",
                          "zh_Hans": "输入模型URL"
                      }
                  }
              },
              "models": [
                  {
                      "model": "accounts/fireworks/models/firefunction-v1",
                      "label": {
                          "zh_Hans": "Firefunction V1",
                          "en_US": "Firefunction V1"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.5",
                          "output": "0.5",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "accounts/fireworks/models/firefunction-v2",
                      "label": {
                          "zh_Hans": "Firefunction V2",
                          "en_US": "Firefunction V2"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.9",
                          "output": "0.9",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "accounts/fireworks/models/gemma2-9b-it",
                      "label": {
                          "zh_Hans": "Gemma2 9B Instruct",
                          "en_US": "Gemma2 9B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.2",
                          "output": "0.2",
                          "unit": "0.000001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "accounts/fireworks/models/llama-v3-70b-instruct-hf",
                      "label": {
                          "zh_Hans": "Llama3 70B Instruct(HF version)",
                          "en_US": "Llama3 70B Instruct(HF version)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.9",
                          "output": "0.9",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "accounts/fireworks/models/llama-v3-70b-instruct",
                      "label": {
                          "zh_Hans": "Llama3 70B Instruct",
                          "en_US": "Llama3 70B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.9",
                          "output": "0.9",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "accounts/fireworks/models/llama-v3-8b-instruct-hf",
                      "label": {
                          "zh_Hans": "Llama3 8B Instruct(HF version)",
                          "en_US": "Llama3 8B Instruct(HF version)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.2",
                          "output": "0.2",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "accounts/fireworks/models/llama-v3-8b-instruct",
                      "label": {
                          "zh_Hans": "Llama3 8B Instruct",
                          "en_US": "Llama3 8B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.2",
                          "output": "0.2",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "accounts/fireworks/models/llama-v3p1-405b-instruct",
                      "label": {
                          "zh_Hans": "Llama3.1 405B Instruct",
                          "en_US": "Llama3.1 405B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "3",
                          "output": "3",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "accounts/fireworks/models/llama-v3p1-70b-instruct",
                      "label": {
                          "zh_Hans": "Llama3.1 70B Instruct",
                          "en_US": "Llama3.1 70B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.2",
                          "output": "0.2",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "accounts/fireworks/models/llama-v3p1-8b-instruct",
                      "label": {
                          "zh_Hans": "Llama3.1 8B Instruct",
                          "en_US": "Llama3.1 8B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.2",
                          "output": "0.2",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "accounts/fireworks/models/llama-v3p2-11b-vision-instruct",
                      "label": {
                          "zh_Hans": "Llama 3.2 11B Vision Instruct",
                          "en_US": "Llama 3.2 11B Vision Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.2",
                          "output": "0.2",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "accounts/fireworks/models/llama-v3p2-1b-instruct",
                      "label": {
                          "zh_Hans": "Llama 3.2 1B Instruct",
                          "en_US": "Llama 3.2 1B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.1",
                          "output": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "accounts/fireworks/models/llama-v3p2-3b-instruct",
                      "label": {
                          "zh_Hans": "Llama 3.2 3B Instruct",
                          "en_US": "Llama 3.2 3B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.1",
                          "output": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "accounts/fireworks/models/llama-v3p2-90b-vision-instruct",
                      "label": {
                          "zh_Hans": "Llama 3.2 90B Vision Instruct",
                          "en_US": "Llama 3.2 90B Vision Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.9",
                          "output": "0.9",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "accounts/fireworks/models/mixtral-8x22b-instruct",
                      "label": {
                          "zh_Hans": "Mixtral MoE 8x22B Instruct",
                          "en_US": "Mixtral MoE 8x22B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 65536
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "1.2",
                          "output": "1.2",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "accounts/fireworks/models/mixtral-8x7b-instruct-hf",
                      "label": {
                          "zh_Hans": "Mixtral MoE 8x7B Instruct(HF version)",
                          "en_US": "Mixtral MoE 8x7B Instruct(HF version)"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.5",
                          "output": "0.5",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "accounts/fireworks/models/mixtral-8x7b-instruct",
                      "label": {
                          "zh_Hans": "Mixtral MoE 8x7B Instruct",
                          "en_US": "Mixtral MoE 8x7B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.5",
                          "output": "0.5",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "accounts/fireworks/models/mythomax-l2-13b",
                      "label": {
                          "zh_Hans": "MythoMax L2 13b",
                          "en_US": "MythoMax L2 13b"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.2",
                          "output": "0.2",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "accounts/fireworks/models/phi-3-vision-128k-instruct",
                      "label": {
                          "zh_Hans": "Phi3.5 Vision Instruct",
                          "en_US": "Phi3.5 Vision Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.2",
                          "output": "0.2",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "accounts/fireworks/models/qwen2p5-72b-instruct",
                      "label": {
                          "zh_Hans": "Qwen2.5 72B Instruct",
                          "en_US": "Qwen2.5 72B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.9",
                          "output": "0.9",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "accounts/yi-01-ai/models/yi-large",
                      "label": {
                          "zh_Hans": "Yi-Large",
                          "en_US": "Yi-Large"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens"
                          },
                          {
                              "name": "context_length_exceeded_behavior",
                              "default": "None",
                              "label": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "help": {
                                  "zh_Hans": "上下文长度超出行为",
                                  "en_US": "Context Length Exceeded Behavior"
                              },
                              "type": "string",
                              "options": [
                                  "None",
                                  "truncate",
                                  "error"
                              ]
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "3",
                          "output": "3",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "thenlper/gte-base",
                      "label": {
                          "zh_Hans": "GTE-base",
                          "en_US": "GTE-base"
                      },
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 512,
                          "max_chunks": 1
                      },
                      "pricing": {
                          "input": "0.008",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "thenlper/gte-large",
                      "label": {
                          "zh_Hans": "GTE-large",
                          "en_US": "GTE-large"
                      },
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 512,
                          "max_chunks": 1
                      },
                      "pricing": {
                          "input": "0.008",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "nomic-ai/nomic-embed-text-v1.5",
                      "label": {
                          "zh_Hans": "nomic-embed-text-v1.5",
                          "en_US": "nomic-embed-text-v1.5"
                      },
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 16
                      },
                      "pricing": {
                          "input": "0.008",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "nomic-ai/nomic-embed-text-v1",
                      "label": {
                          "zh_Hans": "nomic-embed-text-v1",
                          "en_US": "nomic-embed-text-v1"
                      },
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 16
                      },
                      "pricing": {
                          "input": "0.008",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "WhereIsAI/UAE-Large-V1",
                      "label": {
                          "zh_Hans": "UAE-Large-V1",
                          "en_US": "UAE-Large-V1"
                      },
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 512,
                          "max_chunks": 1
                      },
                      "pricing": {
                          "input": "0.008",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  }
              ],
              "provider": "fireworks",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "fireworks_api_key"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "Triton Inference Server"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "Triton Inference Server"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "triton_inference_server",
          "plugins": {
              "models": [
                  "provider/triton_inference_server.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.2",
          "model": {
              "background": "#EFFDFD",
              "configurate_methods": [
                  "customizable-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py"
                      ],
                      "provider_source": "provider/triton_inference_server.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "How to deploy Triton Inference Server",
                      "zh_Hans": "如何部署 Triton Inference Server"
                  },
                  "url": {
                      "en_US": "https://github.com/triton-inference-server/server"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.png"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "Triton Inference Server"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "Server url",
                              "zh_Hans": "服务器URL"
                          },
                          "placeholder": {
                              "en_US": "Enter the url of your Triton Inference Server, e.g. http://192.168.1.100:8000",
                              "zh_Hans": "在此输入 Triton Inference Server 的服务器地址，如 http://192.168.1.100:8000"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "server_url"
                      },
                      {
                          "default": "2048",
                          "label": {
                              "en_US": "Context size",
                              "zh_Hans": "上下文大小"
                          },
                          "placeholder": {
                              "en_US": "Enter the context size",
                              "zh_Hans": "在此输入您的上下文大小"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "context_size"
                      },
                      {
                          "default": "chat",
                          "label": {
                              "en_US": "Model type",
                              "zh_Hans": "补全类型"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Completion model",
                                      "zh_Hans": "补全模型"
                                  },
                                  "value": "completion"
                              },
                              {
                                  "label": {
                                      "en_US": "Chat model",
                                      "zh_Hans": "对话模型"
                                  },
                                  "value": "chat"
                              }
                          ],
                          "placeholder": {
                              "en_US": "Enter the completion type",
                              "zh_Hans": "在此输入您的补全类型"
                          },
                          "required": true,
                          "type": "select",
                          "variable": "completion_type"
                      },
                      {
                          "default": "true",
                          "label": {
                              "en_US": "Stream output",
                              "zh_Hans": "流式输出"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Yes",
                                      "zh_Hans": "是"
                                  },
                                  "value": "true"
                              },
                              {
                                  "label": {
                                      "en_US": "No",
                                      "zh_Hans": "否"
                                  },
                                  "value": "false"
                              }
                          ],
                          "placeholder": {
                              "en_US": "Whether to support stream output",
                              "zh_Hans": "是否支持流式输出"
                          },
                          "required": true,
                          "type": "select",
                          "variable": "stream"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  }
              },
              "models": [],
              "provider": "triton_inference_server",
              "supported_model_types": [
                  "llm"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-10-08T16:58:21.101264-04:00",
          "description": {
              "en_US": "Novita AI provides an LLM API that matches various application scenarios with high cost-effectiveness.",
              "zh_Hans": "适配多种海外应用场景的高性价比 LLM API"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "Novita"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.10"
              },
              "version": "0.0.1"
          },
          "name": "novita",
          "plugins": {
              "models": [
                  "provider/novita.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": false,
                      "speech2text": false,
                      "text_embedding": false,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.4",
          "model": {
              "background": "#c7fce2",
              "configurate_methods": [
                  "predefined-model"
              ],
              "description": {
                  "en_US": "An LLM API that matches various application scenarios with high cost-effectiveness.",
                  "zh_Hans": "适配多种海外应用场景的高性价比 LLM API"
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py"
                      ],
                      "provider_source": "provider/novita.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API key from Novita AI",
                      "zh_Hans": "从 Novita AI 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://novita.ai/settings/key-management"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "Novita AI"
              },
              "models": [
                  {
                      "model": "jondurbin/airoboros-l2-70b",
                      "label": {
                          "zh_Hans": "Airoboros L2 70B",
                          "en_US": "Airoboros L2 70B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.005",
                          "output": "0.005",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "deepseek/deepseek-r1-distill-llama-70b",
                      "label": {
                          "zh_Hans": "DeepSeek R1 Distill LLama 70B",
                          "en_US": "DeepSeek R1 Distill LLama 70B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.008",
                          "output": "0.008",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "deepseek/deepseek-r1-distill-llama-8b",
                      "label": {
                          "zh_Hans": "DeepSeek: DeepSeek R1 Distill Llama 8B",
                          "en_US": "DeepSeek: DeepSeek R1 Distill Llama 8B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0004",
                          "output": "0.0004",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "deepseek/deepseek-r1-distill-qwen-14b",
                      "label": {
                          "zh_Hans": "DeepSeek: DeepSeek R1 Distill Qwen 14B",
                          "en_US": "DeepSeek: DeepSeek R1 Distill Qwen 14B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0015",
                          "output": "0.0015",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "deepseek/deepseek-r1-distill-qwen-32b",
                      "label": {
                          "zh_Hans": "DeepSeek: DeepSeek R1 Distill Qwen 32B",
                          "en_US": "DeepSeek: DeepSeek R1 Distill Qwen 32B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.003",
                          "output": "0.003",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "deepseek/deepseek-r1",
                      "label": {
                          "zh_Hans": "DeepSeek R1",
                          "en_US": "DeepSeek R1"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.04",
                          "output": "0.04",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "deepseek/deepseek_v3",
                      "label": {
                          "zh_Hans": "DeepSeek V3",
                          "en_US": "DeepSeek V3"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0089",
                          "output": "0.0089",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "cognitivecomputations/dolphin-mixtral-8x22b",
                      "label": {
                          "zh_Hans": "Dolphin Mixtral 8x22B",
                          "en_US": "Dolphin Mixtral 8x22B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.009",
                          "output": "0.009",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "google/gemma-2-9b-it",
                      "label": {
                          "zh_Hans": "Gemma 2 9B",
                          "en_US": "Gemma 2 9B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0008",
                          "output": "0.0008",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "nousresearch/hermes-2-pro-llama-3-8b",
                      "label": {
                          "zh_Hans": "Hermes 2 Pro Llama 3 8B",
                          "en_US": "Hermes 2 Pro Llama 3 8B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0014",
                          "output": "0.0014",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "sao10k/l3-70b-euryale-v2.1",
                      "label": {
                          "zh_Hans": "L3 70B Euryale V2.1",
                          "en_US": "L3 70B Euryale V2.1"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0148",
                          "output": "0.0148",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "sao10k/l3-8b-lunaris",
                      "label": {
                          "zh_Hans": "Sao10k L3 8B Lunaris",
                          "en_US": "Sao10k L3 8B Lunaris"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0005",
                          "output": "0.0005",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "Sao10K/L3-8B-Stheno-v3.2",
                      "label": {
                          "zh_Hans": "L3 8B Stheno V3.2",
                          "en_US": "L3 8B Stheno V3.2"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0005",
                          "output": "0.0005",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "sao10k/l31-70b-euryale-v2.2",
                      "label": {
                          "zh_Hans": "L31 70B Euryale V2.2",
                          "en_US": "L31 70B Euryale V2.2"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0148",
                          "output": "0.0148",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta-llama/llama-3-70b-instruct",
                      "label": {
                          "zh_Hans": "Llama3 70b Instruct",
                          "en_US": "Llama3 70b Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0051",
                          "output": "0.0074",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta-llama/llama-3-8b-instruct",
                      "label": {
                          "zh_Hans": "Llama 3 8B Instruct",
                          "en_US": "Llama 3 8B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0004",
                          "output": "0.0004",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta-llama/llama-3.1-70b-instruct",
                      "label": {
                          "zh_Hans": "Llama 3.1 70B Instruct",
                          "en_US": "Llama 3.1 70B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0034",
                          "output": "0.0039",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta-llama/llama-3.1-8b-instruct-bf16",
                      "label": {
                          "zh_Hans": "Llama 3.1 8B Instruct BF16",
                          "en_US": "Llama 3.1 8B Instruct BF16"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0006",
                          "output": "0.0006",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta-llama/llama-3.1-8b-instruct-max",
                      "label": {
                          "zh_Hans": "Llama3.1 8B Instruct Max",
                          "en_US": "Llama3.1 8B Instruct Max"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16384
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0005",
                          "output": "0.0005",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta-llama/llama-3.1-8b-instruct",
                      "label": {
                          "zh_Hans": "Llama 3.1 8B Instruct",
                          "en_US": "Llama 3.1 8B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16384
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0005",
                          "output": "0.0005",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta-llama/llama-3.2-11b-vision-instruct",
                      "label": {
                          "zh_Hans": "Llama 3.2 11B Vision Instruct",
                          "en_US": "Llama 3.2 11B Vision Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0006",
                          "output": "0.0006",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta-llama/llama-3.2-1b-instruct",
                      "label": {
                          "zh_Hans": "Llama 3.2 1B Instruct",
                          "en_US": "Llama 3.2 1B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0002",
                          "output": "0.0002",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta-llama/llama-3.2-3b-instruct",
                      "label": {
                          "zh_Hans": "Llama 3.2 3B Instruct",
                          "en_US": "Llama 3.2 3B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0003",
                          "output": "0.0005",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta-llama/llama-3.3-70b-instruct",
                      "label": {
                          "zh_Hans": "Llama 3.3 70B Instruct",
                          "en_US": "Llama 3.3 70B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0039",
                          "output": "0.0039",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "sophosympatheia/midnight-rose-70b",
                      "label": {
                          "zh_Hans": "Midnight Rose 70B",
                          "en_US": "Midnight Rose 70B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.008",
                          "output": "0.008",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "mistralai/mistral-7b-instruct",
                      "label": {
                          "zh_Hans": "Mistral 7B Instruct",
                          "en_US": "Mistral 7B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.00059",
                          "output": "0.00059",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "mistralai/mistral-nemo",
                      "label": {
                          "zh_Hans": "Mistral Nemo",
                          "en_US": "Mistral Nemo"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0017",
                          "output": "0.0017",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gryphe/mythomax-l2-13b",
                      "label": {
                          "zh_Hans": "Mythomax L2 13B",
                          "en_US": "Mythomax L2 13B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0009",
                          "output": "0.0009",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "nousresearch/nous-hermes-llama2-13b",
                      "label": {
                          "zh_Hans": "Nous Hermes Llama2 13B",
                          "en_US": "Nous Hermes Llama2 13B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0017",
                          "output": "0.0017",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "openchat/openchat-7b",
                      "label": {
                          "zh_Hans": "OpenChat 7B",
                          "en_US": "OpenChat 7B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0006",
                          "output": "0.0006",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "teknium/openhermes-2.5-mistral-7b",
                      "label": {
                          "zh_Hans": "Openhermes2.5 Mistral 7B",
                          "en_US": "Openhermes2.5 Mistral 7B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0017",
                          "output": "0.0017",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "qwen/qwen-2-7b-instruct",
                      "label": {
                          "zh_Hans": "Qwen 2 7B Instruct",
                          "en_US": "Qwen 2 7B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.00054",
                          "output": "0.00054",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "qwen/qwen-2-vl-72b-instruct",
                      "label": {
                          "zh_Hans": "Qwen 2 VL 72B Instruct",
                          "en_US": "Qwen 2 VL 72B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0045",
                          "output": "0.0045",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "qwen/qwen-2.5-72b-instruct",
                      "label": {
                          "zh_Hans": "Qwen 2.5 72B Instruct",
                          "en_US": "Qwen 2.5 72B Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0038",
                          "output": "0.004",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "microsoft/wizardlm-2-8x22b",
                      "label": {
                          "zh_Hans": "Wizardlm 2 8x22B",
                          "en_US": "Wizardlm 2 8x22B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 65535
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.0062",
                          "output": "0.0062",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  }
              ],
              "provider": "novita",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm"
              ]
          }
      },
      {
          "version": "0.0.3",
          "type": "plugin",
          "author": "ssrag",
          "name": "aihubmix",
          "label": {
              "en_US": "Aihubmix",
              "ja_JP": "Aihubmix",
              "zh_Hans": "Aihubmix",
              "pt_BR": "Aihubmix"
          },
          "description": {
              "en_US": "One Gateway, Infinite Models",
              "ja_JP": "One Gateway, Infinite Models",
              "zh_Hans": "一个接口，无限模型",
              "pt_BR": "One Gateway, Infinite Models"
          },
          "icon": "icon.svg",
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "text_embedding": true,
                      "rerank": true,
                      "tts": true,
                      "speech2text": true,
                      "moderation": false
                  }
              }
          },
          "plugins": {
              "models": [
                  "provider/aihubmix.yaml"
              ]
          },
          "meta": {
              "version": "0.0.1",
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "language": "python",
                  "version": "3.12",
                  "entrypoint": "main"
              }
          },
          "created_at": "2025-05-15T02:27:12.287187+08:00",
          "verified": false,
          "model": {
              "provider": "aihubmix",
              "label": {
                  "en_US": "Aihubmix"
              },
              "description": {
                  "en_US": "Models provided by Aihubmix.",
                  "zh_Hans": "Aihubmix 提供的模型。"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "background": "#E5E7EB",
              "help": {
                  "title": {
                      "en_US": "Get your API Key from Aihubmix",
                      "zh_Hans": "从 Aihubmix 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://aihubmix.com/token"
                  }
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding",
                  "rerank",
                  "speech2text",
                  "tts"
              ],
              "configurate_methods": [
                  "predefined-model",
                  "customizable-model"
              ],
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "variable": "api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "type": "secret-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Key",
                              "en_US": "Enter your API Key"
                          }
                      }
                  ]
              },
              "model_credential_schema": {
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  },
                  "credential_form_schemas": [
                      {
                          "variable": "api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "type": "secret-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Key",
                              "en_US": "Enter your API Key"
                          }
                      },
                      {
                          "variable": "mode",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "en_US": "Completion mode"
                          },
                          "type": "select",
                          "required": false,
                          "default": "chat",
                          "placeholder": {
                              "zh_Hans": "选择对话类型",
                              "en_US": "Select completion mode"
                          },
                          "options": [
                              {
                                  "value": "completion",
                                  "label": {
                                      "en_US": "Completion",
                                      "zh_Hans": "补全"
                                  }
                              },
                              {
                                  "value": "chat",
                                  "label": {
                                      "en_US": "Chat",
                                      "zh_Hans": "对话"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "context_size",
                          "label": {
                              "zh_Hans": "模型上下文长度",
                              "en_US": "Model context size"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "type": "text-input",
                          "default": "4096",
                          "placeholder": {
                              "zh_Hans": "在此输入您的模型上下文长度",
                              "en_US": "Enter your Model context size"
                          }
                      },
                      {
                          "variable": "context_size",
                          "label": {
                              "zh_Hans": "模型上下文长度",
                              "en_US": "Model context size"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "text-embedding"
                              }
                          ],
                          "type": "text-input",
                          "default": "4096",
                          "placeholder": {
                              "zh_Hans": "在此输入您的模型上下文长度",
                              "en_US": "Enter your Model context size"
                          }
                      },
                      {
                          "variable": "context_size",
                          "label": {
                              "zh_Hans": "模型上下文长度",
                              "en_US": "Model context size"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "rerank"
                              }
                          ],
                          "type": "text-input",
                          "default": "4096",
                          "placeholder": {
                              "zh_Hans": "在此输入您的模型上下文长度",
                              "en_US": "Enter your Model context size"
                          }
                      },
                      {
                          "variable": "max_tokens_to_sample",
                          "label": {
                              "zh_Hans": "最大 token 上限",
                              "en_US": "Upper bound for max tokens"
                          },
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "default": "4096",
                          "type": "text-input"
                      },
                      {
                          "variable": "agent_though_support",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "en_US": "Agent Thought"
                          },
                          "type": "select",
                          "required": false,
                          "default": "supported",
                          "options": [
                              {
                                  "value": "supported",
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  }
                              },
                              {
                                  "value": "not_supported",
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "function_calling_type",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "en_US": "Function calling"
                          },
                          "type": "select",
                          "required": false,
                          "default": "function_call",
                          "options": [
                              {
                                  "value": "function_call",
                                  "label": {
                                      "en_US": "Function Call",
                                      "zh_Hans": "Function Call"
                                  }
                              },
                              {
                                  "value": "tool_call",
                                  "label": {
                                      "en_US": "Tool Call",
                                      "zh_Hans": "Tool Call"
                                  }
                              },
                              {
                                  "value": "no_call",
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "stream_function_calling",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "en_US": "Stream function calling"
                          },
                          "type": "select",
                          "required": false,
                          "default": "supported",
                          "options": [
                              {
                                  "value": "supported",
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  }
                              },
                              {
                                  "value": "not_supported",
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "vision_support",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "zh_Hans": "Vision 支持",
                              "en_US": "Vision Support"
                          },
                          "type": "select",
                          "required": false,
                          "default": "support",
                          "options": [
                              {
                                  "value": "support",
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  }
                              },
                              {
                                  "value": "no_support",
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "structured_output_support",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "en_US": "Structured Output"
                          },
                          "type": "select",
                          "required": false,
                          "default": "supported",
                          "options": [
                              {
                                  "value": "supported",
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  }
                              },
                              {
                                  "value": "not_supported",
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "stream_mode_delimiter",
                          "label": {
                              "zh_Hans": "流模式返回结果的分隔符",
                              "en_US": "Delimiter for streaming results"
                          },
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "default": "\\n\\n",
                          "type": "text-input"
                      },
                      {
                          "variable": "voices",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "tts"
                              }
                          ],
                          "label": {
                              "en_US": "Available Voices (comma-separated)",
                              "zh_Hans": "可用声音（用英文逗号分隔）"
                          },
                          "type": "text-input",
                          "required": false,
                          "default": "alloy",
                          "placeholder": {
                              "en_US": "alloy,echo,fable,onyx,nova,shimmer",
                              "zh_Hans": "alloy,echo,fable,onyx,nova,shimmer"
                          },
                          "help": {
                              "en_US": "List voice names separated by commas. First voice will be used as default.",
                              "zh_Hans": "用英文逗号分隔的声音列表。第一个声音将作为默认值。"
                          }
                      }
                  ]
              },
              "models": [
                  {
                      "model": "claude-3-5-haiku-20241022",
                      "label": {
                          "en_US": "claude-3-5-haiku-20241022"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "1.10",
                          "output": "5.50",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "claude-3-5-sonnet-20240620",
                      "label": {
                          "en_US": "claude-3-5-sonnet-20240620"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "3.30",
                          "output": "16.50",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "claude-3-5-sonnet-20241022",
                      "label": {
                          "en_US": "claude-3-5-sonnet-20241022"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "3.30",
                          "output": "16.50",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "claude-3-7-sonnet-20250219",
                      "label": {
                          "en_US": "claude-3-7-sonnet-20250219"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "thinking",
                              "label": {
                                  "zh_Hans": "推理模式",
                                  "en_US": "Thinking Mode"
                              },
                              "type": "boolean",
                              "default": false,
                              "required": false,
                              "help": {
                                  "zh_Hans": "控制模型的推理能力。启用时，temperature、top_p和top_k将被禁用。",
                                  "en_US": "Controls the model's thinking capability. When enabled, temperature, top_p and top_k will be disabled."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "label": {
                                  "zh_Hans": "推理预算",
                                  "en_US": "Thinking Budget"
                              },
                              "type": "int",
                              "default": 1024,
                              "min": 0,
                              "max": 128000,
                              "required": false,
                              "help": {
                                  "zh_Hans": "推理的预算限制（最小1024），必须小于max_tokens。仅在推理模式启用时可用。",
                                  "en_US": "Budget limit for thinking (minimum 1024), must be less than max_tokens. Only available when thinking mode is enabled."
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 64000,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "extended_output",
                              "label": {
                                  "zh_Hans": "扩展输出",
                                  "en_US": "Extended Output"
                              },
                              "type": "boolean",
                              "default": false,
                              "help": {
                                  "zh_Hans": "启用长达128K标记的输出能力。",
                                  "en_US": "Enable capability for up to 128K output tokens."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "3.30",
                          "output": "16.50",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "claude-3-opus-20240229",
                      "label": {
                          "en_US": "claude-3-opus-20240229"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 4096,
                              "min": 1,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "16.80",
                          "output": "84.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "claude-opus-4-20250514",
                      "label": {
                          "en_US": "claude-opus-4-20250514"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "thinking",
                              "label": {
                                  "zh_Hans": "推理模式",
                                  "en_US": "Thinking Mode"
                              },
                              "type": "boolean",
                              "default": false,
                              "required": false,
                              "help": {
                                  "zh_Hans": "控制模型的推理能力。启用时，temperature、top_p和top_k将被禁用。",
                                  "en_US": "Controls the model's thinking capability. When enabled, temperature, top_p and top_k will be disabled."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "label": {
                                  "zh_Hans": "推理预算",
                                  "en_US": "Thinking Budget"
                              },
                              "type": "int",
                              "default": 1024,
                              "min": 0,
                              "max": 32000,
                              "required": false,
                              "help": {
                                  "zh_Hans": "推理的预算限制（最小1024），必须小于max_tokens。仅在推理模式启用时可用。",
                                  "en_US": "Budget limit for thinking (minimum 1024), must be less than max_tokens. Only available when thinking mode is enabled."
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 32000,
                              "min": 1,
                              "max": 32000
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "16.80",
                          "output": "84.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "claude-sonnet-4-20250514",
                      "label": {
                          "en_US": "claude-sonnet-4-20250514"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "thinking",
                              "label": {
                                  "zh_Hans": "推理模式",
                                  "en_US": "Thinking Mode"
                              },
                              "type": "boolean",
                              "default": false,
                              "required": false,
                              "help": {
                                  "zh_Hans": "控制模型的推理能力。启用时，temperature、top_p和top_k将被禁用。",
                                  "en_US": "Controls the model's thinking capability. When enabled, temperature, top_p and top_k will be disabled."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "label": {
                                  "zh_Hans": "推理预算",
                                  "en_US": "Thinking Budget"
                              },
                              "type": "int",
                              "default": 1024,
                              "min": 0,
                              "max": 64000,
                              "required": false,
                              "help": {
                                  "zh_Hans": "推理的预算限制（最小1024），必须小于max_tokens。仅在推理模式启用时可用。",
                                  "en_US": "Budget limit for thinking (minimum 1024), must be less than max_tokens. Only available when thinking mode is enabled."
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 64000,
                              "min": 1,
                              "max": 64000
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "3.30",
                          "output": "16.50",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "aihubmix-DeepSeek-R1",
                      "label": {
                          "en_US": "aihubmix-DeepSeek-R1"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 16384,
                              "default": 16384
                          }
                      ],
                      "pricing": {
                          "input": "1.40",
                          "output": "5.60",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "DeepSeek-R1",
                      "label": {
                          "en_US": "DeepSeek-R1"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 16384,
                              "default": 16384
                          }
                      ],
                      "pricing": {
                          "input": "0.546",
                          "output": "2.184",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "deepseek-reasoner",
                      "label": {
                          "en_US": "deepseek-reasoner"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.60",
                          "output": "2.40",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "deepseek-ai/DeepSeek-V3-0324",
                      "label": {
                          "en_US": "deepseek-ai/DeepSeek-V3-0324"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 16384
                          }
                      ],
                      "pricing": {
                          "input": "0.2",
                          "output": "0.8",
                          "unit": "0.00001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "DeepSeek-V3",
                      "label": {
                          "en_US": "DeepSeek-V3"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 4096,
                              "min": 1,
                              "max": 8192,
                              "help": {
                                  "zh_Hans": "指定生成结果长度的上限。如果生成结果截断，可以调大该参数。",
                                  "en_US": "Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.272",
                          "output": "1.088",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.0-flash",
                      "label": {
                          "en_US": "gemini-2.0-flash"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document",
                          "video",
                          "audio"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 8192
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          },
                          {
                              "name": "grounding",
                              "label": {
                                  "en_US": "Grounding",
                                  "ja_JP": "Grounding"
                              },
                              "type": "boolean",
                              "help": {
                                  "en_US": "ensures responses are based on Google Search.",
                                  "ja_JP": "Google検索に基づいた応答をします。"
                              },
                              "required": true,
                              "default": false
                          }
                      ],
                      "pricing": {
                          "input": "0.1",
                          "output": "0.4",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.5-flash-preview-04-17-nothink",
                      "label": {
                          "en_US": "gemini-2.5-flash-preview-04-17-nothink"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 65536
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.15",
                          "output": "0.6",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.5-flash-preview-04-17",
                      "label": {
                          "en_US": "gemini-2.5-flash-preview-04-17"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 65536
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.15",
                          "output": "3.45",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.5-pro-preview-03-25-search",
                      "label": {
                          "en_US": "gemini-2.5-pro-preview-03-25-search"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 65536
                          },
                          {
                              "name": "grounding",
                              "label": {
                                  "en_US": "Grounding",
                                  "zh_Hans": "事实核查",
                                  "ja_JP": "事実チェック"
                              },
                              "type": "boolean",
                              "help": {
                                  "en_US": "Grounding with Google Search",
                                  "zh_Hans": "Google 事实核查",
                                  "ja_JP": "Google検索に基づいた応答をします。"
                              },
                              "required": true,
                              "default": false
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "1.25",
                          "output": "10.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.5-pro-preview-03-25",
                      "label": {
                          "en_US": "gemini-2.5-pro-preview-03-25"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 8192,
                              "min": 1,
                              "max": 65536
                          },
                          {
                              "name": "grounding",
                              "label": {
                                  "en_US": "Grounding",
                                  "zh_Hans": "事实核查",
                                  "ja_JP": "事実チェック"
                              },
                              "type": "boolean",
                              "help": {
                                  "en_US": "Grounding with Google Search",
                                  "zh_Hans": "Google 事实核查",
                                  "ja_JP": "Google検索に基づいた応答をします。"
                              },
                              "required": true,
                              "default": false
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "1.25",
                          "output": "10.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.5-pro-preview-05-06-search",
                      "label": {
                          "en_US": "gemini-2.5-pro-preview-05-06-search"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 65535,
                              "min": 1,
                              "max": 65536
                          },
                          {
                              "name": "grounding",
                              "label": {
                                  "en_US": "Grounding",
                                  "zh_Hans": "事实核查",
                                  "ja_JP": "事実チェック"
                              },
                              "type": "boolean",
                              "help": {
                                  "en_US": "Grounding with Google Search",
                                  "zh_Hans": "Google 事实核查",
                                  "ja_JP": "Google検索に基づいた応答をします。"
                              },
                              "required": true,
                              "default": false
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "1.25",
                          "output": "10.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gemini-2.5-pro-preview-05-06",
                      "label": {
                          "en_US": "gemini-2.5-pro-preview-05-06"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call",
                          "stream-tool-call",
                          "document"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1048576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "min": 0,
                              "max": 2
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_output_tokens",
                              "use_template": "max_tokens",
                              "default": 65535,
                              "min": 1,
                              "max": 65536
                          },
                          {
                              "name": "grounding",
                              "label": {
                                  "en_US": "Grounding",
                                  "zh_Hans": "事实核查",
                                  "ja_JP": "事実チェック"
                              },
                              "type": "boolean",
                              "help": {
                                  "en_US": "Grounding with Google Search",
                                  "zh_Hans": "Google 事实核查",
                                  "ja_JP": "Google検索に基づいた応答をします。"
                              },
                              "required": true,
                              "default": false
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "1.25",
                          "output": "10.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4.1-mini",
                      "label": {
                          "en_US": "gpt-4.1-mini"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1047576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 32768
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.40",
                          "output": "1.60",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4.1-nano",
                      "label": {
                          "en_US": "gpt-4.1-nano"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1047576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 32768
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "0.10",
                          "output": "0.40",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4.1",
                      "label": {
                          "en_US": "gpt-4.1"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1047576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 32768
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "2.00",
                          "output": "8.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4.5-preview",
                      "label": {
                          "en_US": "gpt-4.5-preview"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1047576
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 32768
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "75.00",
                          "output": "150.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "aihubmix-Llama-3-1-405B-Instruct",
                      "label": {
                          "en_US": "aihubmix-Llama-3-1-405B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": null,
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": null,
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 4028,
                              "min": 1,
                              "max": 4028
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "5.00",
                          "output": "15.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "aihubmix-Llama-3-3-70B-Instruct",
                      "label": {
                          "en_US": "aihubmix-Llama-3-3-70B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": null,
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": null,
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 4028,
                              "min": 1,
                              "max": 4028
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.80",
                          "output": "0.80",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "chutesai/Llama-4-Maverick-17B-128E-Instruct-FP8",
                      "label": {
                          "en_US": "chutesai/Llama-4-Maverick-17B-128E-Instruct-FP8"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": null,
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": null,
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 4028,
                              "min": 1,
                              "max": 4028
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.25",
                          "output": "0.25",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta-llama/llama-4-scout-17b-16e-instruct",
                      "label": {
                          "en_US": "meta-llama/llama-4-scout-17b-16e-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": null,
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": null,
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 4028,
                              "min": 1,
                              "max": 4028
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.20",
                          "output": "0.20",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "chutesai/Llama-4-Scout-17B-16E-Instruct",
                      "label": {
                          "en_US": "chutesai/Llama-4-Scout-17B-16E-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision",
                          "tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "label": {
                                  "zh_Hans": null,
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": null,
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "required": true,
                              "default": 4028,
                              "min": 1,
                              "max": 4028
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.20",
                          "output": "0.20",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "o1-preview",
                      "label": {
                          "en_US": "o1-preview"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 32768,
                              "min": 1,
                              "max": 32768
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "15.00",
                          "output": "60.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "o1-pro",
                      "label": {
                          "en_US": "o1-pro"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 50000,
                              "min": 1,
                              "max": 50000
                          },
                          {
                              "name": "reasoning_effort",
                              "label": {
                                  "zh_Hans": "推理工作",
                                  "en_US": "reasoning_effort"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "限制推理模型的推理工作",
                                  "en_US": "constrains effort on reasoning for reasoning models"
                              },
                              "required": false,
                              "options": [
                                  "low",
                                  "medium",
                                  "high"
                              ]
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "15.00",
                          "output": "60.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "o1",
                      "label": {
                          "en_US": "o1"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 50000,
                              "min": 1,
                              "max": 50000
                          },
                          {
                              "name": "reasoning_effort",
                              "label": {
                                  "zh_Hans": "推理工作",
                                  "en_US": "reasoning_effort"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "限制推理模型的推理工作",
                                  "en_US": "constrains effort on reasoning for reasoning models"
                              },
                              "required": false,
                              "options": [
                                  "low",
                                  "medium",
                                  "high"
                              ]
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "15.00",
                          "output": "60.00",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "o3-mini",
                      "label": {
                          "en_US": "o3-mini"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 100000,
                              "min": 1,
                              "max": 100000
                          },
                          {
                              "name": "reasoning_effort",
                              "label": {
                                  "zh_Hans": "推理工作",
                                  "en_US": "reasoning_effort"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "限制推理模型的推理工作",
                                  "en_US": "constrains effort on reasoning for reasoning models"
                              },
                              "required": false,
                              "options": [
                                  "low",
                                  "medium",
                                  "high"
                              ]
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "1.10",
                          "output": "4.40",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "o3",
                      "label": {
                          "en_US": "o3"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 100000,
                              "min": 1,
                              "max": 100000
                          },
                          {
                              "name": "reasoning_effort",
                              "label": {
                                  "zh_Hans": "推理工作",
                                  "en_US": "reasoning_effort"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "限制推理模型的推理工作",
                                  "en_US": "constrains effort on reasoning for reasoning models"
                              },
                              "required": false,
                              "options": [
                                  "low",
                                  "medium",
                                  "high"
                              ]
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "10.0",
                          "output": "40.0",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "o4-mini",
                      "label": {
                          "zh_Hans": "o4-mini",
                          "en_US": "o4-mini"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 100000,
                              "min": 1,
                              "max": 100000
                          },
                          {
                              "name": "reasoning_effort",
                              "label": {
                                  "zh_Hans": "推理工作",
                                  "en_US": "reasoning_effort"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "限制推理模型的推理工作",
                                  "en_US": "constrains effort on reasoning for reasoning models"
                              },
                              "required": false,
                              "options": [
                                  "low",
                                  "medium",
                                  "high"
                              ]
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "response_format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object",
                                  "json_schema"
                              ]
                          },
                          {
                              "name": "json_schema",
                              "use_template": "json_schema"
                          }
                      ],
                      "pricing": {
                          "input": "1.10",
                          "output": "4.40",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-VL-32B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-VL-32B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.24",
                          "output": "0.24",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "Qwen/Qwen2.5-VL-72B-Instruct",
                      "label": {
                          "en_US": "Qwen/Qwen2.5-VL-72B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 2000,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "seed",
                              "required": false,
                              "type": "int",
                              "default": 1234,
                              "label": {
                                  "zh_Hans": "随机种子",
                                  "en_US": "Random seed"
                              },
                              "help": {
                                  "zh_Hans": "生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
                                  "en_US": "The random number seed used when generating, the user controls the randomness of the content generated by the model. Supports unsigned 64-bit integers, default value is 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "zh_Hans": "重复惩罚",
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          },
                          {
                              "name": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式",
                                  "en_US": "specifying the format that the model must output"
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "0.5",
                          "output": "0.5",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-14B",
                      "label": {
                          "zh_Hans": "Qwen/Qwen3-14B",
                          "en_US": "Qwen/Qwen3-14B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.5",
                          "output": "0.5",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-235B-A22B",
                      "label": {
                          "en_US": "Qwen/Qwen3-235B-A22B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "2.2",
                          "output": "2.2",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-30B-A3B",
                      "label": {
                          "zh_Hans": "Qwen/Qwen3-30B-A3B",
                          "en_US": "Qwen/Qwen3-30B-A3B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "1",
                          "output": "1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-32B",
                      "label": {
                          "zh_Hans": "Qwen/Qwen3-32B",
                          "en_US": "Qwen/Qwen3-32B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.5",
                          "output": "0.5",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "Qwen/Qwen3-8B",
                      "label": {
                          "zh_Hans": "Qwen/Qwen3-8B",
                          "en_US": "Qwen/Qwen3-8B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 8192
                          },
                          {
                              "name": "enable_thinking",
                              "required": false,
                              "type": "boolean",
                              "default": true,
                              "label": {
                                  "zh_Hans": "思考模式",
                                  "en_US": "Thinking mode"
                              },
                              "help": {
                                  "zh_Hans": "是否开启思考模式。",
                                  "en_US": "Whether to enable thinking mode."
                              }
                          },
                          {
                              "name": "thinking_budget",
                              "required": false,
                              "type": "int",
                              "default": 512,
                              "min": 1,
                              "max": 8192,
                              "label": {
                                  "zh_Hans": "思考长度限制",
                                  "en_US": "Thinking budget"
                              },
                              "help": {
                                  "zh_Hans": "思考过程的最大长度，只在思考模式为true时生效。",
                                  "en_US": "The maximum length of the thinking process, only effective when thinking mode is true."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.2",
                          "output": "0.2",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "jina-colbert-v2",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 8192
                      }
                  },
                  {
                      "model": "jina-reranker-m0",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 10240
                      }
                  },
                  {
                      "model": "distil-whisper-large-v3-en",
                      "model_type": "speech2text",
                      "model_properties": {
                          "file_upload_limit": 1,
                          "supported_file_extensions": "flac,mp3,mp4,mpeg,mpga,m4a,ogg,wav,webm"
                      }
                  },
                  {
                      "model": "whisper-1",
                      "model_type": "speech2text",
                      "model_properties": {
                          "file_upload_limit": 25,
                          "supported_file_extensions": "flac,mp3,mp4,mpeg,mpga,m4a,ogg,wav,webm"
                      }
                  },
                  {
                      "model": "whisper-large-v3",
                      "model_type": "speech2text",
                      "model_properties": {
                          "file_upload_limit": 1,
                          "supported_file_extensions": "flac,mp3,mp4,mpeg,mpga,m4a,ogg,wav,webm"
                      }
                  },
                  {
                      "model": "gemini-embedding-exp-03-07",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 2048
                      },
                      "pricing": {
                          "input": "0.02",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "jina-clip-v2",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 2048
                      },
                      "pricing": {
                          "input": "0.18",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "jina-colbert-v2",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 2048
                      },
                      "pricing": {
                          "input": "0.18",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "jina-embeddings-v2-base-code",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 2048
                      },
                      "pricing": {
                          "input": "0.18",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "jina-embeddings-v3",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8192,
                          "max_chunks": 2048
                      },
                      "pricing": {
                          "input": "0.18",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "text-embedding-3-large",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8191,
                          "max_chunks": 32
                      },
                      "pricing": {
                          "input": "0.13",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "text-embedding-3-small",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8191,
                          "max_chunks": 32
                      },
                      "pricing": {
                          "input": "0.002",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "text-embedding-ada-002",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 8097,
                          "max_chunks": 32
                      },
                      "pricing": {
                          "input": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "gpt-4o-mini-tts",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "alloy",
                          "voices": [
                              {
                                  "mode": "alloy",
                                  "name": "Alloy",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "ash",
                                  "name": "Ash",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "ballad",
                                  "name": "Ballad",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "coral",
                                  "name": "Coral",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "echo",
                                  "name": "Echo",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "fable",
                                  "name": "Fable",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "onyx",
                                  "name": "Onyx",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "nova",
                                  "name": "Nova",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "sage",
                                  "name": "Sage",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "shimmer",
                                  "name": "Shimmer",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "verse",
                                  "name": "Verse",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              }
                          ],
                          "word_limit": 3500,
                          "audio_type": "mp3",
                          "max_workers": 5
                      },
                      "pricing": {
                          "input": "0.012",
                          "output": "0",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "tts-1-hd",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "alloy",
                          "voices": [
                              {
                                  "mode": "alloy",
                                  "name": "Alloy",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "ash",
                                  "name": "Ash",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "ballad",
                                  "name": "Ballad",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "coral",
                                  "name": "Coral",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "echo",
                                  "name": "Echo",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "fable",
                                  "name": "Fable",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "onyx",
                                  "name": "Onyx",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "nova",
                                  "name": "Nova",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "sage",
                                  "name": "Sage",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "shimmer",
                                  "name": "Shimmer",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "verse",
                                  "name": "Verse",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              }
                          ],
                          "word_limit": 3500,
                          "audio_type": "mp3",
                          "max_workers": 5
                      },
                      "pricing": {
                          "input": "0.03",
                          "output": "0",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "tts-1",
                      "model_type": "tts",
                      "model_properties": {
                          "default_voice": "alloy",
                          "voices": [
                              {
                                  "mode": "alloy",
                                  "name": "Alloy",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "ash",
                                  "name": "Ash",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "ballad",
                                  "name": "Ballad",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "coral",
                                  "name": "Coral",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "echo",
                                  "name": "Echo",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "fable",
                                  "name": "Fable",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "onyx",
                                  "name": "Onyx",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "nova",
                                  "name": "Nova",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "sage",
                                  "name": "Sage",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "shimmer",
                                  "name": "Shimmer",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              },
                              {
                                  "mode": "verse",
                                  "name": "Verse",
                                  "language": [
                                      "zh-Hans",
                                      "en-US",
                                      "de-DE",
                                      "fr-FR",
                                      "es-ES",
                                      "it-IT",
                                      "th-TH",
                                      "id-ID"
                                  ]
                              }
                          ],
                          "word_limit": 3500,
                          "audio_type": "mp3",
                          "max_workers": 5
                      },
                      "pricing": {
                          "input": "0.015",
                          "output": "0",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  }
              ],
              "extra": {
                  "python": {
                      "provider_source": "provider/aihubmix.py",
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/rerank/rerank.py",
                          "models/text_embedding/text_embedding.py",
                          "models/tts/tts.py",
                          "models/speech2text/speech2text.py"
                      ]
                  }
              }
          }
      },
      {
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "maas",
          "author": "ssrag",
          "label": {
              "en_US": "Huawei Cloud MaaS",
              "zh_Hans": "华为云MaaS平台"
          },
          "description": {
              "en_US": "Huawei Cloud MaaS provides access to various models (LLMs), configurable via model name, API key, and other parameters.",
              "zh_Hans": "华为云MaaS平台提供对各种模型（LLM）的访问，可通过模型名称、API密钥和其他参数进行配置。"
          },
          "icon": "maas_square.svg",
          "plugins": {
              "models": [
                  "provider/maas.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": false
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.1",
          "created_at": "2025-06-04T12:32:17.824356+08:00",
          "model": {
              "background": "#ffecff",
              "configurate_methods": [
                  "predefined-model",
                  "customizable-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py"
                      ],
                      "provider_source": "provider/maas.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API Key from Huawei Cloud MaaS",
                      "zh_Hans": "从 华为云MaaS平台 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://console.huaweicloud.com/modelarts/?locale=zh-cn&region=cn-southwest-2#/model-studio/authmanage"
                  }
              },
              "icon_large": {
                  "en_US": "maas_square.svg"
              },
              "icon_small": {
                  "en_US": "maas_square.svg"
              },
              "label": {
                  "en_US": "Huawei Cloud MaaS",
                  "zh_Hans": "华为云MaaS平台"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "Custom API endpoint URL",
                              "zh_Hans": "自定义 API endpoint 地址"
                          },
                          "placeholder": {
                              "en_US": "Base URL, e.g. https://api.modelarts-maas.com/v1 or https://{region}.modelarts-maas.com/v1/infers/{service-id}/v1",
                              "zh_Hans": "Base URL, e.g. https://api.modelarts-maas.com/v1 or https://{region}.modelarts-maas.com/v1/infers/{service-id}/v1"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "endpoint_url"
                      },
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Model context size",
                              "zh_Hans": "模型上下文长度"
                          },
                          "placeholder": {
                              "en_US": "Enter your Model context size",
                              "zh_Hans": "在此输入您的模型上下文长度"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "context_size"
                      },
                      {
                          "default": "4096",
                          "label": {
                              "en_US": "Upper bound for max tokens",
                              "zh_Hans": "最大 token 上限"
                          },
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "text-input",
                          "variable": "max_tokens"
                      },
                      {
                          "default": "no_call",
                          "label": {
                              "en_US": "Function calling"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  },
                                  "value": "no_call"
                              },
                              {
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  },
                                  "value": "function_call"
                              }
                          ],
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "select",
                          "variable": "function_calling_type"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  }
              },
              "models": [
                  {
                      "model": "deepseek-r1-250528",
                      "label": {
                          "zh_Hans": "DeepSeek-R1-250528",
                          "en_US": "DeepSeek-R1-250528"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 16384,
                              "default": 16384
                          }
                      ],
                      "pricing": {
                          "input": "4",
                          "output": "16",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "DeepSeek-R1",
                      "label": {
                          "zh_Hans": "DeepSeek-R1",
                          "en_US": "DeepSeek-R1"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 16384,
                              "default": 16384
                          }
                      ],
                      "pricing": {
                          "input": "4",
                          "output": "16",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "DeepSeek-V3",
                      "label": {
                          "zh_Hans": "DeepSeek-V3",
                          "en_US": "DeepSeek-V3"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 16384,
                              "default": 16384
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "8",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen3-235b-a22b",
                      "label": {
                          "zh_Hans": "Qwen3-235B-A22B",
                          "en_US": "Qwen3-235B-A22B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 16384,
                              "default": 16384
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "8",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "qwen3-32b",
                      "label": {
                          "zh_Hans": "Qwen3-32B",
                          "en_US": "Qwen3-32B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 16384,
                              "default": 16384
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "8",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  }
              ],
              "provider": "huaweicloud_maas",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-10-08T19:50:01.848598Z",
          "description": {
              "en_US": "Mixedbread"
          },
          "icon": "icon_s_en.png",
          "label": {
              "en_US": "Mixedbread"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "mixedbread",
          "plugins": {
              "models": [
                  "provider/mixedbread.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "rerank": true,
                      "text_embedding": true
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.4",
          "model": {
              "background": "#EFFDFD",
              "configurate_methods": [
                  "predefined-model"
              ],
              "description": {
                  "en_US": "Embedding and Rerank Model Supported"
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/text_embedding/text_embedding.py",
                          "models/rerank/rerank.py"
                      ],
                      "provider_source": "provider/mixedbread.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API key from Mixedbread AI",
                      "zh_Hans": "从 Mixedbread 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://mixedbread.com/"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.png"
              },
              "icon_small": {
                  "en_US": "icon_s_en.png"
              },
              "label": {
                  "en_US": "Mixedbread"
              },
              "models": [
                  {
                      "model": "mxbai-rerank-large-v1",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 512
                      }
                  },
                  {
                      "model": "mxbai-rerank-large-v2",
                      "model_type": "rerank",
                      "model_properties": {
                          "context_size": 8000
                      }
                  },
                  {
                      "model": "mxbai-embed-2d-large-v1",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 512
                      },
                      "pricing": {
                          "input": "0.0001",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "mxbai-embed-large-v1",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 512
                      },
                      "pricing": {
                          "input": "0.0001",
                          "unit": "0.001",
                          "currency": "USD"
                      }
                  }
              ],
              "provider": "mixedbread",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      }
                  ]
              },
              "supported_model_types": [
                  "text-embedding",
                  "rerank"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-10-10T17:40:27.659686-04:00",
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "upstage"
          },
          "description": {
              "en_US": "Upstage"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.10"
              },
              "version": "0.0.1"
          },
          "name": "upstage",
          "plugins": {
              "models": [
                  "provider/upstage.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": false,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.5",
          "model": {
              "background": "#FFFFF",
              "configurate_methods": [
                  "predefined-model"
              ],
              "description": {
                  "en_US": "Models provided by Upstage, such as Solar-1-mini-chat.",
                  "zh_Hans": "Upstage 提供的模型，例如 Solar-1-mini-chat."
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/text_embedding/text_embedding.py"
                      ],
                      "provider_source": "provider/upstage.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API Key from Upstage",
                      "zh_Hans": "从 Upstage 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://console.upstage.ai/api-keys"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "Upstage"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "upstage_api_key"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  }
              },
              "models": [
                  {
                      "model": "solar-1-mini-chat",
                      "label": {
                          "zh_Hans": "solar-1-mini-chat",
                          "en_US": "solar-1-mini-chat",
                          "ko_KR": "solar-1-mini-chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 32768
                          },
                          {
                              "name": "seed",
                              "label": {
                                  "zh_Hans": "种子",
                                  "en_US": "Seed"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "如果指定，模型将尽最大努力进行确定性采样，使得重复的具有相同种子和参数的请求应该返回相同的结果。不能保证确定性，您应该参考 system_fingerprint 响应参数来监视变化。",
                                  "en_US": "If specified, model will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes in the backend."
                              },
                              "required": false
                          }
                      ],
                      "pricing": {
                          "input": "0.5",
                          "output": "0.5",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "solar-embedding-1-large-passage",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 4000,
                          "max_chunks": 32
                      },
                      "pricing": {
                          "input": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "solar-embedding-1-large-query",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 4000,
                          "max_chunks": 32
                      },
                      "pricing": {
                          "input": "0.1",
                          "unit": "0.000001",
                          "currency": "USD"
                      }
                  }
              ],
              "provider": "upstage",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "upstage_api_key"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "Models provided by OCI, such as Cohere Command R and Cohere Command R+.",
              "zh_Hans": "OCI 提供的模型，例如 Cohere Command R 和 Cohere Command R+。"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "OCIGenerativeAI"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "oci",
          "plugins": {
              "models": [
                  "provider/oci.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.3",
          "model": {
              "background": "#FFFFFF",
              "configurate_methods": [
                  "predefined-model"
              ],
              "description": {
                  "en_US": "Models provided by OCI, such as Cohere Command R and Cohere Command R+.",
                  "zh_Hans": "OCI 提供的模型，例如 Cohere Command R 和 Cohere Command R+。"
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/text_embedding/text_embedding.py"
                      ],
                      "provider_source": "provider/oci.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API Key from OCI",
                      "zh_Hans": "从 OCI 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://docs.cloud.oracle.com/Content/API/Concepts/sdkconfig.htm"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "OCIGenerativeAI"
              },
              "models": [
                  {
                      "model": "cohere.command-r-08-2024",
                      "label": {
                          "en_US": "cohere.command-r-08-2024 v1.7"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "max": 1.0
                          },
                          {
                              "name": "topP",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "topK",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presencePenalty",
                              "use_template": "presence_penalty",
                              "min": 0,
                              "max": 1,
                              "default": 0
                          },
                          {
                              "name": "frequencyPenalty",
                              "use_template": "frequency_penalty",
                              "min": 0,
                              "max": 1,
                              "default": 0
                          },
                          {
                              "name": "maxTokens",
                              "use_template": "max_tokens",
                              "default": 600,
                              "max": 4000
                          }
                      ],
                      "pricing": {
                          "input": "0.0009",
                          "output": "0.0009",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "cohere.command-r-16k",
                      "label": {
                          "en_US": "cohere.command-r-16k v1.2"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "max": 1.0
                          },
                          {
                              "name": "topP",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "topK",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presencePenalty",
                              "use_template": "presence_penalty",
                              "min": 0,
                              "max": 1,
                              "default": 0
                          },
                          {
                              "name": "frequencyPenalty",
                              "use_template": "frequency_penalty",
                              "min": 0,
                              "max": 1,
                              "default": 0
                          },
                          {
                              "name": "maxTokens",
                              "use_template": "max_tokens",
                              "default": 600,
                              "max": 4000
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.004",
                          "unit": "0.0001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "cohere.command-r-plus-08-2024",
                      "label": {
                          "en_US": "cohere.command-r-plus v1.6"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "max": 1.0
                          },
                          {
                              "name": "topP",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "topK",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presencePenalty",
                              "use_template": "presence_penalty",
                              "min": 0,
                              "max": 1,
                              "default": 0
                          },
                          {
                              "name": "frequencyPenalty",
                              "use_template": "frequency_penalty",
                              "min": 0,
                              "max": 1,
                              "default": 0
                          },
                          {
                              "name": "maxTokens",
                              "use_template": "max_tokens",
                              "default": 600,
                              "max": 4000
                          }
                      ],
                      "pricing": {
                          "input": "0.0156",
                          "output": "0.0156",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "cohere.command-r-plus",
                      "label": {
                          "en_US": "cohere.command-r-plus v1.2"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "max": 1.0
                          },
                          {
                              "name": "topP",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "topK",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presencePenalty",
                              "use_template": "presence_penalty",
                              "min": 0,
                              "max": 1,
                              "default": 0
                          },
                          {
                              "name": "frequencyPenalty",
                              "use_template": "frequency_penalty",
                              "min": 0,
                              "max": 1,
                              "default": 0
                          },
                          {
                              "name": "maxTokens",
                              "use_template": "max_tokens",
                              "default": 600,
                              "max": 4000
                          }
                      ],
                      "pricing": {
                          "input": "0.0219",
                          "output": "0.0219",
                          "unit": "0.0001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "meta.llama-3-70b-instruct",
                      "label": {
                          "zh_Hans": "meta.llama-3-70b-instruct",
                          "en_US": "meta.llama-3-70b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "max": 2.0
                          },
                          {
                              "name": "topP",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "topK",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presencePenalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "frequencyPenalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "maxTokens",
                              "use_template": "max_tokens",
                              "default": 600,
                              "max": 8000
                          }
                      ],
                      "pricing": {
                          "input": "0.015",
                          "output": "0.015",
                          "unit": "0.0001",
                          "currency": "USD"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "meta.llama-3.1-405b-instruct",
                      "label": {
                          "zh_Hans": "meta.llama-3.1-405b-instruct",
                          "en_US": "meta.llama-3.1-405b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "max": 2.0
                          },
                          {
                              "name": "topP",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "topK",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presencePenalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "frequencyPenalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "maxTokens",
                              "use_template": "max_tokens",
                              "default": 600,
                              "max": 4000
                          }
                      ],
                      "pricing": {
                          "input": "0.0267",
                          "output": "0.0267",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta.llama-3.2-90b-vision-instruct",
                      "label": {
                          "zh_Hans": "meta.llama-3.2-90b-vision-instruct",
                          "en_US": "meta.llama-3.2-90b-vision-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "max": 2.0
                          },
                          {
                              "name": "topP",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "topK",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presencePenalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "frequencyPenalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "maxTokens",
                              "use_template": "max_tokens",
                              "default": 600,
                              "max": 4000
                          }
                      ],
                      "pricing": {
                          "input": "0.005",
                          "output": "0.005",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "meta.llama-3.3-70b-instruct",
                      "label": {
                          "zh_Hans": "meta.llama-3.3-70b-instruct",
                          "en_US": "meta.llama-3.3-70b-instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 1,
                              "max": 2.0
                          },
                          {
                              "name": "topP",
                              "use_template": "top_p",
                              "default": 0.75,
                              "min": 0,
                              "max": 1
                          },
                          {
                              "name": "topK",
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "type": "int",
                              "help": {
                                  "zh_Hans": "仅从每个后续标记的前 K 个选项中采样。",
                                  "en_US": "Only sample from the top K options for each subsequent token."
                              },
                              "required": false,
                              "default": 0,
                              "min": 0,
                              "max": 500
                          },
                          {
                              "name": "presencePenalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "frequencyPenalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "maxTokens",
                              "use_template": "max_tokens",
                              "default": 600,
                              "max": 4000
                          }
                      ],
                      "pricing": {
                          "input": "0.0018",
                          "output": "0.0018",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "cohere.embed-english-light-v2.0",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 1024,
                          "max_chunks": 48
                      },
                      "pricing": {
                          "input": "0.001",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "cohere.embed-english-light-v3.0",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 384,
                          "max_chunks": 48
                      },
                      "pricing": {
                          "input": "0.001",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "cohere.embed-english-v3.0",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 1024,
                          "max_chunks": 48
                      },
                      "pricing": {
                          "input": "0.001",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "cohere.embed-multilingual-light-v3.0",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 384,
                          "max_chunks": 48
                      },
                      "pricing": {
                          "input": "0.001",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "cohere.embed-multilingual-v3.0",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 1024,
                          "max_chunks": 48
                      },
                      "pricing": {
                          "input": "0.001",
                          "unit": "0.0001",
                          "currency": "USD"
                      }
                  }
              ],
              "provider": "oci",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "oci api key config file's content"
                          },
                          "placeholder": {
                              "en_US": "Enter your oci api key config file's content(base64.b64encode(\"user_ocid/fingerprint/tenancy_ocid/region/compartment_ocid\".encode('utf-8')))",
                              "zh_Hans": "在此输入您的 oci api key config 文件的内容(base64.b64encode(\"user_ocid/fingerprint/tenancy_ocid/region/compartment_ocid\".encode('utf-8')))"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "oci_config_content"
                      },
                      {
                          "label": {
                              "en_US": "oci api key file's content"
                          },
                          "placeholder": {
                              "en_US": "Enter your oci api key file's content(base64.b64encode(\"pem file content\".encode('utf-8')))",
                              "zh_Hans": "在此输入您的 oci api key 文件的内容(base64.b64encode(\"pem file content\".encode('utf-8')))"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "oci_key_content"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-10-09T15:14:37.903898-04:00",
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "perfxcloud"
          },
          "description": {
              "en_US": "PerfXCloud"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.10"
              },
              "version": "0.0.1"
          },
          "name": "perfxcloud",
          "plugins": {
              "models": [
                  "provider/perfxcloud.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": false,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.5",
          "model": {
              "background": "#e3f0ff",
              "configurate_methods": [
                  "predefined-model"
              ],
              "description": {
                  "en_US": "PerfXCloud (Pengfeng Technology) is an AI development and deployment platform tailored for developers and enterprises, providing reasoning capabilities for multiple models.",
                  "zh_Hans": "PerfXCloud（澎峰科技）为开发者和企业量身打造的AI开发和部署平台，提供多种模型的的推理能力。"
              },
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/text_embedding/text_embedding.py"
                      ],
                      "provider_source": "provider/perfxcloud.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API Key from PerfXCloud",
                      "zh_Hans": "从 PerfXCloud 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://cloud.perfxlab.cn/panel/token"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "PerfXCloud",
                  "zh_Hans": "PerfXCloud"
              },
              "models": [
                  {
                      "model": "chatglm3-6b",
                      "label": {
                          "en_US": "chatglm3-6b"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.5,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 600,
                              "min": 1,
                              "max": 1248,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "deepseek-v2-chat",
                      "label": {
                          "en_US": "deepseek-v2-chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.5,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 600,
                              "min": 1,
                              "max": 1248,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "deepseek-v2-lite-chat",
                      "label": {
                          "en_US": "deepseek-v2-lite-chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2048
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.5,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 600,
                              "min": 1,
                              "max": 1248,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Llama3-Chinese_v2",
                      "label": {
                          "en_US": "Llama3-Chinese_v2"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.5,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 600,
                              "min": 1,
                              "max": 1248,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Meta-Llama-3-70B-Instruct-GPTQ-Int4",
                      "label": {
                          "en_US": "Meta-Llama-3-70B-Instruct-GPTQ-Int4"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1024
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.5,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 600,
                              "min": 1,
                              "max": 1248,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Meta-Llama-3-8B-Instruct",
                      "label": {
                          "en_US": "Meta-Llama-3-8B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.5,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 600,
                              "min": 1,
                              "max": 1248,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Meta-Llama-3.1-405B-Instruct-AWQ-INT4",
                      "label": {
                          "en_US": "Meta-Llama-3.1-405B-Instruct-AWQ-INT4"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 410960
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.5,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 600,
                              "min": 1,
                              "max": 1248,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Meta-Llama-3.1-8B-Instruct",
                      "label": {
                          "en_US": "Meta-Llama-3.1-8B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.1,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 600,
                              "min": 1,
                              "max": 1248,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen-14B-Chat-Int4",
                      "label": {
                          "en_US": "Qwen-14B-Chat-Int4"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 600,
                              "min": 1,
                              "max": 1248,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Qwen1.5-110B-Chat-GPTQ-Int4",
                      "label": {
                          "en_US": "Qwen1.5-110B-Chat-GPTQ-Int4"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 128,
                              "min": 1,
                              "max": 256,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Qwen1.5-72B-Chat-GPTQ-Int4",
                      "label": {
                          "en_US": "Qwen1.5-72B-Chat-GPTQ-Int4"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2048
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 600,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Qwen1.5-7B",
                      "label": {
                          "en_US": "Qwen1.5-7B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "completion",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 600,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Qwen2-72B-Instruct-AWQ-int4",
                      "label": {
                          "en_US": "Qwen2-72B-Instruct-AWQ-int4"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.5,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 600,
                              "min": 1,
                              "max": 1248,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen2-72B-Instruct-GPTQ-Int4",
                      "label": {
                          "en_US": "Qwen2-72B-Instruct-GPTQ-Int4"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2048
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.7,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 600,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Qwen2-72B-Instruct",
                      "label": {
                          "en_US": "Qwen2-72B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.5,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 600,
                              "min": 1,
                              "max": 1248,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen2-7B-Instruct",
                      "label": {
                          "en_US": "Qwen2-7B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "completion",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 600,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen2-7B",
                      "label": {
                          "en_US": "Qwen2-7B"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "completion",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.3,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 600,
                              "min": 1,
                              "max": 2000,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      },
                      "deprecated": true
                  },
                  {
                      "model": "Qwen2.5-72B-Instruct",
                      "label": {
                          "en_US": "Qwen2.5-72B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 30720
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.5,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 600,
                              "min": 1,
                              "max": 1248,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen2.5-7B-Instruct",
                      "label": {
                          "en_US": "Qwen2.5-7B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.5,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 600,
                              "min": 1,
                              "max": 1248,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Reflection-Llama-3.1-70B",
                      "label": {
                          "en_US": "Reflection-Llama-3.1-70B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 10240
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.5,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 600,
                              "min": 1,
                              "max": 1248,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Yi-1_5-9B-Chat-16K",
                      "label": {
                          "en_US": "Yi-1_5-9B-Chat-16K"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16384
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.5,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 600,
                              "min": 1,
                              "max": 1248,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Yi-Coder-1.5B-Chat",
                      "label": {
                          "en_US": "Yi-Coder-1.5B-Chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 20480
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.5,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 600,
                              "min": 1,
                              "max": 1248,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Yi-Coder-9B-Chat",
                      "label": {
                          "en_US": "Yi-Coder-9B-Chat"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 20480
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.5,
                              "min": 0.0,
                              "max": 2.0,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, the temperature value controls the degree to which the probability distribution of each candidate word is smoothed when generating text. A higher temperature value will reduce the peak value of the probability distribution, allowing more low-probability words to be selected, and the generated results will be more diverse; while a lower temperature value will enhance the peak value of the probability distribution, making it easier for high-probability words to be selected. , the generated results are more certain."
                              }
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 600,
                              "min": 1,
                              "max": 1248,
                              "help": {
                                  "zh_Hans": "用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。",
                                  "en_US": "It is used to specify the maximum number of tokens when the model generates content. It defines the upper limit of generation, but does not guarantee that this number will be generated every time."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 0.8,
                              "min": 0.1,
                              "max": 0.9,
                              "help": {
                                  "zh_Hans": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
                                  "en_US": "The probability threshold of the kernel sampling method during the generation process. For example, when the value is 0.8, only the smallest set of the most likely tokens with a sum of probabilities greater than or equal to 0.8 is retained as the candidate set. The value range is (0,1.0). The larger the value, the higher the randomness generated; the lower the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "top_k",
                              "type": "int",
                              "min": 0,
                              "max": 99,
                              "label": {
                                  "zh_Hans": "取样数量",
                                  "en_US": "Top k"
                              },
                              "help": {
                                  "zh_Hans": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。",
                                  "en_US": "The size of the sample candidate set when generated. For example, when the value is 50, only the 50 highest-scoring tokens in a single generation form a randomly sampled candidate set. The larger the value, the higher the randomness generated; the smaller the value, the higher the certainty generated."
                              }
                          },
                          {
                              "name": "repetition_penalty",
                              "required": false,
                              "type": "float",
                              "default": 1.1,
                              "label": {
                                  "en_US": "Repetition penalty"
                              },
                              "help": {
                                  "zh_Hans": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
                                  "en_US": "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "0.000",
                          "output": "0.000",
                          "unit": "0.000",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "BAAI/bge-large-en-v1.5",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 32768
                      }
                  },
                  {
                      "model": "BAAI/bge-large-zh-v1.5",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 32768
                      }
                  },
                  {
                      "model": "BAAI/bge-m3",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 32768
                      }
                  },
                  {
                      "model": "gte-Qwen2-7B-instruct",
                      "model_type": "text-embedding",
                      "model_properties": {
                          "context_size": 2048
                      },
                      "deprecated": true
                  }
              ],
              "provider": "perfxcloud",
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "label": {
                              "en_US": "Custom API endpoint URL",
                              "zh_Hans": "自定义 API endpoint 地址"
                          },
                          "placeholder": {
                              "en_US": "Base URL, e.g. https://cloud.perfxlab.cn/v1",
                              "zh_Hans": "Base URL, e.g. https://cloud.perfxlab.cn/v1"
                          },
                          "required": false,
                          "type": "text-input",
                          "variable": "endpoint_url"
                      }
                  ]
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding"
              ]
          }
      },
      {
          "author": "ssrag",
          "created_at": "2024-09-20T00:13:50.29298939-04:00",
          "description": {
              "en_US": "VESSL AI"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "VESSL AI"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.12"
              },
              "version": "0.0.1"
          },
          "name": "vessl_ai",
          "plugins": {
              "models": [
                  "provider/vessl_ai.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": true,
                      "speech2text": false,
                      "text_embedding": true,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.2",
          "model": {
              "background": "#F1EFED",
              "configurate_methods": [
                  "customizable-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py"
                      ],
                      "provider_source": "provider/vessl_ai.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "How to deploy VESSL AI LLM Model Endpoint"
                  },
                  "url": {
                      "en_US": "https://docs.vessl.ai/guides/get-started/llama3-deployment"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.png"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "label": {
                  "en_US": "VESSL AI"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "Endpoint Url"
                          },
                          "placeholder": {
                              "en_US": "Enter VESSL AI service endpoint url"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "endpoint_url"
                      },
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter VESSL AI secret key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "default": "chat",
                          "label": {
                              "en_US": "Completion Mode"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Completion"
                                  },
                                  "value": "completion"
                              },
                              {
                                  "label": {
                                      "en_US": "Chat"
                                  },
                                  "value": "chat"
                              }
                          ],
                          "placeholder": {
                              "en_US": "Select completion mode"
                          },
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "select",
                          "variable": "mode"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name"
                      },
                      "placeholder": {
                          "en_US": "Enter model name"
                      }
                  }
              },
              "provider": "vessl_ai",
              "supported_model_types": [
                  "llm"
              ],
              "models": []
          }
      },
      {
          "version": "0.0.1",
          "type": "plugin",
          "author": "netmind",
          "name": "netmind",
          "description": {
              "en_US": "netmind.ai",
              "zh_Hans": "netmind.ai"
          },
          "label": {
              "en_US": "Netmind",
              "zh_Hans": "Netmind"
          },
          "created_at": "2025-03-10T08:03:44.658609186Z",
          "icon": "netmind.svg",
          "resource": {
              "memory": 1048576,
              "permission": {
                  "tool": {
                      "enabled": true
                  },
                  "model": {
                      "enabled": true,
                      "llm": true
                  }
              }
          },
          "plugins": {
              "models": [
                  "provider/netmind.yaml"
              ]
          },
          "meta": {
              "version": "0.0.1",
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "language": "python",
                  "version": "3.12",
                  "entrypoint": "main"
              }
          },
          "privacy": "https://www.netmind.ai/doc/Privacy_Policy.html",
          "model": {
              "provider": "netmind",
              "label": {
                  "en_US": "Netmind"
              },
              "icon_large": {
                  "en_US": "netmind_larg.svg"
              },
              "icon_small": {
                  "en_US": "netmind.svg"
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding"
              ],
              "configurate_methods": [
                  "customizable-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/text_embedding/text_embedding.py"
                      ],
                      "provider_source": "provider/netmind.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API key from netmind.ai",
                      "zh_Hans": "从 netmind.ai 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://www.netmind.ai/"
                  }
              },
              "model_credential_schema": {
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter full model name",
                          "zh_Hans": "输入模型全称"
                      }
                  },
                  "credential_form_schemas": [
                      {
                          "variable": "api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "type": "secret-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Key",
                              "en_US": "Enter your API Key"
                          }
                      },
                      {
                          "variable": "mode",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "en_US": "Completion mode"
                          },
                          "type": "select",
                          "required": false,
                          "default": "chat",
                          "placeholder": {
                              "zh_Hans": "选择对话类型",
                              "en_US": "Select completion mode"
                          },
                          "options": [
                              {
                                  "value": "completion",
                                  "label": {
                                      "en_US": "Completion",
                                      "zh_Hans": "补全"
                                  }
                              },
                              {
                                  "value": "chat",
                                  "label": {
                                      "en_US": "Chat",
                                      "zh_Hans": "对话"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "context_size",
                          "label": {
                              "zh_Hans": "模型上下文长度",
                              "en_US": "Model context size"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "type": "text-input",
                          "default": "4096",
                          "placeholder": {
                              "zh_Hans": "在此输入您的模型上下文长度",
                              "en_US": "Enter your Model context size"
                          }
                      },
                      {
                          "variable": "context_size",
                          "label": {
                              "zh_Hans": "模型上下文长度",
                              "en_US": "Model context size"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "text-embedding"
                              }
                          ],
                          "type": "text-input",
                          "default": "4096",
                          "placeholder": {
                              "zh_Hans": "在此输入您的模型上下文长度",
                              "en_US": "Enter your Model context size"
                          }
                      },
                      {
                          "variable": "max_tokens_to_sample",
                          "label": {
                              "zh_Hans": "最大 token 上限",
                              "en_US": "Upper bound for max tokens"
                          },
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "default": "4096",
                          "type": "text-input"
                      }
                  ]
              },
              "models": []
          }
      },
      {
          "author": "zuiyue-com",
          "created_at": "2025-05-26T00:18:00+08:00",
          "description": {
              "en_US": "BurnCloud provides stable, cost-effective open-source model API services, supporting Claude 4.0/3.7/3.5, GPT 4o/4o-mini/o1/4.5 preview/o1-mini, GPT-image-1, Gemini 2.5 pro/2.0, DeepSeek R1/V3 and other industry-leading large models.",
              "zh_Hans": "BurnCloud 提供稳定、高性价比的开源模型 API 服务，支持 Claude 4.0/3.7/3.5、GPT 4o/4o-mini/o1/4.5 preview/o1-mini、GPT-image-1、Gemini 2.5 pro/2.0、DeepSeek R1/V3 等行业领先大模型。"
          },
          "icon": "icon_s_en.svg",
          "label": {
              "en_US": "BurnCloud",
              "zh_Hans": "BurnCloud"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "entrypoint": "main",
                  "language": "python",
                  "version": "3.10"
              },
              "version": "1.0.3"
          },
          "name": "burncloud",
          "plugins": {
              "models": [
                  "provider/burncloud.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": false,
                      "speech2text": false,
                      "text_embedding": false,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "1.0.3",
          "privacy": "https://www.burncloud.com/ai_1xPE.html",
          "model": {
              "provider": "burncloud",
              "label": {
                  "en_US": "BurnCloud",
                  "zh_Hans": "BurnCloud"
              },
              "description": {
                  "en_US": "BurnCloud provides stable, cost-effective open-source model API services, supporting Claude 4.0/3.7/3.5, GPT 4o/4o-mini/o1/4.5 preview/o1-mini, GPT-image-1, Gemini 2.5 pro/2.0, DeepSeek R1/V3 and other industry-leading large models.",
                  "zh_Hans": "BurnCloud 提供稳定、高性价比的开源模型 API 服务，支持 Claude 4.0/3.7/3.5、GPT 4o/4o-mini/o1/4.5 preview/o1-mini、GPT-image-1、Gemini 2.5 pro/2.0、DeepSeek R1/V3 等行业领先大模型。"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg",
                  "zh_Hans": "icon_l_zh.svg"
              },
              "background": "#b5cefc",
              "help": {
                  "title": {
                      "en_US": "Get your API key from BurnCloud",
                      "zh_Hans": "从 BurnCloud 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://www.burncloud.com/ai_1xPE.html"
                  }
              },
              "supported_model_types": [
                  "llm"
              ],
              "configurate_methods": [
                  "predefined-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py"
                      ],
                      "provider_source": "provider/burncloud.py"
                  }
              },
              "models": [
                  {
                      "model": "claude-3-5-sonnet-20241022",
                      "label": {
                          "zh_Hans": "Claude 3.5",
                          "en_US": "Claude 3.5"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 4096,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.10",
                          "output": "0.50",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "claude-3-7-sonnet-20250219",
                      "label": {
                          "zh_Hans": "Claude 3.7",
                          "en_US": "Claude 3.7"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 4096,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.12",
                          "output": "0.60",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "claude-sonnet-4-20250514",
                      "label": {
                          "zh_Hans": "Claude 4.0",
                          "en_US": "Claude 4.0"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 4096,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.15",
                          "output": "0.75",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "deepseek-r1",
                      "label": {
                          "zh_Hans": "DeepSeek R1",
                          "en_US": "DeepSeek R1"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.04",
                          "output": "0.16",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "deepseek-v3",
                      "label": {
                          "zh_Hans": "DeepSeek V3",
                          "en_US": "DeepSeek V3"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 64000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 2048,
                              "default": 512
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.01",
                          "output": "0.02",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "gemini-2.0-flash",
                      "label": {
                          "zh_Hans": "Gemini 2.0",
                          "en_US": "Gemini 2.0"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 1000000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.12",
                          "output": "0.48",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "gemini-2.5-pro-preview-05-06",
                      "label": {
                          "zh_Hans": "Gemini 2.5 Pro",
                          "en_US": "Gemini 2.5 Pro"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 2000000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 8192,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.15",
                          "output": "0.60",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "gpt-4.5-preview",
                      "label": {
                          "zh_Hans": "GPT-4.5 Preview",
                          "en_US": "GPT-4.5 Preview"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 4096,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.12",
                          "output": "0.48",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "gpt-4o-mini",
                      "label": {
                          "zh_Hans": "GPT-4o Mini",
                          "en_US": "GPT-4o Mini"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 4096,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.02",
                          "output": "0.08",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "gpt-4o",
                      "label": {
                          "zh_Hans": "GPT-4o",
                          "en_US": "GPT-4o"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 4096,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.08",
                          "output": "0.32",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "gpt-image-1",
                      "label": {
                          "zh_Hans": "GPT-Image-1",
                          "en_US": "GPT-Image-1"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 4096,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.10",
                          "output": "0.40",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "o1-mini",
                      "label": {
                          "zh_Hans": "GPT-o1 Mini",
                          "en_US": "GPT-o1 Mini"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 4096,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.06",
                          "output": "0.24",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "o1",
                      "label": {
                          "zh_Hans": "GPT-o1",
                          "en_US": "GPT-o1"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 200000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "min": 0,
                              "max": 2,
                              "default": 1
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "min": 0,
                              "max": 1,
                              "default": 1
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 4096,
                              "default": 1024
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "min": -2,
                              "max": 2,
                              "default": 0
                          }
                      ],
                      "pricing": {
                          "input": "0.20",
                          "output": "0.80",
                          "unit": "0.0001",
                          "currency": "CNY"
                      }
                  }
              ],
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "variable": "api_key",
                          "label": {
                              "en_US": "API Key",
                              "zh_Hans": "API Key"
                          },
                          "type": "secret-input",
                          "required": true,
                          "placeholder": {
                              "en_US": "Please input your API Key",
                              "zh_Hans": "请输入您的 API Key"
                          }
                      }
                  ]
              }
          }
      },
      {
          "version": "0.0.1",
          "type": "plugin",
          "author": "featherlessai",
          "name": "featherlessai",
          "label": {
              "en_US": "FeatherlessAI",
              "ja_JP": "FeatherlessAI",
              "zh_Hans": "FeatherlessAI",
              "pt_BR": "FeatherlessAI"
          },
          "description": {
              "en_US": "Featherless AI is a serverless inference provider that provides access to over 4200+ open source models, including LLama, Mistral, DeepSeek, Qwen, and more.",
              "ja_JP": "Featherless AI はサーバーレス推論プロバイダーで、LLama、Mistral、DeepSeek、Qwenなど、4200以上のオープンソースモデルへのアクセスを提供します。",
              "zh_Hans": "Featherless AI 是一个无服务器推理提供商，提供对超过 4200 个开源模型的访问，包括 LLama、Mistral、DeepSeek、Qwen 等。",
              "pt_BR": "Featherless AI é um provedor de inferência sem servidor que oferece acesso a mais de 4200 modelos de código aberto, incluindo LLama, Mistral, DeepSeek, Qwen e mais."
          },
          "icon": "featherless.svg",
          "resource": {
              "memory": 268435456,
              "permission": {
                  "tool": {
                      "enabled": false
                  },
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "text_embedding": false,
                      "rerank": false,
                      "tts": false,
                      "speech2text": false,
                      "moderation": false
                  },
                  "node": {
                      "enabled": false
                  },
                  "endpoint": {
                      "enabled": false
                  },
                  "app": {
                      "enabled": false
                  },
                  "storage": {
                      "enabled": true,
                      "size": 1048576
                  }
              }
          },
          "plugins": {
              "models": [
                  "provider/featherlessai.yaml"
              ]
          },
          "meta": {
              "version": "0.0.1",
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "language": "python",
                  "version": "3.12",
                  "entrypoint": "main"
              }
          },
          "created_at": "2025-05-26T14:18:56.329224+02:00",
          "privacy": "PRIVACY.md",
          "verified": false,
          "model": {
              "provider": "featherlessai",
              "label": {
                  "en_US": "Featherless AI"
              },
              "icon_large": {
                  "en_US": "featherless_larg.svg"
              },
              "icon_small": {
                  "en_US": "featherless.svg"
              },
              "supported_model_types": [
                  "llm"
              ],
              "configurate_methods": [
                  "customizable-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/llm/llm.py"
                      ],
                      "provider_source": "provider/featherlessai.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "Get your API key from featherless.ai",
                      "zh_Hans": "从 featherless.ai 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://www.featherless.ai/"
                  }
              },
              "model_credential_schema": {
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter full model name",
                          "zh_Hans": "输入模型全称"
                      }
                  },
                  "credential_form_schemas": [
                      {
                          "variable": "api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "type": "secret-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Key",
                              "en_US": "Enter your API Key"
                          }
                      },
                      {
                          "variable": "mode",
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "label": {
                              "en_US": "Completion mode"
                          },
                          "type": "select",
                          "required": false,
                          "default": "chat",
                          "placeholder": {
                              "zh_Hans": "选择对话类型",
                              "en_US": "Select completion mode"
                          },
                          "options": [
                              {
                                  "value": "completion",
                                  "label": {
                                      "en_US": "Completion",
                                      "zh_Hans": "补全"
                                  }
                              },
                              {
                                  "value": "chat",
                                  "label": {
                                      "en_US": "Chat",
                                      "zh_Hans": "对话"
                                  }
                              }
                          ]
                      },
                      {
                          "variable": "context_size",
                          "label": {
                              "zh_Hans": "模型上下文长度",
                              "en_US": "Model context size"
                          },
                          "required": true,
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "type": "text-input",
                          "default": "4096",
                          "placeholder": {
                              "zh_Hans": "在此输入您的模型上下文长度",
                              "en_US": "Enter your Model context size"
                          }
                      },
                      {
                          "variable": "max_tokens_to_sample",
                          "label": {
                              "zh_Hans": "最大 token 上限",
                              "en_US": "Upper bound for max tokens"
                          },
                          "show_on": [
                              {
                                  "variable": "__model_type",
                                  "value": "llm"
                              }
                          ],
                          "default": "4096",
                          "type": "text-input"
                      }
                  ]
              },
              "models": []
          }
      },
      {
          "version": "0.0.1",
          "type": "plugin",
          "author": "jiangzhijie",
          "name": "lindormai",
          "label": {
              "en_US": "lindormai",
              "ja_JP": "lindormai",
              "zh_Hans": "lindormai",
              "pt_BR": "lindormai"
          },
          "description": {
              "en_US": "lindormai",
              "ja_JP": "lindormai",
              "zh_Hans": "lindormai",
              "pt_BR": "lindormai"
          },
          "icon": "icon_s_en.png",
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": false,
                      "text_embedding": true,
                      "rerank": true,
                      "tts": false,
                      "speech2text": false,
                      "moderation": false
                  }
              }
          },
          "plugins": {
              "models": [
                  "provider/lindormai.yaml"
              ]
          },
          "meta": {
              "version": "0.0.1",
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "language": "python",
                  "version": "3.12",
                  "entrypoint": "main"
              }
          },
          "created_at": "2025-01-13T20:37:28.806965+08:00",
          "privacy": "PRIVACY.md",
          "verified": false,
          "model": {
              "background": "#FAF5FF",
              "configurate_methods": [
                  "customizable-model"
              ],
              "extra": {
                  "python": {
                      "model_sources": [
                          "models/rerank/rerank.py",
                          "models/text_embedding/text_embedding.py"
                      ],
                      "provider_source": "provider/lindormai.py"
                  }
              },
              "help": {
                  "title": {
                      "en_US": "How to deploy your model in Lindorm AI Engine",
                      "zh_Hans": "如何在Lindorm AI引擎部署模型"
                  },
                  "url": {
                      "en_US": "https://help.aliyun.com/document_detail/2393245.html?spm=a2c4g.11186623.help-menu-172543.d_2_7.4b0f1513fp0y82&scm=20140722.H_2393245._.OR_help-T_cn#DAS#zh-V_1"
                  }
              },
              "icon_large": {
                  "en_US": "icon_l_en.png"
              },
              "icon_small": {
                  "en_US": "icon_s_en.png"
              },
              "label": {
                  "en_US": "LindormAI"
              },
              "model_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "Lindorm AI Engine URL",
                              "zh_Hans": "Lindorm AI Engine URL"
                          },
                          "placeholder": {
                              "en_US": "Enter the URL of you LindormAI, e.g. http://ld-xxxxxxxxxxxxx-proxy-ai-pub.lindorm.aliyuncs.com:9002",
                              "zh_Hans": "在此输入Lindorm的AI连接地址，如 http://ld-xxxxxxxxxxxxx-proxy-ai-pub.lindorm.aliyuncs.com:9002"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "lindormai_endpoint"
                      },
                      {
                          "label": {
                              "en_US": "Username",
                              "zh_Hans": "lindorm 用户名"
                          },
                          "placeholder": {
                              "en_US": "Enter your lindorm username",
                              "zh_Hans": "在此输入您的用户名"
                          },
                          "required": true,
                          "type": "text-input",
                          "variable": "lindormai_username"
                      },
                      {
                          "label": {
                              "en_US": "Password",
                              "zh_Hans": "密码"
                          },
                          "placeholder": {
                              "en_US": "Enter the password",
                              "zh_Hans": "在此输入您的密码"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "lindormai_password"
                      }
                  ],
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your deployed model name",
                          "zh_Hans": "输入部署的模型名称"
                      }
                  }
              },
              "provider": "lindormai",
              "supported_model_types": [
                  "text-embedding",
                  "rerank"
              ],
              "models": []
          }
      },
      {
          "version": "0.1.1",
          "type": "plugin",
          "author": "pedrogomes02",
          "name": "ibm_watsonx",
          "label": {
              "en_US": "IBM WatsonX",
              "ja_JP": "IBM WatsonX",
              "zh_Hans": "IBM WatsonX",
              "pt_BR": "IBM WatsonX"
          },
          "description": {
              "en_US": "IBM WatsonX provider",
              "ja_JP": "IBM WatsonX provider",
              "zh_Hans": "IBM WatsonX provider",
              "pt_BR": "IBM WatsonX provider"
          },
          "icon": "icon.svg",
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "text_embedding": false,
                      "rerank": false,
                      "tts": false,
                      "speech2text": false,
                      "moderation": false
                  }
              }
          },
          "plugins": {
              "models": [
                  "provider/ibm_watsonx.yaml"
              ]
          },
          "meta": {
              "version": "0.0.1",
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "language": "python",
                  "version": "3.12",
                  "entrypoint": "main"
              }
          },
          "created_at": "2025-05-06T13:02:21.099091+01:00",
          "privacy": "PRIVACY.md",
          "verified": false,
          "model": {
              "provider": "ibm_watsonx",
              "label": {
                  "en_US": "IbmWatsonx"
              },
              "description": {
                  "en_US": "Models provided by ibm_watsonx.",
                  "zh_Hans": "IbmWatsonx 提供的模型。"
              },
              "icon_small": {
                  "en_US": "icon.svg"
              },
              "icon_large": {
                  "en_US": "icon.svg"
              },
              "background": "#E5E7EB",
              "help": {
                  "title": {
                      "en_US": "Get your API Key from ibm_watsonx",
                      "zh_Hans": "从 IbmWatsonx 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://cloud.ibm.com/iam/apikeys"
                  }
              },
              "supported_model_types": [
                  "llm"
              ],
              "configurate_methods": [
                  "predefined-model",
                  "customizable-model"
              ],
              "model_credential_schema": {
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  },
                  "credential_form_schemas": [
                      {
                          "variable": "ibm_api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "type": "secret-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Key",
                              "en_US": "Enter your API Key"
                          }
                      },
                      {
                          "variable": "ibm_project_id",
                          "label": {
                              "en_US": "Project ID"
                          },
                          "type": "text-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 Project ID",
                              "en_US": "Enter your Project ID"
                          }
                      }
                  ]
              },
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "variable": "ibm_api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "type": "secret-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Key",
                              "en_US": "Enter your API Key"
                          }
                      },
                      {
                          "variable": "ibm_project_id",
                          "label": {
                              "en_US": "Project ID"
                          },
                          "type": "text-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 Project ID",
                              "en_US": "Enter your Project ID"
                          }
                      },
                      {
                          "variable": "ibm_url",
                          "label": {
                              "en_US": "Ibm Server"
                          },
                          "type": "select",
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Dallas",
                                      "zh_Hans": "Dallas"
                                  },
                                  "value": "https://us-south.ml.cloud.ibm.com"
                              },
                              {
                                  "label": {
                                      "en_US": "UK",
                                      "zh_Hans": "UK"
                                  },
                                  "value": "https://eu-gb.ml.cloud.ibm.com"
                              },
                              {
                                  "label": {
                                      "en_US": "Tokyo",
                                      "zh_Hans": "Tokyo"
                                  },
                                  "value": "https://jp-tok.ml.cloud.ibm.com"
                              },
                              {
                                  "label": {
                                      "en_US": "Frankfurt",
                                      "zh_Hans": "Frankfurt"
                                  },
                                  "value": "https://eu-de.ml.cloud.ibm.com"
                              },
                              {
                                  "label": {
                                      "en_US": "Sydney",
                                      "zh_Hans": "Sydney"
                                  },
                                  "value": "https://au-syd.ml.cloud.ibm.com"
                              },
                              {
                                  "label": {
                                      "en_US": "Toronto",
                                      "zh_Hans": "Toronto"
                                  },
                                  "value": "https://ca-tor.ml.cloud.ibm.com"
                              }
                          ],
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "Ibm Server",
                              "en_US": "Ibm Server"
                          }
                      }
                  ]
              },
              "models": [
                  {
                      "model": "mistralai/mistral-small-3-1-24b-instruct-2503",
                      "label": {
                          "zh_Hans": "mistralai/mistral-small-3-1-24b-instruct-2503",
                          "en_US": "mistralai/mistral-small-3-1-24b-instruct-2503"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "agent-thought",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 16385
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.010",
                          "output": "0.030",
                          "unit": "0.00001",
                          "currency": "USD"
                      }
                  }
              ],
              "extra": {
                  "python": {
                      "provider_source": "provider/ibm_watsonx.py",
                      "model_sources": [
                          "models/llm/llm.py"
                      ]
                  }
              }
          }
      },
      {
          "version": "0.0.1",
          "type": "plugin",
          "author": "ssrag",
          "name": "sambanova",
          "label": {
              "en_US": "SambaNovaCloud",
              "ja_JP": "SambaNovaCloud",
              "zh_Hans": "SambaNovaCloud",
              "pt_BR": "SambaNovaCloud"
          },
          "description": {
              "en_US": "SambaNova Cloud provides access to the SambaNova Cloud API, which hosts LLama4, Qwen and DeepSeek Models.",
              "ja_JP": "SambaNova Cloud provides access to the SambaNova Cloud API, which hosts LLama4, Qwen and DeepSeek Models.",
              "zh_Hans": "SambaNova Cloud provides access to the SambaNova Cloud API, which hosts LLama4, Qwen and DeepSeek Models.",
              "pt_BR": "SambaNova Cloud provides access to the SambaNova Cloud API, which hosts LLama4, Qwen and DeepSeek Models."
          },
          "icon": "icon_s_en.svg",
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "text_embedding": false,
                      "rerank": false,
                      "tts": false,
                      "speech2text": false,
                      "moderation": false
                  }
              }
          },
          "plugins": {
              "models": [
                  "provider/sambanova.yaml"
              ]
          },
          "meta": {
              "version": "0.0.1",
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "language": "python",
                  "version": "3.12",
                  "entrypoint": "main"
              }
          },
          "created_at": "2025-05-12T15:02:07.839808-05:00",
          "model": {
              "provider": "sambanova",
              "label": {
                  "en_US": "SambaNova Cloud",
                  "zh_Hans": "Sambanova Cloud"
              },
              "description": {
                  "en_US": "SambaNova Cloud provides access to the SambaNova Cloud API, which hosts LLama4, Qwen and DeepSeek Models.",
                  "zh_Hans": "Sambanova Cloud 提供的模型。"
              },
              "icon_small": {
                  "en_US": "icon_s_en.svg"
              },
              "icon_large": {
                  "en_US": "icon_l_en.svg"
              },
              "background": "#E5E7EB",
              "help": {
                  "title": {
                      "en_US": "Get your API Key from sambanova Cloud",
                      "zh_Hans": "从 Sambanova Cloud 获取 API Key"
                  },
                  "url": {
                      "en_US": "http://cloud.sambanova.ai"
                  }
              },
              "supported_model_types": [
                  "llm"
              ],
              "configurate_methods": [
                  "predefined-model",
                  "customizable-model"
              ],
              "model_credential_schema": {
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  },
                  "credential_form_schemas": [
                      {
                          "variable": "api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "type": "secret-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Key",
                              "en_US": "Enter your API Key"
                          }
                      }
                  ]
              },
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "variable": "api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "type": "secret-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Key",
                              "en_US": "Enter your API Key"
                          }
                      }
                  ]
              },
              "models": [
                  {
                      "model": "DeepSeek-R1-Distill-Llama-70B",
                      "label": {
                          "zh_Hans": "DeepSeek-R1-Distill-Llama-70B",
                          "en_US": "DeepSeek-R1-Distill-Llama-70B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "use_template": "top_k"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.07",
                          "output": "0.14",
                          "unit": "0.00001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "DeepSeek-R1",
                      "label": {
                          "zh_Hans": "DeepSeek-R1",
                          "en_US": "DeepSeek-R1"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "use_template": "top_k"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 16384
                          }
                      ],
                      "pricing": {
                          "input": "0.5",
                          "output": "0.7",
                          "unit": "0.00001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "DeepSeek-V3-0324",
                      "label": {
                          "zh_Hans": "DeepSeek-V3-0324",
                          "en_US": "DeepSeek-V3-0324"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "use_template": "top_k"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 16384
                          }
                      ],
                      "pricing": {
                          "input": "0.3",
                          "output": "0.45",
                          "unit": "0.00001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "Llama-4-Maverick-17B-128E-Instruct",
                      "label": {
                          "zh_Hans": "Llama-4-Maverick-17B-128E-Instruct",
                          "en_US": "Llama-4-Maverick-17B-128E-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought",
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 65536
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "use_template": "top_k"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.063",
                          "output": "0.18",
                          "unit": "0.00001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "Llama-4-Scout-17B-16E-Instruct",
                      "label": {
                          "zh_Hans": "Llama-4-Scout-17B-16E-Instruct",
                          "en_US": "Llama-4-Scout-17B-16E-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "use_template": "top_k"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.04",
                          "output": "0.07",
                          "unit": "0.00001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "Meta-Llama-3.1-405B-Instruct",
                      "label": {
                          "zh_Hans": "Meta-Llama-3.1-405B-Instruct",
                          "en_US": "Meta-Llama-3.1-405B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16384
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "use_template": "top_k"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.5",
                          "output": "1.0",
                          "unit": "0.00001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "Meta-Llama-3.1-8B-Instruct",
                      "label": {
                          "zh_Hans": "Meta-Llama-3.1-8B-Instruct",
                          "en_US": "Meta-Llama-3.1-8B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16384
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "use_template": "top_k"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.01",
                          "output": "0.02",
                          "unit": "0.00001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "Meta-Llama-3.2-1B-Instruct",
                      "label": {
                          "zh_Hans": "Meta-Llama-3.2-1B-Instruct",
                          "en_US": "Meta-Llama-3.2-1B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16384
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "use_template": "top_k"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.008",
                          "unit": "0.00001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "Meta-Llama-3.2-3B-Instruct",
                      "label": {
                          "zh_Hans": "Meta-Llama-3.2-3B-Instruct",
                          "en_US": "Meta-Llama-3.2-3B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "use_template": "top_k"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.008",
                          "output": "0.016",
                          "unit": "0.00001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "Meta-Llama-3.3-70B-Instruct",
                      "label": {
                          "zh_Hans": "Meta-Llama-3.3-70B-Instruct",
                          "en_US": "Meta-Llama-3.3-70B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "use_template": "top_k"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 32768
                          }
                      ],
                      "pricing": {
                          "input": "0.06",
                          "output": "0.12",
                          "unit": "0.00001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "Meta-Llama-Guard-3-8B",
                      "label": {
                          "zh_Hans": "Meta-Llama-Guard-3-8B",
                          "en_US": "Meta-Llama-Guard-3-8B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16384
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "use_template": "top_k"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.03",
                          "output": "0.03",
                          "unit": "0.00001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "Qwen2-Audio-7B-Instruct",
                      "label": {
                          "zh_Hans": "Qwen2-Audio-7B-Instruct",
                          "en_US": "Qwen2-Audio-7B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 4096
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "use_template": "top_k"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "1.0",
                          "output": "0.1",
                          "unit": "0.00001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "Qwen3-32B",
                      "label": {
                          "zh_Hans": "Qwen3-32B",
                          "en_US": "Qwen3-32B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 8192
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "use_template": "top_k"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.04",
                          "output": "0.08",
                          "unit": "0.00001",
                          "currency": "USD"
                      }
                  },
                  {
                      "model": "QwQ-32B",
                      "label": {
                          "zh_Hans": "QwQ-32B",
                          "en_US": "QwQ-32B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 16384
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "top_k",
                              "use_template": "top_k"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 512,
                              "min": 1,
                              "max": 4096
                          }
                      ],
                      "pricing": {
                          "input": "0.05",
                          "output": "0.1",
                          "unit": "0.00001",
                          "currency": "USD"
                      }
                  }
              ],
              "extra": {
                  "python": {
                      "provider_source": "provider/sambanova.py",
                      "model_sources": [
                          "models/llm/llm.py"
                      ]
                  }
              }
          }
      },
      {
          "author": "axdlee",
          "created_at": "2025-06-13T10:25:38.280130+08:00",
          "description": {
              "en_US": "SophNet provides full-blood DeepSeek R1/V3, Qwen, QwQ models, and its own DeepSeek V3 Fast model, as well as text-to-speech, image OCR, document parsing, and other models.",
              "zh_Hans": "SophNet 提供满血版 DeepSeek R1/V3，Qwen, QwQ 模型，以及其独有的 DeepSeek V3 Fast 模型, 此外还提供文字转语音，图片OCR， 文档解析等模型。"
          },
          "icon": "icon.svg",
          "label": {
              "en_US": "SophNet",
              "zh_Hans": "SophNet 算能"
          },
          "meta": {
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "language": "python",
                  "version": "3.12",
                  "entrypoint": "main"
              },
              "version": "0.0.1"
          },
          "name": "sophnet",
          "plugins": {
              "models": [
                  "provider/sophnet.yaml"
              ]
          },
          "resource": {
              "memory": 268435456,
              "permission": {
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "moderation": false,
                      "rerank": false,
                      "speech2text": false,
                      "text_embedding": false,
                      "tts": false
                  },
                  "tool": {
                      "enabled": true
                  }
              }
          },
          "type": "plugin",
          "version": "0.0.1",
          "privacy": "PRIVACY.md",
          "repo": "https://github.com/axdlee/sophnet",
          "verified": false,
          "model": {
              "provider": "sophnet",
              "label": {
                  "en_US": "SophNet",
                  "zh_Hans": "SophNet 算能"
              },
              "description": {
                  "en_US": "SophNet provides full-blood DeepSeek R1/V3, Qwen, QwQ models, and its own DeepSeek V3 Fast model, as well as text-to-speech, image OCR, document parsing, and other models.",
                  "zh_Hans": "SophNet 提供满血版 DeepSeek R1/V3，Qwen, QwQ 模型，以及其独有的 DeepSeek V3 Fast 模型, 此外还提供文字转语音，图片OCR， 文档解析等模型。"
              },
              "icon_large": {
                  "en_US": "icon.svg"
              },
              "icon_small": {
                  "en_US": "icon.svg"
              },
              "background": "#E5E7EB",
              "help": {
                  "title": {
                      "en_US": "Get your API Key from SophNet",
                      "zh_Hans": "从 SophNet 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://www.sophnet.com/#/project/key"
                  }
              },
              "supported_model_types": [
                  "llm",
                  "text-embedding"
              ],
              "configurate_methods": [
                  "predefined-model",
                  "customizable-model"
              ],
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "variable": "api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "type": "secret-input",
                          "required": true
                      },
                      {
                          "variable": "project_id",
                          "label": {
                              "en_US": "Project ID"
                          },
                          "placeholder": {
                              "en_US": "Enter your Project ID",
                              "zh_Hans": "在此输入您的 Project ID"
                          },
                          "type": "text-input",
                          "required": true
                      }
                  ]
              },
              "models": [
                  {
                      "model": "DeepSeek-Prover-V2",
                      "label": {
                          "zh_Hans": "DeepSeek-Prover-V2",
                          "en_US": "DeepSeek-Prover-V2"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 128000,
                              "required": false,
                              "help": {
                                  "zh_Hans": "模型回复最大长度（单位 token）。如果生成结果截断，可以调大该参数。",
                                  "en_US": "The maximum length of the model's response (in tokens). If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.6,
                              "min": 0.0,
                              "max": 2.0,
                              "required": false,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，较高的数值会使输出更加随机，而较低的数值会使其更加集中。默认值1.0，取值范围[0,2.0]。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, a higher value will make the output more random, while a lower value will make it more concentrated. The default value is 1.0, with a range of [0,2.0]."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 1.0,
                              "min": 0.1,
                              "max": 1.0,
                              "required": false,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。影响输出文本的多样性，取值越大，生成文本的多样性越强。默认值1.0。",
                                  "en_US": "Used to control the degree of randomness and diversity. It affects the diversity of the output text. The larger the value, the stronger the diversity of the generated text. The default value is 1.0."
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "type": "float",
                              "default": 0.0,
                              "min": -2.0,
                              "max": 2.0,
                              "required": false,
                              "help": {
                                  "zh_Hans": "用于控制模型在生成内容时避免重复使用某些词汇的倾向。根据新词在当前文本中的频率进行惩罚，降低模型逐字重复同一行的可能性。 默认值0，取值范围：[-2.0, 2.0]。",
                                  "en_US": "Used to control the tendency of the model to avoid using certain words when generating content. The frequency of new words in the current text is penalized, reducing the likelihood of the model repeating the same line word by word. The default value is 0, with a range of [-2.0, 2.0]."
                              }
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "type": "float",
                              "default": 0.0,
                              "min": -2.0,
                              "max": 2.0,
                              "required": false,
                              "help": {
                                  "zh_Hans": "用于控制模型在生成内容时避免重复使用某些词汇的倾向。通过对已生成的token增加惩罚，减少重复生成的现象。默认值0，取值范围：[-2.0, 2.0]。",
                                  "en_US": "Used to control the tendency of the model to avoid using certain words when generating content. By adding a penalty to the already generated tokens, the phenomenon of repeated generation is reduced. The default value is 0, with a range of [-2.0, 2.0]."
                              }
                          },
                          {
                              "name": "logprobs",
                              "label": {
                                  "zh_Hans": "输出 tokens 的对数概率",
                                  "en_US": "Log Probabilities of Output Tokens"
                              },
                              "type": "boolean",
                              "default": false,
                              "required": false,
                              "help": {
                                  "zh_Hans": "是否返回输出 tokens 的对数概率。",
                                  "en_US": "Whether to return the log probabilities of the output tokens."
                              }
                          },
                          {
                              "name": "top_logprobs",
                              "label": {
                                  "zh_Hans": "每个输出 token 位置最有可能返回的 token 数量",
                                  "en_US": "The number of tokens that are most likely to be returned at each output token position"
                              },
                              "type": "int",
                              "default": 0,
                              "min": 0,
                              "max": 100,
                              "required": false,
                              "help": {
                                  "zh_Hans": "默认值0，取值范围为 [0, 20]。指定每个输出 token 位置最有可能返回的 token 数量，每个 token 都有关联的对数概率。仅当 logprobs为true 时可以设置 top_logprobs 参数。",
                                  "en_US": "The default value is 0, with a range of [0, 20]. Specifies the number of tokens that are most likely to be returned at each output token position, with each token having an associated log probability. Only when logprobs is true can the top_logprobs parameter be set."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "4",
                          "output": "16",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "DeepSeek-R1-0528",
                      "label": {
                          "zh_Hans": "DeepSeek-R1-0528",
                          "en_US": "DeepSeek-R1-0528"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 128000,
                              "required": false,
                              "help": {
                                  "zh_Hans": "模型回复最大长度（单位 token）。如果生成结果截断，可以调大该参数。",
                                  "en_US": "The maximum length of the model's response (in tokens). If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式的对象。 可启用 JSON 模式，这保证模型生成的消息是有效的 JSON。重要：使用 JSON 模式时，您还必须通过系统或用户消息提示模型自行生成JSON。",
                                  "en_US": "Specifies the format that the model must output. JSON mode can be enabled, which ensures that the message generated by the model is valid JSON. Important! When using JSON mode, you must also prompt the model to generate JSON through system or user messages."
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "4",
                          "output": "16",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "DeepSeek-R1-Distill-Qwen-32B",
                      "label": {
                          "zh_Hans": "DeepSeek-R1-Distill-Qwen-32B",
                          "en_US": "DeepSeek-R1-Distill-Qwen-32B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 32768,
                              "default": 8192
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "6",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "DeepSeek-R1-Distill-Qwen-7B",
                      "label": {
                          "zh_Hans": "DeepSeek-R1-Distill-Qwen-7B",
                          "en_US": "DeepSeek-R1-Distill-Qwen-7B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "default": 0.95
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 32768,
                              "default": 8192
                          }
                      ],
                      "pricing": {
                          "input": "0.5",
                          "output": "1",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "DeepSeek-R1",
                      "label": {
                          "zh_Hans": "DeepSeek-R1",
                          "en_US": "DeepSeek-R1"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "stream-tool-call",
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 65536
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 65536,
                              "required": false,
                              "help": {
                                  "zh_Hans": "模型回复最大长度（单位 token）。如果生成结果截断，可以调大该参数。",
                                  "en_US": "The maximum length of the model's response (in tokens). If the generated results are truncated, you can increase this parameter."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "4",
                          "output": "16",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "DeepSeek-V3-Fast",
                      "label": {
                          "zh_Hans": "DeepSeek-V3-Fast",
                          "en_US": "DeepSeek-V3-Fast"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32767
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 32767,
                              "required": false,
                              "help": {
                                  "zh_Hans": "模型回复最大长度（单位 token）。如果生成结果截断，可以调大该参数。",
                                  "en_US": "The maximum length of the model's response (in tokens). If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.6,
                              "min": 0.0,
                              "max": 2.0,
                              "required": false,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，较高的数值会使输出更加随机，而较低的数值会使其更加集中。默认值1.0，取值范围[0,2.0]。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, a higher value will make the output more random, while a lower value will make it more concentrated. The default value is 1.0, with a range of [0,2.0]."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 1.0,
                              "min": 0.1,
                              "max": 1.0,
                              "required": false,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。影响输出文本的多样性，取值越大，生成文本的多样性越强。默认值1.0。",
                                  "en_US": "Used to control the degree of randomness and diversity. It affects the diversity of the output text. The larger the value, the stronger the diversity of the generated text. The default value is 1.0."
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "type": "float",
                              "default": 0.0,
                              "min": -2.0,
                              "max": 2.0,
                              "required": false,
                              "help": {
                                  "zh_Hans": "用于控制模型在生成内容时避免重复使用某些词汇的倾向。根据新词在当前文本中的频率进行惩罚，降低模型逐字重复同一行的可能性。 默认值0，取值范围：[-2.0, 2.0]。",
                                  "en_US": "Used to control the tendency of the model to avoid using certain words when generating content. The frequency of new words in the current text is penalized, reducing the likelihood of the model repeating the same line word by word. The default value is 0, with a range of [-2.0, 2.0]."
                              }
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "type": "float",
                              "default": 0.0,
                              "min": -2.0,
                              "max": 2.0,
                              "required": false,
                              "help": {
                                  "zh_Hans": "用于控制模型在生成内容时避免重复使用某些词汇的倾向。通过对已生成的token增加惩罚，减少重复生成的现象。默认值0，取值范围：[-2.0, 2.0]。",
                                  "en_US": "Used to control the tendency of the model to avoid using certain words when generating content. By adding a penalty to the already generated tokens, the phenomenon of repeated generation is reduced. The default value is 0, with a range of [-2.0, 2.0]."
                              }
                          },
                          {
                              "name": "logprobs",
                              "label": {
                                  "zh_Hans": "输出 tokens 的对数概率",
                                  "en_US": "Log Probabilities of Output Tokens"
                              },
                              "type": "boolean",
                              "default": false,
                              "required": false,
                              "help": {
                                  "zh_Hans": "是否返回输出 tokens 的对数概率。",
                                  "en_US": "Whether to return the log probabilities of the output tokens."
                              }
                          },
                          {
                              "name": "top_logprobs",
                              "label": {
                                  "zh_Hans": "每个输出 token 位置最有可能返回的 token 数量",
                                  "en_US": "The number of tokens that are most likely to be returned at each output token position"
                              },
                              "type": "int",
                              "default": 0,
                              "min": 0,
                              "max": 100,
                              "required": false,
                              "help": {
                                  "zh_Hans": "默认值0，取值范围为 [0, 20]。指定每个输出 token 位置最有可能返回的 token 数量，每个 token 都有关联的对数概率。仅当 logprobs为true 时可以设置 top_logprobs 参数。",
                                  "en_US": "The default value is 0, with a range of [0, 20]. Specifies the number of tokens that are most likely to be returned at each output token position, with each token having an associated log probability. Only when logprobs is true can the top_logprobs parameter be set."
                              }
                          }
                      ],
                      "pricing": {
                          "input": "4",
                          "output": "16",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "DeepSeek-v3",
                      "label": {
                          "zh_Hans": "DeepSeek-v3",
                          "en_US": "DeepSeek-v3"
                      },
                      "model_type": "llm",
                      "features": [
                          "tool-call",
                          "stream-tool-call",
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "type": "int",
                              "default": 8192,
                              "min": 1,
                              "max": 128000,
                              "required": false,
                              "help": {
                                  "zh_Hans": "模型回复最大长度（单位 token）。如果生成结果截断，可以调大该参数。",
                                  "en_US": "The maximum length of the model's response (in tokens). If the generated results are truncated, you can increase this parameter."
                              }
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "type": "float",
                              "default": 0.6,
                              "min": 0.0,
                              "max": 2.0,
                              "required": false,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。具体来说，较高的数值会使输出更加随机，而较低的数值会使其更加集中。默认值1.0，取值范围[0,2.0]。",
                                  "en_US": "Used to control the degree of randomness and diversity. Specifically, a higher value will make the output more random, while a lower value will make it more concentrated. The default value is 1.0, with a range of [0,2.0]."
                              }
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "type": "float",
                              "default": 1.0,
                              "min": 0.1,
                              "max": 1.0,
                              "required": false,
                              "help": {
                                  "zh_Hans": "用于控制随机性和多样性的程度。影响输出文本的多样性，取值越大，生成文本的多样性越强。默认值1.0。",
                                  "en_US": "Used to control the degree of randomness and diversity. It affects the diversity of the output text. The larger the value, the stronger the diversity of the generated text. The default value is 1.0."
                              }
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty",
                              "type": "float",
                              "default": 0.0,
                              "min": -2.0,
                              "max": 2.0,
                              "required": false,
                              "help": {
                                  "zh_Hans": "用于控制模型在生成内容时避免重复使用某些词汇的倾向。根据新词在当前文本中的频率进行惩罚，降低模型逐字重复同一行的可能性。 默认值0，取值范围：[-2.0, 2.0]。",
                                  "en_US": "Used to control the tendency of the model to avoid using certain words when generating content. The frequency of new words in the current text is penalized, reducing the likelihood of the model repeating the same line word by word. The default value is 0, with a range of [-2.0, 2.0]."
                              }
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty",
                              "type": "float",
                              "default": 0.0,
                              "min": -2.0,
                              "max": 2.0,
                              "required": false,
                              "help": {
                                  "zh_Hans": "用于控制模型在生成内容时避免重复使用某些词汇的倾向。通过对已生成的token增加惩罚，减少重复生成的现象。默认值0，取值范围：[-2.0, 2.0]。",
                                  "en_US": "Used to control the tendency of the model to avoid using certain words when generating content. By adding a penalty to the already generated tokens, the phenomenon of repeated generation is reduced. The default value is 0, with a range of [-2.0, 2.0]."
                              }
                          },
                          {
                              "name": "logprobs",
                              "label": {
                                  "zh_Hans": "输出 tokens 的对数概率",
                                  "en_US": "Log Probabilities of Output Tokens"
                              },
                              "type": "boolean",
                              "default": false,
                              "required": false,
                              "help": {
                                  "zh_Hans": "是否返回输出 tokens 的对数概率。",
                                  "en_US": "Whether to return the log probabilities of the output tokens."
                              }
                          },
                          {
                              "name": "top_logprobs",
                              "label": {
                                  "zh_Hans": "每个输出 token 位置最有可能返回的 token 数量",
                                  "en_US": "The number of tokens that are most likely to be returned at each output token position"
                              },
                              "type": "int",
                              "default": 0,
                              "min": 0,
                              "max": 100,
                              "required": false,
                              "help": {
                                  "zh_Hans": "默认值0，取值范围为 [0, 20]。指定每个输出 token 位置最有可能返回的 token 数量，每个 token 都有关联的对数概率。仅当 logprobs为true 时可以设置 top_logprobs 参数。",
                                  "en_US": "The default value is 0, with a range of [0, 20]. Specifies the number of tokens that are most likely to be returned at each output token position, with each token having an associated log probability. Only when logprobs is true can the top_logprobs parameter be set."
                              }
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format",
                              "label": {
                                  "zh_Hans": "回复格式",
                                  "en_US": "Response Format"
                              },
                              "type": "string",
                              "help": {
                                  "zh_Hans": "指定模型必须输出的格式的对象。 可启用 JSON 模式，这保证模型生成的消息是有效的 JSON。重要：使用 JSON 模式时，您还必须通过系统或用户消息提示模型自行生成JSON。",
                                  "en_US": "Specifies the format that the model must output. JSON mode can be enabled, which ensures that the message generated by the model is valid JSON. Important! When using JSON mode, you must also prompt the model to generate JSON through system or user messages."
                              },
                              "required": false,
                              "options": [
                                  "text",
                                  "json_object"
                              ]
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "8",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "QwQ-32B",
                      "label": {
                          "en_US": "QwQ-32B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 128000,
                              "default": 8192
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "required": false
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "6",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen2-VL-72B-Instruct",
                      "label": {
                          "en_US": "Qwen2-VL-72B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 1,
                              "max": 32768
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          }
                      ],
                      "pricing": {
                          "input": "16",
                          "output": "48",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen2-VL-7B-Instruct",
                      "label": {
                          "en_US": "Qwen2-VL-7B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 1,
                              "max": 32768
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "5",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen2.5-32B-Instruct",
                      "label": {
                          "en_US": "Qwen2.5-32B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "6",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen2.5-72B-Instruct",
                      "label": {
                          "en_US": "Qwen2.5-72B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          }
                      ],
                      "pricing": {
                          "input": "4",
                          "output": "12",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen2.5-7B-Instruct",
                      "label": {
                          "en_US": "Qwen2.5-7B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          }
                      ],
                      "pricing": {
                          "input": "0.5",
                          "output": "1",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen2.5-VL-72B-Instruct",
                      "label": {
                          "en_US": "Qwen2.5-VL-72B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          }
                      ],
                      "pricing": {
                          "input": "16",
                          "output": "48",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen2.5-VL-7B-Instruct",
                      "label": {
                          "en_US": "Qwen2.5-VL-7B-Instruct"
                      },
                      "model_type": "llm",
                      "features": [
                          "vision"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 1,
                              "max": 128000
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          }
                      ],
                      "pricing": {
                          "input": "2",
                          "output": "6",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  },
                  {
                      "model": "Qwen3-235B-A22B",
                      "label": {
                          "zh_Hans": "Qwen3-235B-A22B",
                          "en_US": "Qwen3-235B-A22B"
                      },
                      "model_type": "llm",
                      "features": [
                          "agent-thought"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 128000
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "min": 1,
                              "max": 128000,
                              "default": 8192
                          },
                          {
                              "name": "temperature",
                              "use_template": "temperature",
                              "default": 0.6
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p",
                              "required": false
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          }
                      ],
                      "pricing": {
                          "input": "4",
                          "output": "12",
                          "unit": "0.000001",
                          "currency": "RMB"
                      }
                  }
              ],
              "extra": {
                  "python": {
                      "provider_source": "provider/sophnet.py",
                      "model_sources": [
                          "models/llm/llm.py",
                          "models/text_embedding/text_embedding.py"
                      ]
                  }
              },
              "model_credential_schema": {
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  },
                  "credential_form_schemas": [
                      {
                          "label": {
                              "en_US": "API Key"
                          },
                          "placeholder": {
                              "en_US": "Enter your API Key",
                              "zh_Hans": "在此输入您的 API Key"
                          },
                          "required": true,
                          "type": "secret-input",
                          "variable": "api_key"
                      },
                      {
                          "variable": "project_id",
                          "label": {
                              "en_US": "Project ID"
                          },
                          "placeholder": {
                              "en_US": "Enter your Project ID",
                              "zh_Hans": "在此输入您的 Project ID"
                          },
                          "type": "text-input",
                          "required": true
                      },
                      {
                          "variable": "context_size",
                          "default": "4096",
                          "label": {
                              "en_US": "Model context size",
                              "zh_Hans": "模型上下文长度"
                          },
                          "placeholder": {
                              "en_US": "Enter your Model context size",
                              "zh_Hans": "在此输入您的模型上下文长度"
                          },
                          "required": true,
                          "type": "text-input",
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ]
                      },
                      {
                          "variable": "max_tokens",
                          "default": "4096",
                          "label": {
                              "en_US": "Upper bound for max tokens",
                              "zh_Hans": "最大 token 上限"
                          },
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "text-input"
                      },
                      {
                          "variable": "function_calling_type",
                          "default": "no_call",
                          "label": {
                              "en_US": "Function calling"
                          },
                          "options": [
                              {
                                  "label": {
                                      "en_US": "Not Support",
                                      "zh_Hans": "不支持"
                                  },
                                  "value": "no_call"
                              },
                              {
                                  "label": {
                                      "en_US": "Support",
                                      "zh_Hans": "支持"
                                  },
                                  "value": "function_call"
                              }
                          ],
                          "required": false,
                          "show_on": [
                              {
                                  "value": "llm",
                                  "variable": "__model_type"
                              }
                          ],
                          "type": "select"
                      },
                      {
                          "variable": "easyllm_id",
                          "label": {
                              "en_US": "EasyLLM ID"
                          },
                          "placeholder": {
                              "en_US": "Enter your EasyLLM ID",
                              "zh_Hans": "在此输入您的 EasyLLM ID"
                          },
                          "type": "text-input",
                          "required": true,
                          "show_on": [
                              {
                                  "value": "text-embedding",
                                  "variable": "__model_type"
                              }
                          ]
                      },
                      {
                          "variable": "dimensions",
                          "default": "1024",
                          "label": {
                              "en_US": "Embedding Dimensions",
                              "zh_Hans": "Embedding 维度"
                          },
                          "placeholder": {
                              "en_US": "Enter your Embedding Dimensions",
                              "zh_Hans": "在此输入您的 Embedding 维度"
                          },
                          "type": "select",
                          "options": [
                              {
                                  "label": {
                                      "en_US": "1024"
                                  },
                                  "value": "1024"
                              },
                              {
                                  "label": {
                                      "en_US": "768"
                                  },
                                  "value": "768"
                              },
                              {
                                  "label": {
                                      "en_US": "512"
                                  },
                                  "value": "512"
                              },
                              {
                                  "label": {
                                      "en_US": "256"
                                  },
                                  "value": "256"
                              },
                              {
                                  "label": {
                                      "en_US": "128"
                                  },
                                  "value": "128"
                              },
                              {
                                  "label": {
                                      "en_US": "64"
                                  },
                                  "value": "64"
                              }
                          ],
                          "required": true,
                          "show_on": [
                              {
                                  "value": "text-embedding",
                                  "variable": "__model_type"
                              }
                          ]
                      }
                  ]
              }
          }
      },
      {
          "version": "0.0.1",
          "type": "plugin",
          "author": "qianfan",
          "name": "baidu_qianfan",
          "label": {
              "en_US": "baidu_qianfan",
              "zh_Hans": "baidu_qianfan"
          },
          "description": {
              "en_US": "百度智能云千帆提供的 SDK",
              "zh_Hans": "百度智能云千帆提供的 SDK"
          },
          "icon": "icon_smart_cloud.png",
          "resource": {
              "memory": 268435456,
              "permission": {
                  "tool": {
                      "enabled": false
                  },
                  "model": {
                      "enabled": true,
                      "llm": true,
                      "text_embedding": true,
                      "rerank": true,
                      "tts": false,
                      "speech2text": false,
                      "moderation": false
                  },
                  "node": {
                      "enabled": false
                  },
                  "endpoint": {
                      "enabled": false
                  },
                  "app": {
                      "enabled": false
                  },
                  "storage": {
                      "enabled": true,
                      "size": 1048576
                  }
              }
          },
          "plugins": {
              "models": [
                  "provider/baidu_qianfan.yaml"
              ]
          },
          "meta": {
              "version": "0.0.1",
              "arch": [
                  "amd64",
                  "arm64"
              ],
              "runner": {
                  "language": "python",
                  "version": "3.12",
                  "entrypoint": "main"
              }
          },
          "created_at": "2025-05-28T14:45:11.287570+08:00",
          "privacy": "https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Rlgujm1c6?rs=1797052477&ruk=cBYeyI4hYNEInXRE89Znvg",
          "verified": false,
          "model": {
              "provider": "baidu_qianfan",
              "label": {
                  "en_US": "BaiduQianfan"
              },
              "description": {
                  "en_US": "Models provided by Baidu Cloud ModelBuilder.",
                  "zh_Hans": "百度智能云 ModelBuilder 提供的模型。"
              },
              "icon_small": {
                  "en_US": "icon_smart_cloud.png",
                  "zh_Hans": "icon_smart_cloud.png"
              },
              "icon_large": {
                  "en_US": "icon_smart_cloud_text.png",
                  "zh_Hans": "icon_smart_cloud_text.png"
              },
              "background": "#E5E7EB",
              "help": {
                  "title": {
                      "en_US": "Get your API Key from Baidu Cloud ModelBuilder",
                      "zh_Hans": "从 百度智能云 ModelBuilder 获取 API Key"
                  },
                  "url": {
                      "en_US": "https://cloud.baidu.com/doc/qianfan-api/s/ym9chdsy5"
                  }
              },
              "supported_model_types": [
                  "llm"
              ],
              "configurate_methods": [
                  "predefined-model",
                  "customizable-model"
              ],
              "model_credential_schema": {
                  "model": {
                      "label": {
                          "en_US": "Model Name",
                          "zh_Hans": "模型名称"
                      },
                      "placeholder": {
                          "en_US": "Enter your model name",
                          "zh_Hans": "输入模型名称"
                      }
                  },
                  "credential_form_schemas": [
                      {
                          "variable": "api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "type": "secret-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Key",
                              "en_US": "Enter your API Key"
                          }
                      }
                  ]
              },
              "provider_credential_schema": {
                  "credential_form_schemas": [
                      {
                          "variable": "api_key",
                          "label": {
                              "en_US": "API Key"
                          },
                          "type": "secret-input",
                          "required": true,
                          "placeholder": {
                              "zh_Hans": "在此输入您的 API Key",
                              "en_US": "Enter your API Key"
                          }
                      }
                  ]
              },
              "models": [
                  {
                      "model": "deepseek-r1",
                      "label": {
                          "zh_Hans": "deepseek-r1",
                          "en_US": "deepseek-r1"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 98304
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 1,
                              "max": 16384
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.016",
                          "unit": "0.001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "deepseek-v3",
                      "label": {
                          "zh_Hans": "deepseek-v3",
                          "en_US": "deepseek-v3"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 1,
                              "max": 16384
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.002",
                          "output": "0.008",
                          "unit": "0.001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "ernie-3.5-128k",
                      "label": {
                          "zh_Hans": "ernie-3.5-128k",
                          "en_US": "ernie-3.5-128k"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "penalty_score",
                              "type": "float",
                              "label": {
                                  "en_US": "penalty score"
                              },
                              "min": 1.0,
                              "max": 2.0
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 2,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.002",
                          "output": "0.0008",
                          "unit": "0.001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "ernie-4.0-turbo-128k",
                      "label": {
                          "zh_Hans": "ernie-4.0-turbo-128k",
                          "en_US": "ernie-4.0-turbo-128k"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "penalty_score",
                              "type": "float",
                              "label": {
                                  "en_US": "penalty score"
                              },
                              "min": 1.0,
                              "max": 2.0
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 2,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0003",
                          "output": "0.0009",
                          "unit": "0.001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "ernie-4.5-turbo-128k",
                      "label": {
                          "zh_Hans": "ernie-4.5-turbo-128k",
                          "en_US": "ernie-4.5-turbo-128k"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "penalty_score",
                              "type": "float",
                              "label": {
                                  "en_US": "penalty score"
                              },
                              "min": 1.0,
                              "max": 2.0
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 2048,
                              "min": 2,
                              "max": 12288
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0008",
                          "output": "0.0032",
                          "unit": "0.001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "ernie-4.5-turbo-32k",
                      "label": {
                          "zh_Hans": "ernie-4.5-turbo-32k",
                          "en_US": "ernie-4.5-turbo-32k"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 27648
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "penalty_score",
                              "type": "float",
                              "label": {
                                  "en_US": "penalty score"
                              },
                              "min": 1.0,
                              "max": 2.0
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 2048,
                              "min": 2,
                              "max": 12288
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ],
                      "pricing": {
                          "input": "0.0008",
                          "output": "0.0032",
                          "unit": "0.001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "ernie-lite-pro-128k",
                      "label": {
                          "zh_Hans": "ernie-lite-pro-128k",
                          "en_US": "ernie-lite-pro-128k"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "penalty_score",
                              "type": "float",
                              "label": {
                                  "en_US": "penalty score"
                              },
                              "min": 1.0,
                              "max": 2.0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 2,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ]
                  },
                  {
                      "model": "ernie-speed-pro-128k",
                      "label": {
                          "zh_Hans": "ernie-speed-pro-128k",
                          "en_US": "ernie-speed-pro-128k"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 131072
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "penalty_score",
                              "type": "float",
                              "label": {
                                  "en_US": "penalty score"
                              },
                              "min": 1.0,
                              "max": 2.0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 2,
                              "max": 4096
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          }
                      ]
                  },
                  {
                      "model": "ernie-x1-turbo-32k",
                      "label": {
                          "zh_Hans": "ernie-x1-turbo-32k",
                          "en_US": "ernie-x1-turbo-32k"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 2048,
                              "min": 2,
                              "max": 16384
                          }
                      ],
                      "pricing": {
                          "input": "0.001",
                          "output": "0.004",
                          "unit": "0.001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "qwen3-0.6b",
                      "label": {
                          "zh_Hans": "qwen3-0.6b",
                          "en_US": "qwen3-0.6b"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "penalty_score",
                              "type": "float",
                              "label": {
                                  "en_US": "penalty score"
                              },
                              "min": 1.0,
                              "max": 2.0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 2,
                              "max": 8192
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "enable_thinking",
                              "type": "boolean",
                              "default": false
                          }
                      ],
                      "pricing": {
                          "input": "0.0003",
                          "output": "0.0012",
                          "unit": "0.001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "qwen3-1.7b",
                      "label": {
                          "zh_Hans": "qwen3-1.7b",
                          "en_US": "qwen3-1.7b"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "penalty_score",
                              "type": "float",
                              "label": {
                                  "en_US": "penalty score"
                              },
                              "min": 1.0,
                              "max": 2.0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 2,
                              "max": 8192
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "enable_thinking",
                              "type": "boolean",
                              "default": false
                          }
                      ],
                      "pricing": {
                          "input": "0.0003",
                          "output": "0.0012",
                          "unit": "0.001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "qwen3-14b",
                      "label": {
                          "zh_Hans": "qwen3-14b",
                          "en_US": "qwen3-14b"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "penalty_score",
                              "type": "float",
                              "label": {
                                  "en_US": "penalty score"
                              },
                              "min": 1.0,
                              "max": 2.0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 2,
                              "max": 8192
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "enable_thinking",
                              "type": "boolean",
                              "default": false
                          }
                      ],
                      "pricing": {
                          "input": "0.001",
                          "output": "0.004",
                          "unit": "0.001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "qwen3-235b-a22b",
                      "label": {
                          "zh_Hans": "qwen3-235b-a22b",
                          "en_US": "qwen3-235b-a22b"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "penalty_score",
                              "type": "float",
                              "label": {
                                  "en_US": "penalty score"
                              },
                              "min": 1.0,
                              "max": 2.0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 2,
                              "max": 8192
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "enable_thinking",
                              "type": "boolean",
                              "default": false
                          }
                      ],
                      "pricing": {
                          "input": "0.004",
                          "output": "0.012",
                          "unit": "0.001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "qwen3-30b-a3b",
                      "label": {
                          "zh_Hans": "qwen3-30b-a3b",
                          "en_US": "qwen3-30b-a3b"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "penalty_score",
                              "type": "float",
                              "label": {
                                  "en_US": "penalty score"
                              },
                              "min": 1.0,
                              "max": 2.0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 2,
                              "max": 8192
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "enable_thinking",
                              "type": "boolean",
                              "default": false
                          }
                      ],
                      "pricing": {
                          "input": "0.0015",
                          "output": "0.006",
                          "unit": "0.001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "qwen3-32b",
                      "label": {
                          "zh_Hans": "qwen3-32b",
                          "en_US": "qwen3-32b"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "penalty_score",
                              "type": "float",
                              "label": {
                                  "en_US": "penalty score"
                              },
                              "min": 1.0,
                              "max": 2.0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 2,
                              "max": 8192
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "enable_thinking",
                              "type": "boolean",
                              "default": false
                          }
                      ],
                      "pricing": {
                          "input": "0.002",
                          "output": "0.008",
                          "unit": "0.001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "qwen3-4b",
                      "label": {
                          "zh_Hans": "qwen3-4b",
                          "en_US": "qwen3-4b"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "penalty_score",
                              "type": "float",
                              "label": {
                                  "en_US": "penalty score"
                              },
                              "min": 1.0,
                              "max": 2.0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 2,
                              "max": 8192
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "enable_thinking",
                              "type": "boolean",
                              "default": false
                          }
                      ],
                      "pricing": {
                          "input": "0.0003",
                          "output": "0.0012",
                          "unit": "0.001",
                          "currency": "CNY"
                      }
                  },
                  {
                      "model": "qwen3-8b",
                      "label": {
                          "zh_Hans": "qwen3-8b",
                          "en_US": "qwen3-8b"
                      },
                      "model_type": "llm",
                      "features": [
                          "multi-tool-call",
                          "stream-tool-call"
                      ],
                      "model_properties": {
                          "mode": "chat",
                          "context_size": 32768
                      },
                      "parameter_rules": [
                          {
                              "name": "temperature",
                              "use_template": "temperature"
                          },
                          {
                              "name": "top_p",
                              "use_template": "top_p"
                          },
                          {
                              "name": "penalty_score",
                              "type": "float",
                              "label": {
                                  "en_US": "penalty score"
                              },
                              "min": 1.0,
                              "max": 2.0
                          },
                          {
                              "name": "presence_penalty",
                              "use_template": "presence_penalty"
                          },
                          {
                              "name": "frequency_penalty",
                              "use_template": "frequency_penalty"
                          },
                          {
                              "name": "max_tokens",
                              "use_template": "max_tokens",
                              "default": 4096,
                              "min": 2,
                              "max": 8192
                          },
                          {
                              "name": "response_format",
                              "use_template": "response_format"
                          },
                          {
                              "name": "enable_thinking",
                              "type": "boolean",
                              "default": false
                          }
                      ],
                      "pricing": {
                          "input": "0.0005",
                          "output": "0.002",
                          "unit": "0.001",
                          "currency": "CNY"
                      }
                  }
              ],
              "extra": {
                  "python": {
                      "provider_source": "provider/baidu_qianfan.py",
                      "model_sources": [
                          "models/llm/llm.py"
                      ]
                  }
              }
          }
      }
  ]
}